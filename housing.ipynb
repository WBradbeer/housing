{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>11924</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12968</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>91.0</td>\n",
       "      <td>10652</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>279500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10920</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11241</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10791</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13695</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7560</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>101.0</td>\n",
       "      <td>14215</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>RM</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7449</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>139400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9742</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>RM</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4224</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8246</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>110.0</td>\n",
       "      <td>14230</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>98.0</td>\n",
       "      <td>11478</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16321</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6324</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>68500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>1431</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>21930</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>192140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1432</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4928</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1433</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10800</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>64500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1434</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10261</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1435</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>17400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1436</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1437</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1438</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12444</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>394617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1439</td>\n",
       "      <td>20</td>\n",
       "      <td>RM</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7407</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1440</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11584</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1441</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>79.0</td>\n",
       "      <td>11526</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1442</td>\n",
       "      <td>120</td>\n",
       "      <td>RM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4426</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1443</td>\n",
       "      <td>60</td>\n",
       "      <td>FV</td>\n",
       "      <td>85.0</td>\n",
       "      <td>11003</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1444</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8854</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1445</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1446</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>1447</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26142</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1448</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1449</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11767</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1450</td>\n",
       "      <td>180</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1533</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1451</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1452</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9262</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>287090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1453</td>\n",
       "      <td>180</td>\n",
       "      <td>RM</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3675</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1454</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>90.0</td>\n",
       "      <td>17217</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1455</td>\n",
       "      <td>20</td>\n",
       "      <td>FV</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5        6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6        7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7        8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8        9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9       10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "10      11          20       RL         70.0    11200   Pave   NaN      Reg   \n",
       "11      12          60       RL         85.0    11924   Pave   NaN      IR1   \n",
       "12      13          20       RL          NaN    12968   Pave   NaN      IR2   \n",
       "13      14          20       RL         91.0    10652   Pave   NaN      IR1   \n",
       "14      15          20       RL          NaN    10920   Pave   NaN      IR1   \n",
       "15      16          45       RM         51.0     6120   Pave   NaN      Reg   \n",
       "16      17          20       RL          NaN    11241   Pave   NaN      IR1   \n",
       "17      18          90       RL         72.0    10791   Pave   NaN      Reg   \n",
       "18      19          20       RL         66.0    13695   Pave   NaN      Reg   \n",
       "19      20          20       RL         70.0     7560   Pave   NaN      Reg   \n",
       "20      21          60       RL        101.0    14215   Pave   NaN      IR1   \n",
       "21      22          45       RM         57.0     7449   Pave  Grvl      Reg   \n",
       "22      23          20       RL         75.0     9742   Pave   NaN      Reg   \n",
       "23      24         120       RM         44.0     4224   Pave   NaN      Reg   \n",
       "24      25          20       RL          NaN     8246   Pave   NaN      IR1   \n",
       "25      26          20       RL        110.0    14230   Pave   NaN      Reg   \n",
       "26      27          20       RL         60.0     7200   Pave   NaN      Reg   \n",
       "27      28          20       RL         98.0    11478   Pave   NaN      Reg   \n",
       "28      29          20       RL         47.0    16321   Pave   NaN      IR1   \n",
       "29      30          30       RM         60.0     6324   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1430  1431          60       RL         60.0    21930   Pave   NaN      IR3   \n",
       "1431  1432         120       RL          NaN     4928   Pave   NaN      IR1   \n",
       "1432  1433          30       RL         60.0    10800   Pave  Grvl      Reg   \n",
       "1433  1434          60       RL         93.0    10261   Pave   NaN      IR1   \n",
       "1434  1435          20       RL         80.0    17400   Pave   NaN      Reg   \n",
       "1435  1436          20       RL         80.0     8400   Pave   NaN      Reg   \n",
       "1436  1437          20       RL         60.0     9000   Pave   NaN      Reg   \n",
       "1437  1438          20       RL         96.0    12444   Pave   NaN      Reg   \n",
       "1438  1439          20       RM         90.0     7407   Pave   NaN      Reg   \n",
       "1439  1440          60       RL         80.0    11584   Pave   NaN      Reg   \n",
       "1440  1441          70       RL         79.0    11526   Pave   NaN      IR1   \n",
       "1441  1442         120       RM          NaN     4426   Pave   NaN      Reg   \n",
       "1442  1443          60       FV         85.0    11003   Pave   NaN      Reg   \n",
       "1443  1444          30       RL          NaN     8854   Pave   NaN      Reg   \n",
       "1444  1445          20       RL         63.0     8500   Pave   NaN      Reg   \n",
       "1445  1446          85       RL         70.0     8400   Pave   NaN      Reg   \n",
       "1446  1447          20       RL          NaN    26142   Pave   NaN      IR1   \n",
       "1447  1448          60       RL         80.0    10000   Pave   NaN      Reg   \n",
       "1448  1449          50       RL         70.0    11767   Pave   NaN      Reg   \n",
       "1449  1450         180       RM         21.0     1533   Pave   NaN      Reg   \n",
       "1450  1451          90       RL         60.0     9000   Pave   NaN      Reg   \n",
       "1451  1452          20       RL         78.0     9262   Pave   NaN      Reg   \n",
       "1452  1453         180       RM         35.0     3675   Pave   NaN      Reg   \n",
       "1453  1454          20       RL         90.0    17217   Pave   NaN      Reg   \n",
       "1454  1455          20       FV         62.0     7500   Pave  Pave      Reg   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities    ...     PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "2            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "3            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "4            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "5            Lvl    AllPub    ...            0    NaN  MnPrv        Shed   \n",
       "6            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "7            Lvl    AllPub    ...            0    NaN    NaN        Shed   \n",
       "8            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "9            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "10           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "11           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "12           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "13           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "14           Lvl    AllPub    ...            0    NaN   GdWo         NaN   \n",
       "15           Lvl    AllPub    ...            0    NaN  GdPrv         NaN   \n",
       "16           Lvl    AllPub    ...            0    NaN    NaN        Shed   \n",
       "17           Lvl    AllPub    ...            0    NaN    NaN        Shed   \n",
       "18           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "19           Lvl    AllPub    ...            0    NaN  MnPrv         NaN   \n",
       "20           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "21           Bnk    AllPub    ...            0    NaN  GdPrv         NaN   \n",
       "22           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "23           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "24           Lvl    AllPub    ...            0    NaN  MnPrv         NaN   \n",
       "25           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "26           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "27           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "28           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "29           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "...          ...       ...    ...          ...    ...    ...         ...   \n",
       "1430         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1431         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1432         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1433         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1434         Low    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1435         Lvl    AllPub    ...            0    NaN  GdPrv         NaN   \n",
       "1436         Lvl    AllPub    ...            0    NaN   GdWo         NaN   \n",
       "1437         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1438         Lvl    AllPub    ...            0    NaN  MnPrv         NaN   \n",
       "1439         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1440         Bnk    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1441         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1442         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1443         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1444         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1445         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1446         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1447         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1448         Lvl    AllPub    ...            0    NaN   GdWo         NaN   \n",
       "1449         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1450         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1451         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1452         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1453         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1454         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1455         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1456         Lvl    AllPub    ...            0    NaN  MnPrv         NaN   \n",
       "1457         Lvl    AllPub    ...            0    NaN  GdPrv        Shed   \n",
       "1458         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1459         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0          0      2   2008        WD         Normal     208500  \n",
       "1          0      5   2007        WD         Normal     181500  \n",
       "2          0      9   2008        WD         Normal     223500  \n",
       "3          0      2   2006        WD        Abnorml     140000  \n",
       "4          0     12   2008        WD         Normal     250000  \n",
       "5        700     10   2009        WD         Normal     143000  \n",
       "6          0      8   2007        WD         Normal     307000  \n",
       "7        350     11   2009        WD         Normal     200000  \n",
       "8          0      4   2008        WD        Abnorml     129900  \n",
       "9          0      1   2008        WD         Normal     118000  \n",
       "10         0      2   2008        WD         Normal     129500  \n",
       "11         0      7   2006       New        Partial     345000  \n",
       "12         0      9   2008        WD         Normal     144000  \n",
       "13         0      8   2007       New        Partial     279500  \n",
       "14         0      5   2008        WD         Normal     157000  \n",
       "15         0      7   2007        WD         Normal     132000  \n",
       "16       700      3   2010        WD         Normal     149000  \n",
       "17       500     10   2006        WD         Normal      90000  \n",
       "18         0      6   2008        WD         Normal     159000  \n",
       "19         0      5   2009       COD        Abnorml     139000  \n",
       "20         0     11   2006       New        Partial     325300  \n",
       "21         0      6   2007        WD         Normal     139400  \n",
       "22         0      9   2008        WD         Normal     230000  \n",
       "23         0      6   2007        WD         Normal     129900  \n",
       "24         0      5   2010        WD         Normal     154000  \n",
       "25         0      7   2009        WD         Normal     256300  \n",
       "26         0      5   2010        WD         Normal     134800  \n",
       "27         0      5   2010        WD         Normal     306000  \n",
       "28         0     12   2006        WD         Normal     207500  \n",
       "29         0      5   2008        WD         Normal      68500  \n",
       "...      ...    ...    ...       ...            ...        ...  \n",
       "1430       0      7   2006        WD         Normal     192140  \n",
       "1431       0     10   2009        WD         Normal     143750  \n",
       "1432       0      8   2007        WD         Normal      64500  \n",
       "1433       0      5   2008        WD         Normal     186500  \n",
       "1434       0      5   2006        WD         Normal     160000  \n",
       "1435       0      7   2008       COD        Abnorml     174000  \n",
       "1436       0      5   2007        WD         Normal     120500  \n",
       "1437       0     11   2008       New        Partial     394617  \n",
       "1438       0      4   2010        WD         Normal     149700  \n",
       "1439       0     11   2007        WD         Normal     197000  \n",
       "1440       0      9   2008        WD         Normal     191000  \n",
       "1441       0      5   2008        WD         Normal     149300  \n",
       "1442       0      4   2009        WD         Normal     310000  \n",
       "1443       0      5   2009        WD         Normal     121000  \n",
       "1444       0     11   2007        WD         Normal     179600  \n",
       "1445       0      5   2007        WD         Normal     129000  \n",
       "1446       0      4   2010        WD         Normal     157900  \n",
       "1447       0     12   2007        WD         Normal     240000  \n",
       "1448       0      5   2007        WD         Normal     112000  \n",
       "1449       0      8   2006        WD        Abnorml      92000  \n",
       "1450       0      9   2009        WD         Normal     136000  \n",
       "1451       0      5   2009       New        Partial     287090  \n",
       "1452       0      5   2006        WD         Normal     145000  \n",
       "1453       0      7   2006        WD        Abnorml      84500  \n",
       "1454       0     10   2009        WD         Normal     185000  \n",
       "1455       0      8   2007        WD         Normal     175000  \n",
       "1456       0      2   2010        WD         Normal     210000  \n",
       "1457    2500      5   2010        WD         Normal     266500  \n",
       "1458       0      4   2010        WD         Normal     142125  \n",
       "1459       0      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
       "\n",
       "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
       "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
       "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
       "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
       "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "           SalePrice  \n",
       "count    1460.000000  \n",
       "mean   180921.195890  \n",
       "std     79442.502883  \n",
       "min     34900.000000  \n",
       "25%    129975.000000  \n",
       "50%    163000.000000  \n",
       "75%    214000.000000  \n",
       "max    755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lots of text fields that will need to be encoded (maybe try catboost)\n",
    "* Lots of missing values, especially in categoricals\n",
    "* Some in numerical values that I should try to impute\n",
    "* Medium number of features and not that much data (should try some simple models)\n",
    "* May want to bucket some of the numerical features like year built'\n",
    "* MSSubClass is actually a categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MSSubClass = df.MSSubClass.astype(str)\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['SalePrice', 'Id'], axis=1).values\n",
    "y = df.SalePrice.values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>1201.0</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>21.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>1452.0</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>1379.0</td>\n",
       "      <td>1978.506164</td>\n",
       "      <td>24.689725</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min     25%     50%     75%  \\\n",
       "LotFrontage  1201.0    70.049958   24.284752    21.0    59.0    69.0    80.0   \n",
       "MasVnrArea   1452.0   103.685262  181.066207     0.0     0.0     0.0   166.0   \n",
       "GarageYrBlt  1379.0  1978.506164   24.689725  1900.0  1961.0  1980.0  2002.0   \n",
       "\n",
       "                max  \n",
       "LotFrontage   313.0  \n",
       "MasVnrArea   1600.0  \n",
       "GarageYrBlt  2010.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose().loc[lambda x: x['count'] != 1460]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After getting dummy variables there are 304 features which is likely too many for OLS\n",
    "* Will need to use some kind of feature selection or regularization\n",
    "* Still a few missing values to impute\n",
    "* Try a simple pipeline with regression, random forest, gboosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbose=0)), ('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('regressor', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'scaler': [MinMaxScaler(copy=True, feature_range=(0, 1)), None], 'regressor': [RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=0.3, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_l...  normalize=False, random_state=None, solver='auto', tol=0.001)], 'regressor__alpha': [0.1, 1, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy=\"median\")),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "param_grid = [{'scaler': [MinMaxScaler(), None],\n",
    "               'regressor': [RandomForestRegressor(n_estimators=100)],\n",
    "               'regressor__min_samples_split': [5, 10],\n",
    "               'regressor__max_features': ['sqrt', 'log2', 0.3],\n",
    "              },\n",
    "              {'scaler': [MinMaxScaler(), None],\n",
    "               'regressor': [GradientBoostingRegressor()],\n",
    "               'regressor__max_depth': [2, 3, 4, 5, 6],\n",
    "               'regressor__max_features': ['sqrt', 'log2', 0.3],\n",
    "              },\n",
    "              {'scaler': [MinMaxScaler(), None],\n",
    "               'regressor': [Ridge()],\n",
    "               'regressor__alpha': [0.1, 1, 10]}\n",
    "             ]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_log_error', return_train_score=False)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor</th>\n",
       "      <th>param_regressor__max_features</th>\n",
       "      <th>param_regressor__max_depth</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.130814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>3</td>\n",
       "      <td>0.131091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>4</td>\n",
       "      <td>0.132561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.132754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>6</td>\n",
       "      <td>0.132810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>7</td>\n",
       "      <td>0.133331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>8</td>\n",
       "      <td>0.133366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.133631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>10</td>\n",
       "      <td>0.134229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>0.134490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>0.135121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>0.135457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>0.135659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>15</td>\n",
       "      <td>0.135961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.136452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>17</td>\n",
       "      <td>0.136723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>18</td>\n",
       "      <td>0.138374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>19</td>\n",
       "      <td>0.139105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>20</td>\n",
       "      <td>0.139193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>21</td>\n",
       "      <td>0.139453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>22</td>\n",
       "      <td>0.140383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>23</td>\n",
       "      <td>0.140461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>0.141165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>0.141229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>26</td>\n",
       "      <td>0.142630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>27</td>\n",
       "      <td>0.144420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>0.146062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>29</td>\n",
       "      <td>0.146089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>0.147105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>0.147564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>0.147808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>33</td>\n",
       "      <td>0.148446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>34</td>\n",
       "      <td>0.149221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>35</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>36</td>\n",
       "      <td>0.154483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>37</td>\n",
       "      <td>0.154552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>38</td>\n",
       "      <td>0.156240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>39</td>\n",
       "      <td>0.156472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>0.156598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>0.157803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>0.165534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>43</td>\n",
       "      <td>0.166128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>44</td>\n",
       "      <td>0.166589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>45</td>\n",
       "      <td>0.169028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>46</td>\n",
       "      <td>0.170874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>47</td>\n",
       "      <td>0.182045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48</td>\n",
       "      <td>0.185133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      param_regressor  \\\n",
       "29  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "25  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "28  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "34  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "23  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "22  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "36  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "30  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "41  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "46  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "37  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "31  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "19  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "18  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "24  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "35  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "40  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "32  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "47  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "26  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "38  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "27  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "39  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "33  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "17  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "16  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "20  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "9   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "8   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "13  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "21  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "11  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "12  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "10  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "44  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "0   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "1   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "14  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "2   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "3   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "45  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "5   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "15  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "4   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "6   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "7   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "42  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "43  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "\n",
       "   param_regressor__max_features param_regressor__max_depth  \\\n",
       "29                           0.3                          4   \n",
       "25                          sqrt                          4   \n",
       "28                           0.3                          4   \n",
       "34                           0.3                          5   \n",
       "23                           0.3                          3   \n",
       "22                           0.3                          3   \n",
       "36                          sqrt                          6   \n",
       "30                          sqrt                          5   \n",
       "41                           0.3                          6   \n",
       "46                           NaN                        NaN   \n",
       "37                          sqrt                          6   \n",
       "31                          sqrt                          5   \n",
       "19                          sqrt                          3   \n",
       "18                          sqrt                          3   \n",
       "24                          sqrt                          4   \n",
       "35                           0.3                          5   \n",
       "40                           0.3                          6   \n",
       "32                          log2                          5   \n",
       "47                           NaN                        NaN   \n",
       "26                          log2                          4   \n",
       "38                          log2                          6   \n",
       "27                          log2                          4   \n",
       "39                          log2                          6   \n",
       "33                          log2                          5   \n",
       "17                           0.3                          2   \n",
       "16                           0.3                          2   \n",
       "20                          log2                          3   \n",
       "9                            0.3                        NaN   \n",
       "8                            0.3                        NaN   \n",
       "13                          sqrt                          2   \n",
       "21                          log2                          3   \n",
       "11                           0.3                        NaN   \n",
       "12                          sqrt                          2   \n",
       "10                           0.3                        NaN   \n",
       "44                           NaN                        NaN   \n",
       "0                           sqrt                        NaN   \n",
       "1                           sqrt                        NaN   \n",
       "14                          log2                          2   \n",
       "2                           sqrt                        NaN   \n",
       "3                           sqrt                        NaN   \n",
       "45                           NaN                        NaN   \n",
       "5                           log2                        NaN   \n",
       "15                          log2                          2   \n",
       "4                           log2                        NaN   \n",
       "6                           log2                        NaN   \n",
       "7                           log2                        NaN   \n",
       "42                           NaN                        NaN   \n",
       "43                           NaN                        NaN   \n",
       "\n",
       "                                     param_scaler  rank_test_score     rmsle  \n",
       "29                                           None                1  0.130453  \n",
       "25                                           None                2  0.130814  \n",
       "28  MinMaxScaler(copy=True, feature_range=(0, 1))                3  0.131091  \n",
       "34  MinMaxScaler(copy=True, feature_range=(0, 1))                4  0.132561  \n",
       "23                                           None                5  0.132754  \n",
       "22  MinMaxScaler(copy=True, feature_range=(0, 1))                6  0.132810  \n",
       "36  MinMaxScaler(copy=True, feature_range=(0, 1))                7  0.133331  \n",
       "30  MinMaxScaler(copy=True, feature_range=(0, 1))                8  0.133366  \n",
       "41                                           None                9  0.133631  \n",
       "46  MinMaxScaler(copy=True, feature_range=(0, 1))               10  0.134229  \n",
       "37                                           None               11  0.134490  \n",
       "31                                           None               12  0.135121  \n",
       "19                                           None               13  0.135457  \n",
       "18  MinMaxScaler(copy=True, feature_range=(0, 1))               14  0.135659  \n",
       "24  MinMaxScaler(copy=True, feature_range=(0, 1))               15  0.135961  \n",
       "35                                           None               16  0.136452  \n",
       "40  MinMaxScaler(copy=True, feature_range=(0, 1))               17  0.136723  \n",
       "32  MinMaxScaler(copy=True, feature_range=(0, 1))               18  0.138374  \n",
       "47                                           None               19  0.139105  \n",
       "26  MinMaxScaler(copy=True, feature_range=(0, 1))               20  0.139193  \n",
       "38  MinMaxScaler(copy=True, feature_range=(0, 1))               21  0.139453  \n",
       "27                                           None               22  0.140383  \n",
       "39                                           None               23  0.140461  \n",
       "33                                           None               24  0.141165  \n",
       "17                                           None               25  0.141229  \n",
       "16  MinMaxScaler(copy=True, feature_range=(0, 1))               26  0.142630  \n",
       "20  MinMaxScaler(copy=True, feature_range=(0, 1))               27  0.144420  \n",
       "9                                            None               28  0.146062  \n",
       "8   MinMaxScaler(copy=True, feature_range=(0, 1))               29  0.146089  \n",
       "13                                           None               30  0.147105  \n",
       "21                                           None               31  0.147564  \n",
       "11                                           None               32  0.147808  \n",
       "12  MinMaxScaler(copy=True, feature_range=(0, 1))               33  0.148446  \n",
       "10  MinMaxScaler(copy=True, feature_range=(0, 1))               34  0.149221  \n",
       "44  MinMaxScaler(copy=True, feature_range=(0, 1))               35  0.152174  \n",
       "0   MinMaxScaler(copy=True, feature_range=(0, 1))               36  0.154483  \n",
       "1                                            None               37  0.154552  \n",
       "14  MinMaxScaler(copy=True, feature_range=(0, 1))               38  0.156240  \n",
       "2   MinMaxScaler(copy=True, feature_range=(0, 1))               39  0.156472  \n",
       "3                                            None               40  0.156598  \n",
       "45                                           None               41  0.157803  \n",
       "5                                            None               42  0.165534  \n",
       "15                                           None               43  0.166128  \n",
       "4   MinMaxScaler(copy=True, feature_range=(0, 1))               44  0.166589  \n",
       "6   MinMaxScaler(copy=True, feature_range=(0, 1))               45  0.169028  \n",
       "7                                            None               46  0.170874  \n",
       "42  MinMaxScaler(copy=True, feature_range=(0, 1))               47  0.182045  \n",
       "43                                           None               48  0.185133  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(grid.cv_results_)\n",
    "res['rmsle'] = np.sqrt(-res.mean_test_score)\n",
    "res.loc[:, ['param_regressor', 'param_regressor__max_features', 'param_regressor__max_depth',\n",
    "            'param_scaler', 'rank_test_score', 'rmsle']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor': GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='ls', max_depth=4, max_features=0.3,\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "              random_state=None, subsample=1.0, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'regressor__max_depth': 4,\n",
       " 'regressor__max_features': 0.3,\n",
       " 'scaler': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ridge regression is able to do alright despite the lack of feature engineering\n",
    "* Gradient Boosting does well should try others like xgboost and catboost\n",
    "* Should probably look at the data to reduce the feature space.\n",
    "* Should also look at residuals to seem if fit is reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverallQual             0.309910\n",
       "GrLivArea               0.141641\n",
       "GarageCars              0.138257\n",
       "TotalBsmtSF             0.043114\n",
       "1stFlrSF                0.029702\n",
       "ExterQual_TA            0.027180\n",
       "YearBuilt               0.026722\n",
       "BsmtFinSF1              0.025691\n",
       "ExterQual_Gd            0.022554\n",
       "Fireplaces              0.021132\n",
       "LotArea                 0.016987\n",
       "GarageYrBlt             0.016732\n",
       "BsmtQual_Ex             0.016508\n",
       "YearRemodAdd            0.015471\n",
       "GarageArea              0.014414\n",
       "2ndFlrSF                0.013787\n",
       "FullBath                0.011006\n",
       "OverallCond             0.007360\n",
       "Exterior2nd_HdBoard     0.006726\n",
       "KitchenQual_TA          0.004432\n",
       "TotRmsAbvGrd            0.004384\n",
       "BsmtUnfSF               0.004352\n",
       "WoodDeckSF              0.004260\n",
       "LotFrontage             0.003811\n",
       "BsmtFinType1_GLQ        0.003380\n",
       "CentralAir_Y            0.003356\n",
       "MSSubClass_60           0.002870\n",
       "MasVnrArea              0.002533\n",
       "BsmtFullBath            0.002497\n",
       "OpenPorchSF             0.002486\n",
       "                          ...   \n",
       "Condition2_Artery       0.000000\n",
       "Exterior1st_AsphShn     0.000000\n",
       "Neighborhood_CollgCr    0.000000\n",
       "Street_Pave             0.000000\n",
       "Utilities_NoSeWa        0.000000\n",
       "Alley_Grvl              0.000000\n",
       "GarageCond_Po           0.000000\n",
       "MasVnrType_BrkCmn       0.000000\n",
       "Exterior2nd_Stone       0.000000\n",
       "Exterior2nd_Other       0.000000\n",
       "Exterior2nd_ImStucc     0.000000\n",
       "Exterior2nd_CmentBd     0.000000\n",
       "Exterior2nd_CBlock      0.000000\n",
       "Exterior2nd_BrkFace     0.000000\n",
       "Exterior2nd_AsphShn     0.000000\n",
       "Utilities_AllPub        0.000000\n",
       "Exterior2nd_AsbShng     0.000000\n",
       "Exterior1st_BrkComm     0.000000\n",
       "Exterior1st_WdShing     0.000000\n",
       "Exterior1st_Wd Sdng     0.000000\n",
       "LotConfig_FR3           0.000000\n",
       "Exterior1st_Stucco      0.000000\n",
       "LandSlope_Gtl           0.000000\n",
       "Exterior1st_Stone       0.000000\n",
       "Exterior1st_MetalSd     0.000000\n",
       "Neighborhood_Blmngtn    0.000000\n",
       "Neighborhood_Blueste    0.000000\n",
       "Neighborhood_BrDale     0.000000\n",
       "Exterior1st_ImStucc     0.000000\n",
       "Exterior1st_CBlock      0.000000\n",
       "Length: 302, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(grid.best_estimator_.named_steps.regressor.feature_importances_,\n",
    "          index=df.drop(['SalePrice', 'Id'], axis=1).columns.values).sort_values()[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1272846828460598"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fda7c2bd940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_val, grid.predict(X_val) - y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(grid.predict(X_val) - y_val).hist(bins=30).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-2.82405984, -2.5268341 , -2.35847189, -2.23845937, -2.14401259,\n",
       "         -2.06553252, -1.99803001, -1.9385663 , -1.88525859, -1.83682524,\n",
       "         -1.79235285, -1.75116654, -1.712753  , -1.6767123 , -1.64272657,\n",
       "         -1.6105388 , -1.57993808, -1.55074915, -1.52282467, -1.49603959,\n",
       "         -1.47028677, -1.44547373, -1.42152004, -1.39835531, -1.37591755,\n",
       "         -1.35415189, -1.33300949, -1.31244672, -1.29242438, -1.27290718,\n",
       "         -1.25386317, -1.23526335, -1.21708133, -1.199293  , -1.18187626,\n",
       "         -1.16481085, -1.14807809, -1.13166074, -1.11554287, -1.09970971,\n",
       "         -1.08414754, -1.0688436 , -1.05378598, -1.03896357, -1.02436598,\n",
       "         -1.00998348, -0.99580691, -0.98182771, -0.96803779, -0.95442953,\n",
       "         -0.94099577, -0.92772971, -0.91462495, -0.90167541, -0.88887533,\n",
       "         -0.87621926, -0.86370201, -0.85131863, -0.83906446, -0.826935  ,\n",
       "         -0.814926  , -0.8030334 , -0.7912533 , -0.77958199, -0.76801592,\n",
       "         -0.7565517 , -0.74518605, -0.73391587, -0.72273814, -0.71164999,\n",
       "         -0.70064865, -0.68973147, -0.67889588, -0.66813942, -0.65745972,\n",
       "         -0.64685448, -0.6363215 , -0.62585865, -0.61546387, -0.60513517,\n",
       "         -0.59487063, -0.58466839, -0.57452664, -0.56444364, -0.55441771,\n",
       "         -0.5444472 , -0.53453053, -0.52466614, -0.51485255, -0.50508829,\n",
       "         -0.49537195, -0.48570215, -0.47607756, -0.46649687, -0.45695882,\n",
       "         -0.44746215, -0.43800567, -0.42858819, -0.41920858, -0.4098657 ,\n",
       "         -0.40055846, -0.3912858 , -0.38204665, -0.37284001, -0.36366486,\n",
       "         -0.35452022, -0.34540513, -0.33631866, -0.32725986, -0.31822785,\n",
       "         -0.30922172, -0.3002406 , -0.29128364, -0.28234998, -0.2734388 ,\n",
       "         -0.26454928, -0.25568062, -0.24683203, -0.23800272, -0.22919192,\n",
       "         -0.22039888, -0.21162285, -0.20286309, -0.19411887, -0.18538946,\n",
       "         -0.17667416, -0.16797226, -0.15928306, -0.15060587, -0.14194001,\n",
       "         -0.13328479, -0.12463954, -0.11600361, -0.10737631, -0.098757  ,\n",
       "         -0.09014502, -0.08153972, -0.07294045, -0.06434657, -0.05575745,\n",
       "         -0.04717243, -0.0385909 , -0.0300122 , -0.02143571, -0.01286079,\n",
       "         -0.00428683,  0.00428683,  0.01286079,  0.02143571,  0.0300122 ,\n",
       "          0.0385909 ,  0.04717243,  0.05575745,  0.06434657,  0.07294045,\n",
       "          0.08153972,  0.09014502,  0.098757  ,  0.10737631,  0.11600361,\n",
       "          0.12463954,  0.13328479,  0.14194001,  0.15060587,  0.15928306,\n",
       "          0.16797226,  0.17667416,  0.18538946,  0.19411887,  0.20286309,\n",
       "          0.21162285,  0.22039888,  0.22919192,  0.23800272,  0.24683203,\n",
       "          0.25568062,  0.26454928,  0.2734388 ,  0.28234998,  0.29128364,\n",
       "          0.3002406 ,  0.30922172,  0.31822785,  0.32725986,  0.33631866,\n",
       "          0.34540513,  0.35452022,  0.36366486,  0.37284001,  0.38204665,\n",
       "          0.3912858 ,  0.40055846,  0.4098657 ,  0.41920858,  0.42858819,\n",
       "          0.43800567,  0.44746215,  0.45695882,  0.46649687,  0.47607756,\n",
       "          0.48570215,  0.49537195,  0.50508829,  0.51485255,  0.52466614,\n",
       "          0.53453053,  0.5444472 ,  0.55441771,  0.56444364,  0.57452664,\n",
       "          0.58466839,  0.59487063,  0.60513517,  0.61546387,  0.62585865,\n",
       "          0.6363215 ,  0.64685448,  0.65745972,  0.66813942,  0.67889588,\n",
       "          0.68973147,  0.70064865,  0.71164999,  0.72273814,  0.73391587,\n",
       "          0.74518605,  0.7565517 ,  0.76801592,  0.77958199,  0.7912533 ,\n",
       "          0.8030334 ,  0.814926  ,  0.826935  ,  0.83906446,  0.85131863,\n",
       "          0.86370201,  0.87621926,  0.88887533,  0.90167541,  0.91462495,\n",
       "          0.92772971,  0.94099577,  0.95442953,  0.96803779,  0.98182771,\n",
       "          0.99580691,  1.00998348,  1.02436598,  1.03896357,  1.05378598,\n",
       "          1.0688436 ,  1.08414754,  1.09970971,  1.11554287,  1.13166074,\n",
       "          1.14807809,  1.16481085,  1.18187626,  1.199293  ,  1.21708133,\n",
       "          1.23526335,  1.25386317,  1.27290718,  1.29242438,  1.31244672,\n",
       "          1.33300949,  1.35415189,  1.37591755,  1.39835531,  1.42152004,\n",
       "          1.44547373,  1.47028677,  1.49603959,  1.52282467,  1.55074915,\n",
       "          1.57993808,  1.6105388 ,  1.64272657,  1.6767123 ,  1.712753  ,\n",
       "          1.75116654,  1.79235285,  1.83682524,  1.88525859,  1.9385663 ,\n",
       "          1.99803001,  2.06553252,  2.14401259,  2.23845937,  2.35847189,\n",
       "          2.5268341 ,  2.82405984]),\n",
       "  array([-2.08538180e+05, -1.65093280e+05, -1.39946654e+05, -7.95728243e+04,\n",
       "         -7.69096256e+04, -5.38616517e+04, -5.06777924e+04, -4.39610796e+04,\n",
       "         -4.25996926e+04, -4.17056488e+04, -3.88393406e+04, -3.22388978e+04,\n",
       "         -3.08684702e+04, -3.06405084e+04, -3.04154654e+04, -2.89790188e+04,\n",
       "         -2.74616670e+04, -2.70588568e+04, -2.69625565e+04, -2.38305426e+04,\n",
       "         -2.24421499e+04, -2.19178112e+04, -2.15851570e+04, -2.15438429e+04,\n",
       "         -2.08853603e+04, -2.07283419e+04, -2.06768482e+04, -2.01950391e+04,\n",
       "         -2.01596442e+04, -1.96101454e+04, -1.94873758e+04, -1.93329934e+04,\n",
       "         -1.87975381e+04, -1.86038261e+04, -1.81075716e+04, -1.80984620e+04,\n",
       "         -1.78301733e+04, -1.76762835e+04, -1.74738170e+04, -1.73538628e+04,\n",
       "         -1.67497425e+04, -1.66155739e+04, -1.63749233e+04, -1.63425928e+04,\n",
       "         -1.62293619e+04, -1.59782135e+04, -1.59367425e+04, -1.59045790e+04,\n",
       "         -1.57648968e+04, -1.56372022e+04, -1.54804202e+04, -1.54071529e+04,\n",
       "         -1.50428450e+04, -1.50419518e+04, -1.49740424e+04, -1.48470827e+04,\n",
       "         -1.47524002e+04, -1.46403073e+04, -1.34109112e+04, -1.30694321e+04,\n",
       "         -1.28973836e+04, -1.27710169e+04, -1.26812250e+04, -1.26472872e+04,\n",
       "         -1.26423929e+04, -1.25503832e+04, -1.23214715e+04, -1.23157900e+04,\n",
       "         -1.22024215e+04, -1.18411406e+04, -1.17718192e+04, -1.10213017e+04,\n",
       "         -1.09188055e+04, -1.07935881e+04, -1.05589042e+04, -1.01131041e+04,\n",
       "         -9.97182211e+03, -9.96370958e+03, -9.83277048e+03, -9.50259152e+03,\n",
       "         -9.25905987e+03, -9.14648551e+03, -8.96651030e+03, -8.78108424e+03,\n",
       "         -8.63972959e+03, -8.57985904e+03, -8.47718596e+03, -8.06562077e+03,\n",
       "         -7.93593259e+03, -7.49143525e+03, -7.11862979e+03, -7.06658394e+03,\n",
       "         -6.76098768e+03, -6.70494311e+03, -6.62045476e+03, -6.55995533e+03,\n",
       "         -6.51752805e+03, -6.21332129e+03, -6.09356776e+03, -5.99437889e+03,\n",
       "         -5.84281287e+03, -5.60627718e+03, -5.59095504e+03, -5.48506961e+03,\n",
       "         -5.31785850e+03, -5.23616477e+03, -5.11405815e+03, -4.82308797e+03,\n",
       "         -4.76096390e+03, -4.42712381e+03, -4.30164195e+03, -4.23623057e+03,\n",
       "         -4.21502820e+03, -3.95139991e+03, -3.90221713e+03, -3.89369179e+03,\n",
       "         -3.67614233e+03, -3.54487227e+03, -3.39359917e+03, -3.33773175e+03,\n",
       "         -3.14238246e+03, -2.76302585e+03, -2.62928862e+03, -2.56974376e+03,\n",
       "         -2.44375336e+03, -2.27479649e+03, -2.15637816e+03, -2.06185454e+03,\n",
       "         -1.92787843e+03, -1.84952084e+03, -1.52188669e+03, -1.41050668e+03,\n",
       "         -1.40911119e+03, -1.34218844e+03, -1.16265705e+03, -9.58151679e+02,\n",
       "         -8.19853386e+02, -7.33652965e+02, -7.26982700e+02, -6.93360814e+02,\n",
       "         -6.65571421e+02, -6.21650654e+02, -4.91727738e+02, -2.12595145e+02,\n",
       "         -1.07510285e+02,  8.30716075e+00,  7.74305020e+01,  1.50710308e+02,\n",
       "          2.65046029e+02,  3.68584758e+02,  5.26539895e+02,  6.32030305e+02,\n",
       "          7.22052722e+02,  7.90835793e+02,  9.07191578e+02,  9.34039300e+02,\n",
       "          9.47797599e+02,  1.08066732e+03,  1.13232711e+03,  1.19722396e+03,\n",
       "          1.32452361e+03,  1.42693265e+03,  1.53689883e+03,  1.64200946e+03,\n",
       "          1.67930503e+03,  1.71758714e+03,  1.77947160e+03,  1.89299856e+03,\n",
       "          1.95297910e+03,  2.00533048e+03,  2.02363714e+03,  2.10907212e+03,\n",
       "          2.11400696e+03,  2.19448426e+03,  2.20638048e+03,  2.38778580e+03,\n",
       "          2.76642486e+03,  2.93121387e+03,  2.97027127e+03,  3.18940269e+03,\n",
       "          3.31763943e+03,  3.96141777e+03,  4.01907313e+03,  4.08084923e+03,\n",
       "          4.54261658e+03,  4.63857340e+03,  4.71233726e+03,  4.72160004e+03,\n",
       "          4.82578745e+03,  5.31204093e+03,  5.43702402e+03,  5.51096424e+03,\n",
       "          5.55936554e+03,  5.61878367e+03,  6.08306394e+03,  6.24660900e+03,\n",
       "          6.31953383e+03,  6.38984663e+03,  6.55361477e+03,  6.62842444e+03,\n",
       "          6.72288113e+03,  6.89534609e+03,  7.04653420e+03,  7.25354772e+03,\n",
       "          7.40022356e+03,  7.40806309e+03,  7.43814737e+03,  7.56184698e+03,\n",
       "          7.61202386e+03,  7.62916901e+03,  8.17459007e+03,  8.53912392e+03,\n",
       "          8.55465402e+03,  9.00552156e+03,  9.23159921e+03,  9.73802437e+03,\n",
       "          1.01106283e+04,  1.02940993e+04,  1.09947207e+04,  1.10668408e+04,\n",
       "          1.16680463e+04,  1.17190385e+04,  1.19168611e+04,  1.19944886e+04,\n",
       "          1.20360450e+04,  1.23970510e+04,  1.24970093e+04,  1.25373622e+04,\n",
       "          1.27673303e+04,  1.28594881e+04,  1.28817563e+04,  1.29956360e+04,\n",
       "          1.32519279e+04,  1.35584015e+04,  1.36340688e+04,  1.37773066e+04,\n",
       "          1.42873227e+04,  1.43632110e+04,  1.44689529e+04,  1.47018880e+04,\n",
       "          1.47903420e+04,  1.48537752e+04,  1.48883215e+04,  1.50242956e+04,\n",
       "          1.51129116e+04,  1.54218520e+04,  1.54612883e+04,  1.54757980e+04,\n",
       "          1.55727123e+04,  1.61138733e+04,  1.65663750e+04,  1.67924792e+04,\n",
       "          1.81457325e+04,  1.96986063e+04,  1.97546527e+04,  1.99095722e+04,\n",
       "          2.05674275e+04,  2.06150281e+04,  2.06164798e+04,  2.09939752e+04,\n",
       "          2.12628084e+04,  2.15620411e+04,  2.18149617e+04,  2.18173526e+04,\n",
       "          2.19506626e+04,  2.21236885e+04,  2.45411950e+04,  2.49644978e+04,\n",
       "          2.56855705e+04,  2.57676873e+04,  2.66947138e+04,  2.76726020e+04,\n",
       "          2.84581969e+04,  2.84724925e+04,  2.89020894e+04,  2.92546576e+04,\n",
       "          2.94435125e+04,  2.98641901e+04,  3.03915215e+04,  3.30018448e+04,\n",
       "          3.30376098e+04,  3.61491108e+04,  3.73147338e+04,  3.94375236e+04,\n",
       "          3.95936714e+04,  4.58855603e+04,  5.25001220e+04,  5.98250252e+04,\n",
       "          6.29253255e+04,  8.22768702e+04,  9.68585262e+04,  2.14397719e+05])),\n",
       " (24544.772440110322, -524.8235762894176, 0.8383076880816948))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEWCAYAAADLkvgyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xl8VfWd//HXO4hgQEERN1atVEXFhZBYO9OOSxU7bdHWtbRqtTJulbbTRYfO2GlLp8tMO9pFi9VRa6q2tS7zq45btba2JgREEdxwAcENBUVEUODz++N8k9yELDeQm5Pl/Xw88rj3fM+553xOavPh+z2f+/0qIjAzM8tTWd4BmJmZORmZmVnunIzMzCx3TkZmZpY7JyMzM8udk5GZmeXOycishCR9U9J1m/nZ0yX9pY39d0g6raVjJa2WtMfmXLeDMd4v6fOlvo71fk5GZs1Iel7SO+kP+iuSrpY0OO+4mouIYyLimlb2DY6IZwFS/N/Z3Ot0xu9D0lhJIWmrzY3DejcnI7OWfTwiBgMHAxXAN5ofoExf+f9Qu78Psy3RV/6PZLZZImIZcAewHzQMS82U9CCwBthD0m6SbpO0QtIiSWc1O81ASTdKekvSXEkH1O+QdKGkZ9K+hZKOa/ZZSfqppDclPSHpiIIdrQ6RpV7InpKmAVOBr6Wezf9K+qqkm5odf6mkSzr6+2h2jjJJ35C0WNKrkq6VNCTtfiC9vpHi+EB717K+xcnIrA2SRgEfBR4uaP4sMA3YFlgM3AAsBXYDjge+K+nwguOnAL8FdgB+DdwiqX/a9wzw98AQ4N+B6yTtWvDZqnTMjsDFwO8l7VBs/BExC6gGfpCG7j4OXAdMljQ03eNWwMnAte2dr5XfR73T089hwB7AYOCnad+H0uvQFMffir0H6xucjMxadoukN4C/AH8Cvluw7+qIWBAR64FdgA8CX4+ItRExD/glcGrB8XMi4ncR8R7wI2AgcAhARPw2Il6MiI0RcSPwNFBZ8NlXgf+OiPfS/ieBf9ySG4uIl8h6KiekpsnAaxExp42PtfX7qDcV+FFEPBsRq4GLgJP9nMiK4f9IzFp2bETc08q+Fwre7wasiIi3CtoWkz1X2eT4iNgoqb4XhaRTgS8DY9Mhg8l6QfWWRdPZjBfXf3YLXQOcA1wBfAb4VTvHt/X7qLcbWXz1FpP9jdl5c4O0vsM9I7OOK0wOLwI7SNq2oG00sKxge1T9m1TwMBJ4UdIYsmRwPjAsIoYCjwEq+OwISYXbo9M1NzfeercAEyTtB3yMbChvS70IjCnYHg2sB15pJQazBk5GZlsgIl4A/gr8h6SBkiYAZ5I9l6k3UdIn03DVF4F1wEPAILI/0ssBJH2OTQsDdgIukNRf0gnAPsDtHQzzFbJnOIVxrwV+R/YMqzYilnTwnC25HviSpN1T6fd3gRvTcOZyYGPzOMzqORmZbblTyIbZXgRuBi5uNqR1K3ASsJKs+OGT6RnQQuC/gL+RJYz9gQebnbsGGAe8BswEjo+I1zsY35XAeElvSLqloP2adM32huiKdVU61wPAc8Ba4AsAEbGGLP4HUxyHdNI1rZeQF9cz65skjQaeAHaJiFV5x2N9m3tGZn1Qenb1ZeAGJyLrDlxNZ9bHSBpENiy4mKys2yx3HqYzM7PceZjOzMxy52G6Iu24444xduzYvMMwM+tR5syZ81pEDG/vOCejIo0dO5a6urq8wzAz61EkLW7/KA/TmZlZN+BkZGZmuXMyMjOz3DkZmZlZ7pyMzMwsd05GZmbWoupqGDsWysqy1+rOWGikFS7tNjOzTVRXw7RpsGZNtr14cbYNMHVq51/PPSMzM9vEjBmNiajemjVZeyk4GZmZ2SaWtLLcYmvtW8rJyMzMNjF6dMfat5STkZmZbWLmTCgvb9pWXp61l4KTkZmZbWLqVJg1C8aMASl7nTWrNMULkGMykjRK0n2SFkpaIGl6at9B0t2Snk6v26d2SbpU0iJJj0o6uOBcp6Xjn5Z0WkH7REnz02culaS2rmFmZo2mToXnn4eNG7PXUiUiyLdntB7454gYDxwCnCdpPHAhcG9EjAPuTdsAxwDj0s804DLIEgtwMVAFVAIXFySXy4CzCj5Xv6pla9cwM7Mc5JaMIuKliJib3r8FPA6MAKYA16TDrgGOTe+nANdG5iFgqKRdgaOBuyNiRUSsBO4GJqd920XEQ5EtZ3tts3O1dA0zM8tBt3hmJGkscBBQA+wcES+lXS8DO6f3I4AXCj62NLW11b60hXbauEbzuKZJqpNUt3z58o7fmJmZFSX3ZCRpMHAT8MWIWFW4L/VoopTXb+saETErIioiomL48HYXKjQzs82UazKS1J8sEVVHxO9T8ytpiI30+mpqXwaMKvj4yNTWVvvIFtrbuoaZmeUgz2o6AVcCj0fEjwp23QbUV8SdBtxa0H5qqqo7BHgzDbXdCRwlaftUuHAUcGfat0rSIelapzY7V0vXMDOzHOQ5UeoHgc8C8yXNS23/AnwP+I2kM4HFwIlp3+3AR4FFwBrgcwARsULSt4HZ6bhvRcSK9P5c4GpgG+CO9EMb1zAzsxwoe2Ri7amoqIi6urq8wzAz61EkzYmIivaOy72AwczMzMnIzMxy52RkZma5czIyM7PcORmZmVnunIzMzCx3TkZmZpY7JyMzM8udk5GZmeXOycjMzHLnZGRmZrlzMjIzs9w5GZmZWe6cjMzMLHdORmZmljsnIzMzy52TkZmZ5c7JyMzMcudkZGZmuXMyMjOz3DkZmZlZ7pyMzMwsd05GZmaWOycjMzPLnZORmZnlzsnIzMxy52RkZma5czIyM7PcORmZmVnunIzMzCx3TkZmZpY7JyMzM8udk5GZmeXOycjMzHLnZGRmZrlzMjIzs9w5GZmZWe6cjMzMLHe5JiNJV0l6VdJjBW07SLpb0tPpdfvULkmXSlok6VFJBxd85rR0/NOSTitonyhpfvrMpZLU1jXMzCwfefeMrgYmN2u7ELg3IsYB96ZtgGOAcelnGnAZZIkFuBioAiqBiwuSy2XAWQWfm9zONczMeo3qahg7FsrKstfq6rwjal2uySgiHgBWNGueAlyT3l8DHFvQfm1kHgKGStoVOBq4OyJWRMRK4G5gctq3XUQ8FBEBXNvsXC1dw8ysV6iuhmnTYPFiiMhep03rvgkp755RS3aOiJfS+5eBndP7EcALBcctTW1ttS9tob2tazQhaZqkOkl1y5cv38zbMTPrejNmwJo1TdvWrMnau6PumIwapB5N5HWNiJgVERURUTF8+PBShmFm1qmWLOlYe966YzJ6JQ2xkV5fTe3LgFEFx41MbW21j2yhva1rmJn1CqNHd6w9b90xGd0G1FfEnQbcWtB+aqqqOwR4Mw213QkcJWn7VLhwFHBn2rdK0iGpiu7UZudq6RpmZr3CzJlQXt60rbw8a++O8i7tvh74G7CXpKWSzgS+B3xE0tPAkWkb4HbgWWARcAVwLkBErAC+DcxOP99KbaRjfpk+8wxwR2pv7RpmZr3C1KkwaxaMGQNS9jprVtbeHSl7ZGLtqaioiLq6urzDMDMDsqq4GTOyZ0CjR2c9nu6YaCTNiYiK9o7bqiuCMTOzzlNftl1fLVdftg3dMyEVozs+MzIzszb0tLLtYnQoGaUigQmlCsbMzNrX08q2i9FuMpJ0v6Tt0rQ7c4ErJP2o9KGZmVlLelrZdjGK6RkNiYhVwCfJpuOpIqtAMzOzHPS0su1iFJOMtkpfDD0R+H8ljsfMzNrR08q2i1FMNd23yL5Y+mBEzJa0B/B0acMyM7O2TJ3as5NPc+0mo4j4LfDbgu1ngU+VMigzM8vZu+/C/PlQUwP77w9///clvVwxBQzvl3Rv/QJ4kiZI+kZJozIzs65bjygCnnkGrr8evvhFOPRQ2G47qKiA886Dm28u0YUbFTNMdwXwVeAXABHxqKRfA98pZWBmZn1J8xkVPvpRuOaaEn2x9fXXobY2+6mpyV5ffz3bt802MHFiloSqqrKfLijTKyYZlUdEbVqxu976EsVjZtbntDSjwuWXZx2WQvVfbO1QMlq7FubNa0w6NTVZLwiy6od994UpU6CyMks8++4L/ft3yn11RDHJ6DVJ7yOt+SPpeOCltj9iZmbFamlGhdamDW3zi60bN8JTTzUmnZoaeOQRWJ/6DyNGZEnnrLOy14oK2HbbTrmHLVVMMjoPmAXsLWkZ8BzwmZJGZWbWh3Rk5oQmI2Yvv9x0uG32bHjzzWzf4MEwaRL88z9nPZ7KyiwZdVPFVNM9CxwpaRBQFhFvlT4sM7PerfAZUVkZbNiw6TFSYw+pnLc5dMBcvn9oDZyQhtzqs1i/fjBhApx8cmPi2XvvrL2HaDcZSfq3ZtsARMS3ShSTmVmv1vwZUfNEVMYGJg5cyAWH1FJWV8P41bXsx2NstW4DXE9WWveBD8D06VnyOeigTadk6GGKGaZ7u+D9QOBjwOOlCcfMrPdr+owoGMEyqqjhENUyKWqYpDoGrX0b7geGDoWjKqHqE1mPp7ISdtopv+BLpJhhuv8q3Jb0n2QzMpiZWZHqh+VWLl7FROo4hRoqqaWKGnZLNWHvRn+2rjwIKj/XONw2blw2XtfLbc7ieuXAyM4OxMys13nvPZg/n9qf1rLx2hpu31DD3jxBWVaczFOM416OoJZKaqjijdEH8FTNgJyDzkcxz4zmk8q6gX7AcLL56szMrF4EPPdc0+q2uXNh7Voqgd3ZkRqquJ5TqKWS2UxiJTs0fLy8HGZ9N7/w81ZMz+hjBe/XA69EhL/0amZ924oVWSl1/fd5amvhtdcAWKuB1MVE5g88hzmDq7h3dSXPMxbYdLhNysq1Z87sXROfdlSrySgtpgfQvJR7O0lExIrShWVm1o2sW5fNYlA4fc7TafECCfbZh2fGf5zL5lRy79tVPBb7sZ7+sLbt044ZA88/X/Loe4S2ekZzyIbnWnpyFsAeJYnIzCxPGzfCokVNezzz5mXPfwB23TUrLjjjDO5ZVckXr6tgwcLtmnwnqBg9fTG8ztZqMoqI3bsyEDOzXLz6atMeT20tvPFGtm/QoGwWgy99Caqq+P3SSr78o5EsvgV0a9Pk05FENGaMh+WaK6qaTtL2wDiy7xkBEBEPlCooM7OSWLMmKyoonLtt8eJsX1lZtm7PiSc2TBr664f34V/+tR+L72eTnk9Hkk8hD821rJhqus8D08nKuecBhwB/Aw4vbWhmZltgwwZ4/PGm1W3z5zdOdzBmDIt3ruRXq77AnSsreXjjwbz9yCB4hGw2zmY2N/kU8tBc64rpGU0HJgEPRcRhkvYG+nABopl1S8uWNe3x1NXB6tXZviFDeGlUJb/e+kLuf6eK2UzilcW7wOLShjRoEAwcmBXeuWKubcUko7URsVYSkgZExBOS9ip5ZGZmrXnrrSzZFD7rWbYs29e/PxxwAJx2GlRWctsrVUz95jhWP9buwtZbrH4oz8+EOq6YZLRU0lDgFuBuSSsp+b8nzMyS9evhsceaVrctXNg4brbnnvDhD1PXr4oZt1byp1UHsq5uINQBP+u6MIcNg0sucQLaXMXMTXdcevtNSfcBQ4D/K2lUZtY3RWQFBYU9njlz4J13AFg7eBj3v1PF3+IEasiG21YsGgaLuj7UsrKsCty9oM7R1pdebwd+DdwSEasBIuJPXRWYmfUBK1c2zmJQX2jw6qvZvgED4OCD4Z/+CSor+dc/VPGd6t1p+auPpefkU1pt9Yx+AZwM/Dj1iK4H/hAR73ZJZGbWu6xbly2BXVjd9tRTDbvf3G0fbn/zGB6giloqeXTdBNb/rX9Wu5sjD791jba+9HorcKukcuDjwKnAZZLuAH4dEXd3UYxm1tNEZLMYpKTz3I017PbqPAaQ/Vv2JXahhipqOY0aqqijglUvDunyMN3b6T6KeWa0BrgRuFHSBOAassTUc9azNbPSWr4camv5w8W19JuTrdOzAysBeJtyllDBb5nesFTCUkaS13CbezrdUzFfet0ZOJFsyG5X4DfA6aUNy8y6rXfegYcfhpoa6n5eww6LatmD5wCYTBmPsR838anU86lkIePZsFlLp3UeJ6Dur60ChrOAU4C9gJuAr0bEX7sqMDPL33nnbOS+y59oWJG0klom8Cj9yVaR2YlR1FDFZZxDDVXM5WDeZnCuMTvx9Ext/XPlA8B/APdGxMYuisfMcnDuuXDZZbALL1FFTUPi+Q9ms11aReZNtmM2k/gBX6OWSmqp5GV2zS3mc86Bn/88t8tbJ2urgOGMrgzEzEqrujqrkn777Wx7EKupoI5KajmcWi6ihlEsBeA9tuIRDuA6PtMw3PYkexGUfhaD9rjn0zvlO5CbM0mTgUvIijF+GRHfyzkks6LV92aK0Y/17MsCTknDbVXUMJ6F9CMb9HiGPfgzf99QYDCPA1nLNiWMvnVlZVnSdK+nb+mzyUhSP7LJQj4CLAVmS7otIhbmG5lZ5sgj4d57N+eTwSheaBhqq6KGicxhEGsAeJ0dqKWSm/hUw3Db6+zYqbG3ZvBguPxy92psU8UsO96iXrDseCWwKCKeBZB0AzAFcDKyLtGRnk1bhvAGFdQ1ST678AoAaxnAwxzEL/l8w3DbM7yPUpdVO+lYRxW77PhoYGV6PxRYAvT0lWBHAC8UbC8FqgoPkDQNmAYwevTorovMeo3mz2m2VH/eZQKPNqlu24cnGvY/wV7cydENw22PMoH32LpzLt4GD63Zlmp32XFJVwA3R8TtafsY4NiuCS9fETGLtMxWRUVFJyytZb1VZ/Vymgr24NkmPZ6DeJiBrAPgFXaihiqu4zPUUslsJvEmQzs7CCBbGuHss51srHSKeWZ0SEScVb8REXdI+kEJY+oqy4BRBdsjU5tZq0qTdDLDeI1JzG5IPpXUsiOvA9ksBnOYyE85v2G4bQmj6ezhNicdy0sxyehFSd8ArkvbU4EXSxdSl5kNjJO0O1kSOhn4dL4hWd7OPTd71tEZS0y3ZQBrOYiHmwy37ckzAGxELGBfbuHYhuG2BezbqbMYOOlYd1PMf92nABcDN5M9Q3ogtfVoEbFe0vnAnWSl3VdFxIKcw7IuUl0N06fD66+X/lpiI+/nqSbDbQfwSMMsBi8wkloqmcU0aqlkDhNZzbYdusYRR8A995QierOuUcxEqSuA6ZIGRUQnPYbtHtJzsNvzjsM6V1cmmpbszMtNejyTmM1Q3gRgFdsym0n8J19pGG57id3aPJ97MdYXFDNR6qHAL4HBwGhJBwD/FBHnljo4s5bknWwKlfM2E5nTJPmMYQkA6+nHo0zgek5pGG57kr3Y2GzCeycbs+KG6X4MHA3cBhARj0j6UEmjsj6tuhpmzMhWn5ZK//ymWGVsYDwLmwy37cdjDbMYPMvu/JVD+W++SA1VPMxBDbMY1CechU44Zi0q6oloRLwgNana2VCacKyvaS/x5JeIgpEsbdLjqaCOwWQj1SvYnloqG4oMaqnkNYY3JJ2/OumYdUgxyeiFNFQXkvoD04HHSxuW9QXNK9fy7AFtyyomMbtJ8tmNlwBYx9Y8zEFcxRkNz3leHrQnl/9CXOwZBsw6RTHJ6GyyyURHkJVA3wWcV8qgrPcp7AH16wcbcuxbb8V77M/8JsNte/MEZWTZ8Enez/1bHcm4T1cy6fwqBkyYwCEDBnBIfiGb9XptJqM0mehnI8L//rPN1rwH1LWJKNid55r0eA5mLtuwFoBXGc7D/at4b8qnOeCsSpg0ib223569ujJEM2s7GUXEBkmfJitiMGtTS72fri5A2J4VDbMXfLBfDR8ur2XgW69lO7fZBiZOhMpzoaoKKivZacwYjlZpJw01s/YVM0z3F0k/BW4EGr5nFBFzSxaV9SgtlVrX935KmYh222EtV17wCJO3r4HaWqipgUWLsp0S7D0eqj4BlZVZ8tl3X+jfv3QBmdlmKyYZHZhev1XQFsDhnR+O9TTV1TBtGqxZ0/nnbrKi58aN8PTTjUmnthbmzYNvvpcdvNtuWcL5/Oez5FNRAdt2bBYDM8tPMTMwHNYVgVjPNGNG5ySiTb74+corWcKprYWjamD2bHjjjWzf4MEwaRJ8+csNw22MGLHlQZhZboqZgWFn4LvAbhFxjKTxwAci4sqSR2fdWnV19nxoc9U/V9pr1BouPX0uRw2pgZNSz6f+xP36wf77w0knNQ637b131m5mvUYxw3RXA/8DzEjbT5E9P3Iy6kPqixOWLIEddoC1azdvwbjhO2zgqq8+zsd2Khhumz8fvp0eMo0dmyWcCy7Iks/BB0N5eafei5l1P8Ukox0j4jeSLoKG2a49A0Mf0NrsCMXMCVdWlj3mGVW2jIqNNXxku1qOG1HDLi/UwUWrs4OGDs0SzkUXZQlo0iTYeefS3ZCZdVvFJKO3JQ0jK1pA0iGQpiC2Xqt5YUIxVXHbsoqJzOFHJ9Zw0Hup5/NiWvrqnf4w+EA4/fTG4bY998yylpn1ecUkoy+TTZL6PkkPAsOB40saleWuvcKErXiP/XisyZdJx7Mwm8XgN8C4cXDYYY0FBgceCAMGdFn8ZtazFFNNN1fSh4G9yNY4fjIi3it5ZJaLwqG5RsEYFjeZPudg5lLOOwAsZ0dqqOLm/ifywS9VcfjXJ2UPlszMitRqMpL0yVZ2vV8SEfH7EsVkOakfmtt6zUo+wuwmyWcnlgPwDgOZy8FcztkNa/Q8z1iGDROXXAKHe+IoM9sMbfWMPp5edwIOBf6Ytg8D/go4GfUC11+9jhsueoTRL9dSpRrmRi178RQAGxGPsw9/4B+poYrZVPIo+zNkWDaLwYoVMHo0XDczfTHVzGwztZqMIuJzAJLuAsZHxEtpe1eycm/raSKy6XJSSfVrt9fwyWfmcQrvAvBi7EoNVVzN6dRQxRwmsoohAIwZAzOddMysRIopYBhVn4iSV4DRJYrHOtPy5U2nz6mthZUrs32DBrFofQV/4osNw23LGEH2WLCpMWPg+ee7NHIz62OKSUb3SroTuD5tnwTcU7qQbLO88w7Mnds0+Tz3XLavrCybxeD44xur28aP59D+/WivYru8POsRmZmVUjHVdOdLOg74UGqaFRE3lzYsa9PGjfDEE41Jp6YGHn20cars0aOzpHNuWirh4INh0KBNTjN6dMvT+fTrl11i9GgPzZlZ1yhmcb170mSpTkB5efHFpj2e2bPhrbeyfUOGZDMXXHhh1uOprIRddinqtDNnbjrjdnk5zJrlBGRmXauYxfU2ShoSEZ51oSusXg11dU2Tz9Kl2b7+/eGAA+Czn20cbnv/+zd7FoP6hFM/55x7QmaWl2KeGa0G5ku6m6aL611Qsqj6ivXrYcGCpsNtCxdmY2QA73sffOhDjdPnHHggDBzYqSFMnerkY2b5KyYZ/R5/p2jLRWTdj8Iez5w5jWNkw4ZlSef44xuH24YNyzdmM7MuUkwyuhHYM71fFBFrSxhP7/Pgg/D972fJ55VXsrYBA7KigrPOahxu22OPbGpsM7M+qK3pgLYiW1TvDGAx2RdQRkn6H2CG56cr0rp12XLZkyc3Drftvz9svXUu4RSuS+RnRGbWXbTVM/ohsC2we0S8BSBpO+A/08/00ofXCxx+ODz+eN5RAJsuC7F4cbYNTkhmlq+2yrA+BpxVn4gAImIVcA7w0VIHZluuujpbOLWsLHudPn3TZSHWrMl6SmZmeWqrZxQRmy6plsq9i1hqzfLUUi+oNUuWdE1MZmataatntFDSqc0bJX0GeKJ0IVlnaG9xvEKjPdOgmeWsrZ7RecDvJZ0BzEltFcA2wHGlDsy2TLG9Hc89Z2bdQVtLSCwDqiQdDuybmm+PiHu7JDLbIq3NOzdsGAwe7Go6M+teipko9Y80LqxnPURr885dcomTj5l1P5s3qZl1e1OnZhOejhmTfZd2zBhPgGpm3VcxMzBYD+V558ysp3DPyMzMcpdLMpJ0gqQFaXmKimb7LpK0SNKTko4uaJ+c2hZJurCgfXdJNan9Rklbp/YBaXtR2j+2vWuYmVk+8uoZPQZ8EnigsFHSeOBksuq9ycDPJfVLi/z9DDgGGA+cko4F+D7w44jYE1gJnJnazwRWpvYfp+NavUapbtTMzNqXSzKKiMcj4skWdk0BboiIdRHxHLAIqEw/iyLi2Yh4F7gBmCJJwOHA79LnrwGOLTjXNen974Aj0vGtXcPMzHLS3Z4ZjQBeKNhemtpaax8GvBER65u1NzlX2v9mOr61c21C0jRJdZLqli9fvgW3ZWZmbSlZNZ2ke4BdWtg1IyJuLdV1O1NEzAJmAVRUVHg+PjOzEilZMoqIIzfjY8uAUQXbI1MbrbS/DgyVtFXq/RQeX3+upWltpiHp+LauYWZmOehuw3S3ASenSrjdgXFALTAbGJcq57YmK0C4Lc0qfh9wfPr8acCtBec6Lb0/HvhjOr61a5iZWU5y+dKrpOOAnwDDgT9ImhcRR0fEAkm/ARYC64HzImJD+sz5wJ1AP+CqiFiQTvd14AZJ3wEeBq5M7VcCv5K0CFhBlsBo6xpmZpYPtbBkkbWgoqIi6urq8g7DzKxHkTQnIiraO667DdOZmVkf5GRkZma5czIyM7PcORmZmVnunIzMzCx3TkZmZpY7JyMzM8udk5GZmeXOycjMzHLnZGRmZrlzMuoFqqth7FgoK8teq6vzjsjMrGNymSjVOk91NUybBmvWZNuLF2fbAFOn5heXmVlHuGfUw82Y0ZiI6q1Zk7WbmfUUTkY93JIlHWs3M+uOnIx6uNGjO9ZuZtYdORn1cDNnQnl507by8qzdzKyncDLq4aZOhVmzYMwYkLLXWbNcvGBmPYur6XqBqVOdfMysZ3PPyMzMcudkZGZmuXMyMjOz3DkZmZlZ7pyMujHPOWdmfYWr6bopzzlnZn2Je0bdlOecM7O+xMmom/Kcc2bWlzgZdVOec87M+hIno27Kc86ZWV/iZNRNec45M+tLXE3XjXnOOTPrK9wzMjOz3DkZmZlZ7pyMzMwsd05GZmaWOycjMzPLnZORmZnlzsnIzMxy52RkZma5yyUZSfqhpCckPSrpZklDC/ZdJGmRpCclHV3QPjm1LZJ0YUH77pJqUvuNkrZO7QMVTEqhAAAJpklEQVTS9qK0f2x71zAzs3zk1TO6G9gvIiYATwEXAUgaD5wM7AtMBn4uqZ+kfsDPgGOA8cAp6ViA7wM/jog9gZXAman9TGBlav9xOq7Va5T4fs3MrA25JKOIuCsi1qfNh4CR6f0U4IaIWBcRzwGLgMr0sygino2Id4EbgCmSBBwO/C59/hrg2IJzXZPe/w44Ih3f2jXMzCwn3eGZ0RnAHen9COCFgn1LU1tr7cOANwoSW317k3Ol/W+m41s71yYkTZNUJ6lu+fLlm3VzZmbWvpIlI0n3SHqshZ8pBcfMANYD1aWKY0tExKyIqIiIiuHDh3f489XVMHYslJVlr9Xd8i7NzPJXslm7I+LItvZLOh34GHBERERqXgaMKjhsZGqjlfbXgaGStkq9n8Lj68+1VNJWwJB0fFvX6DTV1TBtWuPS4YsXZ9vgmbjNzJrLq5puMvA14BMRsaZg123AyakSbndgHFALzAbGpcq5rckKEG5LSew+4Pj0+dOAWwvOdVp6fzzwx3R8a9foVDNmNCaiemvWZO1mZtZUXusZ/RQYANyd1RTwUEScHRELJP0GWEg2fHdeRGwAkHQ+cCfQD7gqIhakc30duEHSd4CHgStT+5XAryQtAlaQJTDaukZnWrKkY+1mZn2ZGkfIrC0VFRVRV1dX9PFjx2ZDc82NGQPPP99pYZmZdWuS5kRERXvHdYdqul5p5kwoL2/aVl6etZuZWVNORiUydSrMmpX1hKTsddYsFy+YmbUkr2dGfcLUqU4+ZmbFcM/IzMxy52RkZma5czIyM7PcORmZmVnunIzMzCx3/tJrkSQtB1r4Gis7Aq91cThdwffVs/TG++qN9wR9777GRES7M007GW0hSXXFfLu4p/F99Sy98b564z2B76s1HqYzM7PcORmZmVnunIy23Ky8AygR31fP0hvvqzfeE/i+WuRnRmZmljv3jMzMLHdORmZmljsno04g6duSHpU0T9JdknbLO6bOIOmHkp5I93azpKF5x7SlJJ0gaYGkjZJ6fHmtpMmSnpS0SNKFecfTGSRdJelVSY/lHUtnkjRK0n2SFqb/BqfnHVNnkDRQUq2kR9J9/ftmncfPjLacpO0iYlV6fwEwPiLOzjmsLSbpKOCPEbFe0vcBIuLrOYe1RSTtA2wEfgF8JSKKX763m5HUD3gK+AiwFJgNnBIRC3MNbAtJ+hCwGrg2IvbLO57OImlXYNeImCtpW2AOcGwv+N9LwKCIWC2pP/AXYHpEPNSR87hn1AnqE1EyCOgVGT4i7oqI9WnzIWBknvF0hoh4PCKezDuOTlIJLIqIZyPiXeAGYErOMW2xiHgAWJF3HJ0tIl6KiLnp/VvA48CIfKPacpFZnTb7p58O/w10MuokkmZKegGYCvxb3vGUwBnAHXkHYU2MAF4o2F5KL/jj1hdIGgscBNTkG0nnkNRP0jzgVeDuiOjwfTkZFUnSPZIea+FnCkBEzIiIUUA1cH6+0RavvftKx8wA1pPdW7dXzD2Z5UXSYOAm4IvNRlV6rIjYEBEHko2eVErq8PCqlx0vUkQcWeSh1cDtwMUlDKfTtHdfkk4HPgYcET3kAWMH/rfq6ZYBowq2R6Y266bSM5WbgOqI+H3e8XS2iHhD0n3AZKBDBSjuGXUCSeMKNqcAT+QVS2eSNBn4GvCJiFiTdzy2idnAOEm7S9oaOBm4LeeYrBXpQf+VwOMR8aO84+kskobXV9pK2oasoKbDfwNdTdcJJN0E7EVWpbUYODsievy/UCUtAgYAr6emh3p6laCk44CfAMOBN4B5EXF0vlFtPkkfBf4b6AdcFREzcw5pi0m6HvgHsiUJXgEujogrcw2qE0j6O+DPwHyyvxUA/xIRt+cX1ZaTNAG4huy/wTLgNxHxrQ6fx8nIzMzy5mE6MzPLnZORmZnlzsnIzMxy52RkZma5czIyM7PcORlZnyNpWJphfZ6klyUtS+/fkNSlk1ZKOjCVZ9dvf2JzZ9+W9LykHTsvug5d+/TC2eol/VLS+Lzjsp7Dycj6nIh4PSIOTNOXXA78OL0/kMbvf3QaSW3NdHIg0JCMIuK2iPheZ8fQBU4HGpJRRHy+p89GbV3LycisqX6SrkjrstyVvlGOpPdJ+j9JcyT9WdLeqX2spD+mNZ/ulTQ6tV8t6XJJNcAPJA1K6/TUSnpY0pQ0a8K3gJNSz+yk1MP4aTrHzsrWkXok/Rya2m9JcSyQNK29G5L0OUlPpWtfUXD+qyUdX3Dc6vQ6ON3LXEnz6+f0S/f6ePPfTzpHBVCd7mMbSferhfWiJH0mxTFP0i+UTbDZL8XyWLrel7bgfz/roZyMzJoaB/wsIvYlm6HhU6l9FvCFiJgIfAX4eWr/CXBNREwgm5fw0oJzjQQOjYgvAzPI1oaqBA4Dfkg21f6/ATemntqNzWK5FPhTRBwAHAwsSO1npDgqgAskDWvtZpStofPvwAeBvwPGF/E7WAscFxEHp1j/K01l0+LvJyJ+B9QBU9N9vNNKLPsAJwEfTD3RDWSz3B8IjIiI/SJif+B/iojRehlPlGrW1HMRMS+9nwOMTbMsHwr8tvFvMgPS6weAT6b3vwJ+UHCu30bEhvT+KOATkr6StgcCo9uJ5XDgVMhmRQbeTO0XpGmNIJsodRyNUzY1VwXcHxHLASTdCLy/nesK+K6yRe42ki1LsXPat8nvp51zFToCmAjMTr/HbciWHPhfYA9JPwH+ANzVgXNaL+FkZNbUuoL3G8j+YJYBb6R/zXfE2wXvRdaLaLKwn6SqjpxQ0j8ARwIfiIg1ku4nS2ybYz1pdERSGbB1ap9KNnffxIh4T9LzBddo6fdTdPhkvciLNtkhHQAcDZwNnEi2fpb1IR6mM2tHWnPmOUknQDb7cvrjCfBXstmyIfsj/udWTnMn8IX64S5JB6X2t4BtW/nMvcA56fh+koYAQ4CVKRHtDRzSTvg1wIdTBWF/4ISCfc+T9VQAPkE2bEi6xqspER0GjGnnGu3dR+H9HC9pp3RPO0gakyrtyiLiJuAbZEOS1sc4GZkVZypwpqRHyJ7d1C/U9wXgc5IeBT4LTG/l898m+2P/qKQFaRvgPmB8fQFDs89MBw6TNJ9sSGw88H/AVpIeB75Hthx8qyLiJeCbwN+AB8mWuq53BVmieoRsuLG+J1cNVKTrnkpxywFcDVxeX8DQSiwLyZLNXen3dTewK9kw4P3KVgq9Dtik52S9n2ftNutDlC2WWBERPWY1Yusb3DMyM7PcuWdkZma5c8/IzMxy52RkZma5czIyM7PcORmZmVnunIzMzCx3/x/uSWrC8GOZxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import probplot\n",
    "probplot(grid.predict(X_val) - y_val, plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals do not look normal. Pretty extreme values at either end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only look at gradient boosting models without scaling. Use model based feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-aab8efae57cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m               }\n\u001b[1;32m     17\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_log_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kaggle/kaggle/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/kaggle/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/kaggle/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy=\"median\")),\n",
    "    ('feature_selection', SelectFromModel(RandomForestRegressor(n_estimators=100))),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "param_grid = { 'feature_selection': [SelectFromModel(RandomForestRegressor(n_estimators=100), threshold=0.0001),\n",
    "                                     None],\n",
    "               'regressor': [GradientBoostingRegressor(max_features=0.3),\n",
    "                             XGBRegressor(),\n",
    "                             CatBoostRegressor()],\n",
    "               'regressor__max_depth': [4, 5, 6, 7, 8],\n",
    "              }\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_log_error', return_train_score=False, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_selection': None,\n",
       " 'regressor': <catboost.core.CatBoostRegressor at 0x7fda7c172710>,\n",
       " 'regressor__max_depth': 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor</th>\n",
       "      <th>param_regressor__max_depth</th>\n",
       "      <th>param_feature_selection</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.129885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.130490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.130713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.131792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.132582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.132681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.132855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.132904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.133133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.133167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.133584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.135146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.135386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>0.135398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.135588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.135602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>0.135922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>19</td>\n",
       "      <td>0.136064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.136169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.136578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>22</td>\n",
       "      <td>0.136905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>23</td>\n",
       "      <td>0.137346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.137458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.138048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.138232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.138647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.139950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.142238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>0.142902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      param_regressor  \\\n",
       "26  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "27  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "28  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "15  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "29  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "11  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "16  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "25  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "20  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "5   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "13  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "12  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "0   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "10  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "22  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "7   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "6   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "21  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "18  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "17  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "14  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "24  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "23  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "1   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "8   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "9   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "2   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "3   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "4   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "19  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "\n",
       "   param_regressor__max_depth  \\\n",
       "26                          5   \n",
       "27                          6   \n",
       "28                          7   \n",
       "15                          4   \n",
       "29                          8   \n",
       "11                          5   \n",
       "16                          5   \n",
       "25                          4   \n",
       "20                          4   \n",
       "5                           4   \n",
       "13                          7   \n",
       "12                          6   \n",
       "0                           4   \n",
       "10                          4   \n",
       "22                          6   \n",
       "7                           6   \n",
       "6                           5   \n",
       "21                          5   \n",
       "18                          7   \n",
       "17                          6   \n",
       "14                          8   \n",
       "24                          8   \n",
       "23                          7   \n",
       "1                           5   \n",
       "8                           7   \n",
       "9                           8   \n",
       "2                           6   \n",
       "3                           7   \n",
       "4                           8   \n",
       "19                          8   \n",
       "\n",
       "                              param_feature_selection  rank_test_score  \\\n",
       "26                                               None                1   \n",
       "27                                               None                2   \n",
       "28                                               None                3   \n",
       "15                                               None                4   \n",
       "29                                               None                5   \n",
       "11  SelectFromModel(estimator=RandomForestRegresso...                6   \n",
       "16                                               None                7   \n",
       "25                                               None                8   \n",
       "20                                               None                9   \n",
       "5   SelectFromModel(estimator=RandomForestRegresso...               10   \n",
       "13  SelectFromModel(estimator=RandomForestRegresso...               11   \n",
       "12  SelectFromModel(estimator=RandomForestRegresso...               12   \n",
       "0   SelectFromModel(estimator=RandomForestRegresso...               13   \n",
       "10  SelectFromModel(estimator=RandomForestRegresso...               14   \n",
       "22                                               None               15   \n",
       "7   SelectFromModel(estimator=RandomForestRegresso...               16   \n",
       "6   SelectFromModel(estimator=RandomForestRegresso...               17   \n",
       "21                                               None               18   \n",
       "18                                               None               19   \n",
       "17                                               None               20   \n",
       "14  SelectFromModel(estimator=RandomForestRegresso...               21   \n",
       "24                                               None               22   \n",
       "23                                               None               23   \n",
       "1   SelectFromModel(estimator=RandomForestRegresso...               24   \n",
       "8   SelectFromModel(estimator=RandomForestRegresso...               25   \n",
       "9   SelectFromModel(estimator=RandomForestRegresso...               26   \n",
       "2   SelectFromModel(estimator=RandomForestRegresso...               27   \n",
       "3   SelectFromModel(estimator=RandomForestRegresso...               28   \n",
       "4   SelectFromModel(estimator=RandomForestRegresso...               29   \n",
       "19                                               None               30   \n",
       "\n",
       "       rmsle  \n",
       "26  0.129675  \n",
       "27  0.129885  \n",
       "28  0.130490  \n",
       "15  0.130713  \n",
       "29  0.131792  \n",
       "11  0.132582  \n",
       "16  0.132681  \n",
       "25  0.132855  \n",
       "20  0.132904  \n",
       "5   0.133133  \n",
       "13  0.133167  \n",
       "12  0.133584  \n",
       "0   0.135146  \n",
       "10  0.135386  \n",
       "22  0.135398  \n",
       "7   0.135588  \n",
       "6   0.135602  \n",
       "21  0.135922  \n",
       "18  0.136064  \n",
       "17  0.136169  \n",
       "14  0.136578  \n",
       "24  0.136905  \n",
       "23  0.137346  \n",
       "1   0.137458  \n",
       "8   0.138048  \n",
       "9   0.138232  \n",
       "2   0.138647  \n",
       "3   0.139950  \n",
       "4   0.142238  \n",
       "19  0.142902  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(grid.cv_results_)\n",
    "res['rmsle'] = np.sqrt(-res.mean_test_score)\n",
    "res.loc[:, ['param_regressor', 'param_regressor__max_depth', 'param_feature_selection',\n",
    "            'rank_test_score', 'rmsle']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13669018005793035"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cat boost seems to do well but might do even better if I hadn't one hot encoded the data.\n",
    "* Feature selection seemed to help a little with a low threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/kaggle/kaggle/lib/python3.6/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test.MSSubClass = test.MSSubClass.astype(str)\n",
    "test = pd.get_dummies(test)\n",
    "X_test = test.drop('Id', axis=1).loc[:, df.drop(['SalePrice', 'Id'], axis=1).columns].values\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy=\"median\")),\n",
    "    ('regressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.1, loss='ls', max_depth=4, max_features=0.3,\n",
    "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "              min_impurity_split=None, min_samples_leaf=1,\n",
    "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=100, n_iter_no_change=None, presort='auto',\n",
    "              random_state=None, subsample=1.0, tol=0.0001,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False))\n",
    "])\n",
    "pipe.fit(X,y)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'SalePrice': y_pred}, index=pd.read_csv('data/test.csv').Id).to_csv('output/pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208500, 181500, 223500, ..., 266500, 142125, 147500])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
