{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>11924</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12968</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>91.0</td>\n",
       "      <td>10652</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>279500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10920</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11241</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10791</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13695</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7560</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>101.0</td>\n",
       "      <td>14215</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>RM</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7449</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>139400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9742</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>RM</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4224</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8246</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>110.0</td>\n",
       "      <td>14230</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>98.0</td>\n",
       "      <td>11478</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16321</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6324</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>68500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>1431</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>21930</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>192140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1432</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4928</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1433</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10800</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>64500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1434</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10261</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1435</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>17400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1436</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1437</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1438</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12444</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>394617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1439</td>\n",
       "      <td>20</td>\n",
       "      <td>RM</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7407</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1440</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11584</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1441</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>79.0</td>\n",
       "      <td>11526</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1442</td>\n",
       "      <td>120</td>\n",
       "      <td>RM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4426</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1443</td>\n",
       "      <td>60</td>\n",
       "      <td>FV</td>\n",
       "      <td>85.0</td>\n",
       "      <td>11003</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1444</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8854</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1445</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1446</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>1447</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26142</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1448</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1449</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11767</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1450</td>\n",
       "      <td>180</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1533</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1451</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1452</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9262</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>287090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1453</td>\n",
       "      <td>180</td>\n",
       "      <td>RM</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3675</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1454</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>90.0</td>\n",
       "      <td>17217</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1455</td>\n",
       "      <td>20</td>\n",
       "      <td>FV</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5        6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6        7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7        8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8        9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9       10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "10      11          20       RL         70.0    11200   Pave   NaN      Reg   \n",
       "11      12          60       RL         85.0    11924   Pave   NaN      IR1   \n",
       "12      13          20       RL          NaN    12968   Pave   NaN      IR2   \n",
       "13      14          20       RL         91.0    10652   Pave   NaN      IR1   \n",
       "14      15          20       RL          NaN    10920   Pave   NaN      IR1   \n",
       "15      16          45       RM         51.0     6120   Pave   NaN      Reg   \n",
       "16      17          20       RL          NaN    11241   Pave   NaN      IR1   \n",
       "17      18          90       RL         72.0    10791   Pave   NaN      Reg   \n",
       "18      19          20       RL         66.0    13695   Pave   NaN      Reg   \n",
       "19      20          20       RL         70.0     7560   Pave   NaN      Reg   \n",
       "20      21          60       RL        101.0    14215   Pave   NaN      IR1   \n",
       "21      22          45       RM         57.0     7449   Pave  Grvl      Reg   \n",
       "22      23          20       RL         75.0     9742   Pave   NaN      Reg   \n",
       "23      24         120       RM         44.0     4224   Pave   NaN      Reg   \n",
       "24      25          20       RL          NaN     8246   Pave   NaN      IR1   \n",
       "25      26          20       RL        110.0    14230   Pave   NaN      Reg   \n",
       "26      27          20       RL         60.0     7200   Pave   NaN      Reg   \n",
       "27      28          20       RL         98.0    11478   Pave   NaN      Reg   \n",
       "28      29          20       RL         47.0    16321   Pave   NaN      IR1   \n",
       "29      30          30       RM         60.0     6324   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1430  1431          60       RL         60.0    21930   Pave   NaN      IR3   \n",
       "1431  1432         120       RL          NaN     4928   Pave   NaN      IR1   \n",
       "1432  1433          30       RL         60.0    10800   Pave  Grvl      Reg   \n",
       "1433  1434          60       RL         93.0    10261   Pave   NaN      IR1   \n",
       "1434  1435          20       RL         80.0    17400   Pave   NaN      Reg   \n",
       "1435  1436          20       RL         80.0     8400   Pave   NaN      Reg   \n",
       "1436  1437          20       RL         60.0     9000   Pave   NaN      Reg   \n",
       "1437  1438          20       RL         96.0    12444   Pave   NaN      Reg   \n",
       "1438  1439          20       RM         90.0     7407   Pave   NaN      Reg   \n",
       "1439  1440          60       RL         80.0    11584   Pave   NaN      Reg   \n",
       "1440  1441          70       RL         79.0    11526   Pave   NaN      IR1   \n",
       "1441  1442         120       RM          NaN     4426   Pave   NaN      Reg   \n",
       "1442  1443          60       FV         85.0    11003   Pave   NaN      Reg   \n",
       "1443  1444          30       RL          NaN     8854   Pave   NaN      Reg   \n",
       "1444  1445          20       RL         63.0     8500   Pave   NaN      Reg   \n",
       "1445  1446          85       RL         70.0     8400   Pave   NaN      Reg   \n",
       "1446  1447          20       RL          NaN    26142   Pave   NaN      IR1   \n",
       "1447  1448          60       RL         80.0    10000   Pave   NaN      Reg   \n",
       "1448  1449          50       RL         70.0    11767   Pave   NaN      Reg   \n",
       "1449  1450         180       RM         21.0     1533   Pave   NaN      Reg   \n",
       "1450  1451          90       RL         60.0     9000   Pave   NaN      Reg   \n",
       "1451  1452          20       RL         78.0     9262   Pave   NaN      Reg   \n",
       "1452  1453         180       RM         35.0     3675   Pave   NaN      Reg   \n",
       "1453  1454          20       RL         90.0    17217   Pave   NaN      Reg   \n",
       "1454  1455          20       FV         62.0     7500   Pave  Pave      Reg   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities    ...     PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "2            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "3            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "4            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "5            Lvl    AllPub    ...            0    NaN  MnPrv        Shed   \n",
       "6            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "7            Lvl    AllPub    ...            0    NaN    NaN        Shed   \n",
       "8            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "9            Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "10           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "11           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "12           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "13           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "14           Lvl    AllPub    ...            0    NaN   GdWo         NaN   \n",
       "15           Lvl    AllPub    ...            0    NaN  GdPrv         NaN   \n",
       "16           Lvl    AllPub    ...            0    NaN    NaN        Shed   \n",
       "17           Lvl    AllPub    ...            0    NaN    NaN        Shed   \n",
       "18           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "19           Lvl    AllPub    ...            0    NaN  MnPrv         NaN   \n",
       "20           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "21           Bnk    AllPub    ...            0    NaN  GdPrv         NaN   \n",
       "22           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "23           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "24           Lvl    AllPub    ...            0    NaN  MnPrv         NaN   \n",
       "25           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "26           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "27           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "28           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "29           Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "...          ...       ...    ...          ...    ...    ...         ...   \n",
       "1430         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1431         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1432         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1433         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1434         Low    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1435         Lvl    AllPub    ...            0    NaN  GdPrv         NaN   \n",
       "1436         Lvl    AllPub    ...            0    NaN   GdWo         NaN   \n",
       "1437         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1438         Lvl    AllPub    ...            0    NaN  MnPrv         NaN   \n",
       "1439         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1440         Bnk    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1441         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1442         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1443         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1444         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1445         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1446         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1447         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1448         Lvl    AllPub    ...            0    NaN   GdWo         NaN   \n",
       "1449         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1450         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1451         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1452         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1453         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1454         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1455         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1456         Lvl    AllPub    ...            0    NaN  MnPrv         NaN   \n",
       "1457         Lvl    AllPub    ...            0    NaN  GdPrv        Shed   \n",
       "1458         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "1459         Lvl    AllPub    ...            0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0          0      2   2008        WD         Normal     208500  \n",
       "1          0      5   2007        WD         Normal     181500  \n",
       "2          0      9   2008        WD         Normal     223500  \n",
       "3          0      2   2006        WD        Abnorml     140000  \n",
       "4          0     12   2008        WD         Normal     250000  \n",
       "5        700     10   2009        WD         Normal     143000  \n",
       "6          0      8   2007        WD         Normal     307000  \n",
       "7        350     11   2009        WD         Normal     200000  \n",
       "8          0      4   2008        WD        Abnorml     129900  \n",
       "9          0      1   2008        WD         Normal     118000  \n",
       "10         0      2   2008        WD         Normal     129500  \n",
       "11         0      7   2006       New        Partial     345000  \n",
       "12         0      9   2008        WD         Normal     144000  \n",
       "13         0      8   2007       New        Partial     279500  \n",
       "14         0      5   2008        WD         Normal     157000  \n",
       "15         0      7   2007        WD         Normal     132000  \n",
       "16       700      3   2010        WD         Normal     149000  \n",
       "17       500     10   2006        WD         Normal      90000  \n",
       "18         0      6   2008        WD         Normal     159000  \n",
       "19         0      5   2009       COD        Abnorml     139000  \n",
       "20         0     11   2006       New        Partial     325300  \n",
       "21         0      6   2007        WD         Normal     139400  \n",
       "22         0      9   2008        WD         Normal     230000  \n",
       "23         0      6   2007        WD         Normal     129900  \n",
       "24         0      5   2010        WD         Normal     154000  \n",
       "25         0      7   2009        WD         Normal     256300  \n",
       "26         0      5   2010        WD         Normal     134800  \n",
       "27         0      5   2010        WD         Normal     306000  \n",
       "28         0     12   2006        WD         Normal     207500  \n",
       "29         0      5   2008        WD         Normal      68500  \n",
       "...      ...    ...    ...       ...            ...        ...  \n",
       "1430       0      7   2006        WD         Normal     192140  \n",
       "1431       0     10   2009        WD         Normal     143750  \n",
       "1432       0      8   2007        WD         Normal      64500  \n",
       "1433       0      5   2008        WD         Normal     186500  \n",
       "1434       0      5   2006        WD         Normal     160000  \n",
       "1435       0      7   2008       COD        Abnorml     174000  \n",
       "1436       0      5   2007        WD         Normal     120500  \n",
       "1437       0     11   2008       New        Partial     394617  \n",
       "1438       0      4   2010        WD         Normal     149700  \n",
       "1439       0     11   2007        WD         Normal     197000  \n",
       "1440       0      9   2008        WD         Normal     191000  \n",
       "1441       0      5   2008        WD         Normal     149300  \n",
       "1442       0      4   2009        WD         Normal     310000  \n",
       "1443       0      5   2009        WD         Normal     121000  \n",
       "1444       0     11   2007        WD         Normal     179600  \n",
       "1445       0      5   2007        WD         Normal     129000  \n",
       "1446       0      4   2010        WD         Normal     157900  \n",
       "1447       0     12   2007        WD         Normal     240000  \n",
       "1448       0      5   2007        WD         Normal     112000  \n",
       "1449       0      8   2006        WD        Abnorml      92000  \n",
       "1450       0      9   2009        WD         Normal     136000  \n",
       "1451       0      5   2009       New        Partial     287090  \n",
       "1452       0      5   2006        WD         Normal     145000  \n",
       "1453       0      7   2006        WD        Abnorml      84500  \n",
       "1454       0     10   2009        WD         Normal     185000  \n",
       "1455       0      8   2007        WD         Normal     175000  \n",
       "1456       0      2   2010        WD         Normal     210000  \n",
       "1457    2500      5   2010        WD         Normal     266500  \n",
       "1458       0      4   2010        WD         Normal     142125  \n",
       "1459       0      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
       "\n",
       "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
       "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
       "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
       "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
       "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "           SalePrice  \n",
       "count    1460.000000  \n",
       "mean   180921.195890  \n",
       "std     79442.502883  \n",
       "min     34900.000000  \n",
       "25%    129975.000000  \n",
       "50%    163000.000000  \n",
       "75%    214000.000000  \n",
       "max    755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lots of text fields that will need to be encoded (maybe try catboost)\n",
    "* Lots of missing values, especially in categoricals\n",
    "* Some in numerical values that I should try to impute\n",
    "* Medium number of features and not that much data (should try some simple models)\n",
    "* May want to bucket some of the numerical features like year built'\n",
    "* MSSubClass is actually a categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MSSubClass = df.MSSubClass.astype(str)\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['SalePrice', 'Id'], axis=1).values\n",
    "y = df.SalePrice.values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>1201.0</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>21.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>1452.0</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>1379.0</td>\n",
       "      <td>1978.506164</td>\n",
       "      <td>24.689725</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min     25%     50%     75%  \\\n",
       "LotFrontage  1201.0    70.049958   24.284752    21.0    59.0    69.0    80.0   \n",
       "MasVnrArea   1452.0   103.685262  181.066207     0.0     0.0     0.0   166.0   \n",
       "GarageYrBlt  1379.0  1978.506164   24.689725  1900.0  1961.0  1980.0  2002.0   \n",
       "\n",
       "                max  \n",
       "LotFrontage   313.0  \n",
       "MasVnrArea   1600.0  \n",
       "GarageYrBlt  2010.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose().loc[lambda x: x['count'] != 1460]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After getting dummy variables there are 304 features which is likely too many for OLS\n",
    "* Will need to use some kind of feature selection or regularization\n",
    "* Still a few missing values to impute\n",
    "* Try a simple pipeline with regression, random forest, gboosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbose=0)), ('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('regressor', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'scaler': [MinMaxScaler(copy=True, feature_range=(0, 1)), None], 'regressor': [RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=0.3, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_l...  normalize=False, random_state=None, solver='auto', tol=0.001)], 'regressor__alpha': [0.1, 1, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy=\"median\")),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "param_grid = [{'scaler': [MinMaxScaler(), None],\n",
    "               'regressor': [RandomForestRegressor(n_estimators=100)],\n",
    "               'regressor__min_samples_split': [5, 10],\n",
    "               'regressor__max_features': ['sqrt', 'log2', 0.3],\n",
    "              },\n",
    "              {'scaler': [MinMaxScaler(), None],\n",
    "               'regressor': [GradientBoostingRegressor()],\n",
    "               'regressor__max_depth': [2, 3, 4, 5, 6],\n",
    "               'regressor__max_features': ['sqrt', 'log2', 0.3],\n",
    "              },\n",
    "              {'scaler': [MinMaxScaler(), None],\n",
    "               'regressor': [Ridge()],\n",
    "               'regressor__alpha': [0.1, 1, 10]}\n",
    "             ]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_log_error', return_train_score=False)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor</th>\n",
       "      <th>param_regressor__max_features</th>\n",
       "      <th>param_regressor__max_depth</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>2</td>\n",
       "      <td>0.131544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.131551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.131859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>5</td>\n",
       "      <td>0.132377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.132657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.132780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>8</td>\n",
       "      <td>0.133133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>9</td>\n",
       "      <td>0.134031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>10</td>\n",
       "      <td>0.134229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>0.134343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>12</td>\n",
       "      <td>0.135011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>0.135319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>14</td>\n",
       "      <td>0.136018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>15</td>\n",
       "      <td>0.136561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>16</td>\n",
       "      <td>0.137086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>0.138617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>0.138686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>19</td>\n",
       "      <td>0.139105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.139503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>21</td>\n",
       "      <td>0.139706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>22</td>\n",
       "      <td>0.140445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>23</td>\n",
       "      <td>0.142503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>24</td>\n",
       "      <td>0.142875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>25</td>\n",
       "      <td>0.143432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>26</td>\n",
       "      <td>0.145777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>27</td>\n",
       "      <td>0.146307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>0.146378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>29</td>\n",
       "      <td>0.146905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>30</td>\n",
       "      <td>0.147415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>31</td>\n",
       "      <td>0.147501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>0.149226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>33</td>\n",
       "      <td>0.149596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>34</td>\n",
       "      <td>0.151845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>35</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>0.153178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>37</td>\n",
       "      <td>0.153738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>38</td>\n",
       "      <td>0.157080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>39</td>\n",
       "      <td>0.157506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>0.157803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>0.160481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>42</td>\n",
       "      <td>0.162953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>43</td>\n",
       "      <td>0.164783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>44</td>\n",
       "      <td>0.165094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>0.170170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>46</td>\n",
       "      <td>0.171267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>47</td>\n",
       "      <td>0.182045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ridge(alpha=10, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48</td>\n",
       "      <td>0.185133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      param_regressor  \\\n",
       "29  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "28  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "35  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "31  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "24  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "25  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "23  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "34  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "30  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "46  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "41  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "22  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "37  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "18  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "36  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "40  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "39  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "33  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "47  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "19  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "17  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "38  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "27  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "16  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "32  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "26  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "8   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "9   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "11  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "10  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "20  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "13  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "21  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "12  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "44  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "1   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "0   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "3   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "2   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "45  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "15  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "14  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "4   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "5   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "7   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "6   (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "42  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "43  Ridge(alpha=10, copy_X=True, fit_intercept=Tru...   \n",
       "\n",
       "   param_regressor__max_features param_regressor__max_depth  \\\n",
       "29                           0.3                          4   \n",
       "28                           0.3                          4   \n",
       "35                           0.3                          5   \n",
       "31                          sqrt                          5   \n",
       "24                          sqrt                          4   \n",
       "25                          sqrt                          4   \n",
       "23                           0.3                          3   \n",
       "34                           0.3                          5   \n",
       "30                          sqrt                          5   \n",
       "46                           NaN                        NaN   \n",
       "41                           0.3                          6   \n",
       "22                           0.3                          3   \n",
       "37                          sqrt                          6   \n",
       "18                          sqrt                          3   \n",
       "36                          sqrt                          6   \n",
       "40                           0.3                          6   \n",
       "39                          log2                          6   \n",
       "33                          log2                          5   \n",
       "47                           NaN                        NaN   \n",
       "19                          sqrt                          3   \n",
       "17                           0.3                          2   \n",
       "38                          log2                          6   \n",
       "27                          log2                          4   \n",
       "16                           0.3                          2   \n",
       "32                          log2                          5   \n",
       "26                          log2                          4   \n",
       "8                            0.3                        NaN   \n",
       "9                            0.3                        NaN   \n",
       "11                           0.3                        NaN   \n",
       "10                           0.3                        NaN   \n",
       "20                          log2                          3   \n",
       "13                          sqrt                          2   \n",
       "21                          log2                          3   \n",
       "12                          sqrt                          2   \n",
       "44                           NaN                        NaN   \n",
       "1                           sqrt                        NaN   \n",
       "0                           sqrt                        NaN   \n",
       "3                           sqrt                        NaN   \n",
       "2                           sqrt                        NaN   \n",
       "45                           NaN                        NaN   \n",
       "15                          log2                          2   \n",
       "14                          log2                          2   \n",
       "4                           log2                        NaN   \n",
       "5                           log2                        NaN   \n",
       "7                           log2                        NaN   \n",
       "6                           log2                        NaN   \n",
       "42                           NaN                        NaN   \n",
       "43                           NaN                        NaN   \n",
       "\n",
       "                                     param_scaler  rank_test_score     rmsle  \n",
       "29                                           None                1  0.131405  \n",
       "28  MinMaxScaler(copy=True, feature_range=(0, 1))                2  0.131544  \n",
       "35                                           None                3  0.131551  \n",
       "31                                           None                4  0.131859  \n",
       "24  MinMaxScaler(copy=True, feature_range=(0, 1))                5  0.132377  \n",
       "25                                           None                6  0.132657  \n",
       "23                                           None                7  0.132780  \n",
       "34  MinMaxScaler(copy=True, feature_range=(0, 1))                8  0.133133  \n",
       "30  MinMaxScaler(copy=True, feature_range=(0, 1))                9  0.134031  \n",
       "46  MinMaxScaler(copy=True, feature_range=(0, 1))               10  0.134229  \n",
       "41                                           None               11  0.134343  \n",
       "22  MinMaxScaler(copy=True, feature_range=(0, 1))               12  0.135011  \n",
       "37                                           None               13  0.135319  \n",
       "18  MinMaxScaler(copy=True, feature_range=(0, 1))               14  0.136018  \n",
       "36  MinMaxScaler(copy=True, feature_range=(0, 1))               15  0.136561  \n",
       "40  MinMaxScaler(copy=True, feature_range=(0, 1))               16  0.137086  \n",
       "39                                           None               17  0.138617  \n",
       "33                                           None               18  0.138686  \n",
       "47                                           None               19  0.139105  \n",
       "19                                           None               20  0.139503  \n",
       "17                                           None               21  0.139706  \n",
       "38  MinMaxScaler(copy=True, feature_range=(0, 1))               22  0.140445  \n",
       "27                                           None               23  0.142503  \n",
       "16  MinMaxScaler(copy=True, feature_range=(0, 1))               24  0.142875  \n",
       "32  MinMaxScaler(copy=True, feature_range=(0, 1))               25  0.143432  \n",
       "26  MinMaxScaler(copy=True, feature_range=(0, 1))               26  0.145777  \n",
       "8   MinMaxScaler(copy=True, feature_range=(0, 1))               27  0.146307  \n",
       "9                                            None               28  0.146378  \n",
       "11                                           None               29  0.146905  \n",
       "10  MinMaxScaler(copy=True, feature_range=(0, 1))               30  0.147415  \n",
       "20  MinMaxScaler(copy=True, feature_range=(0, 1))               31  0.147501  \n",
       "13                                           None               32  0.149226  \n",
       "21                                           None               33  0.149596  \n",
       "12  MinMaxScaler(copy=True, feature_range=(0, 1))               34  0.151845  \n",
       "44  MinMaxScaler(copy=True, feature_range=(0, 1))               35  0.152174  \n",
       "1                                            None               36  0.153178  \n",
       "0   MinMaxScaler(copy=True, feature_range=(0, 1))               37  0.153738  \n",
       "3                                            None               38  0.157080  \n",
       "2   MinMaxScaler(copy=True, feature_range=(0, 1))               39  0.157506  \n",
       "45                                           None               40  0.157803  \n",
       "15                                           None               41  0.160481  \n",
       "14  MinMaxScaler(copy=True, feature_range=(0, 1))               42  0.162953  \n",
       "4   MinMaxScaler(copy=True, feature_range=(0, 1))               43  0.164783  \n",
       "5                                            None               44  0.165094  \n",
       "7                                            None               45  0.170170  \n",
       "6   MinMaxScaler(copy=True, feature_range=(0, 1))               46  0.171267  \n",
       "42  MinMaxScaler(copy=True, feature_range=(0, 1))               47  0.182045  \n",
       "43                                           None               48  0.185133  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(grid.cv_results_)\n",
    "res['rmsle'] = np.sqrt(-res.mean_test_score)\n",
    "res.loc[:, ['param_regressor', 'param_regressor__max_features', 'param_regressor__max_depth',\n",
    "            'param_scaler', 'rank_test_score', 'rmsle']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor': GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='ls', max_depth=4, max_features=0.3,\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "              random_state=None, subsample=1.0, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'regressor__max_depth': 4,\n",
       " 'regressor__max_features': 0.3,\n",
       " 'scaler': None}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ridge regression is able to do alright despite the lack of feature engineering\n",
    "* Gradient Boosting does well should try others like xgboost and catboost\n",
    "* Should probably look at the data to reduce the feature space.\n",
    "* Should also look at residuals to seem if fit is reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverallQual             0.146196\n",
       "GrLivArea               0.136011\n",
       "GarageCars              0.090377\n",
       "GarageArea              0.075258\n",
       "TotalBsmtSF             0.074963\n",
       "ExterQual_TA            0.065781\n",
       "YearBuilt               0.053677\n",
       "GarageYrBlt             0.051217\n",
       "1stFlrSF                0.050114\n",
       "BsmtFinSF1              0.030762\n",
       "FullBath                0.027542\n",
       "TotRmsAbvGrd            0.019707\n",
       "Fireplaces              0.019049\n",
       "LotArea                 0.018337\n",
       "2ndFlrSF                0.012379\n",
       "MSSubClass_60           0.012192\n",
       "YearRemodAdd            0.011946\n",
       "BsmtQual_Ex             0.009816\n",
       "KitchenQual_Ex          0.006863\n",
       "MasVnrArea              0.006381\n",
       "OverallCond             0.006157\n",
       "BsmtUnfSF               0.005641\n",
       "ExterQual_Gd            0.003626\n",
       "CentralAir_Y            0.003075\n",
       "WoodDeckSF              0.002991\n",
       "MoSold                  0.002968\n",
       "LotFrontage             0.002802\n",
       "Neighborhood_Crawfor    0.002758\n",
       "Exterior1st_HdBoard     0.002323\n",
       "BsmtFullBath            0.002103\n",
       "                          ...   \n",
       "Condition2_Artery       0.000000\n",
       "Condition1_RRNn         0.000000\n",
       "Condition1_RRNe         0.000000\n",
       "Condition1_RRAn         0.000000\n",
       "Neighborhood_SawyerW    0.000000\n",
       "Neighborhood_Sawyer     0.000000\n",
       "GarageQual_Ex           0.000000\n",
       "Neighborhood_NPkVill    0.000000\n",
       "BldgType_TwnhsE         0.000000\n",
       "GarageType_CarPort      0.000000\n",
       "Exterior1st_Wd Sdng     0.000000\n",
       "HouseStyle_2.5Fin       0.000000\n",
       "Exterior1st_Stucco      0.000000\n",
       "Exterior1st_Stone       0.000000\n",
       "Exterior1st_MetalSd     0.000000\n",
       "Exterior1st_ImStucc     0.000000\n",
       "GarageType_2Types       0.000000\n",
       "GarageType_BuiltIn      0.000000\n",
       "Exterior1st_BrkComm     0.000000\n",
       "Exterior1st_AsphShn     0.000000\n",
       "RoofMatl_Tar&Grv        0.000000\n",
       "RoofMatl_Roll           0.000000\n",
       "RoofMatl_Metal          0.000000\n",
       "RoofMatl_Membran        0.000000\n",
       "RoofMatl_ClyTile        0.000000\n",
       "RoofStyle_Shed          0.000000\n",
       "RoofStyle_Gambrel       0.000000\n",
       "HouseStyle_SFoyer       0.000000\n",
       "HouseStyle_2.5Unf       0.000000\n",
       "Exterior1st_CBlock      0.000000\n",
       "Length: 302, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(grid.best_estimator_.named_steps.regressor.feature_importances_,\n",
    "          index=df.drop(['SalePrice', 'Id'], axis=1).columns.values).sort_values()[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12271354782825208"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd18a2293c8>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_val, grid.predict(X_val) - y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEf1JREFUeJzt3X+MZWV9x/H3t0xRZFp2F+i4WWh3idQW2TRxJxZDNTNiWgRbMLUWQuyiNJvUHzWKqUv5QxPTBLTUYtpot0K7bYgD/ioEtBa3jMY0YHcVXX6WEVdlsixqYduxxHbjt3/cZ/Xu+NyZ4Z57z8zF9yu5mXOe8+P53rPnzGfOOfeejcxEkqTFfma1C5AkrU0GhCSpyoCQJFUZEJKkKgNCklRlQEiSqgwISVKVASFJqjIgJElVY6tdAMApp5ySmzdvXna+73//+5x44onDL2gIRrV2626Xdbdr1Ovet2/fdzPz1KF1lJmr/tq2bVuuxF133bWi+daiUa3duttl3e0a9bqBvTnE381eYpIkVRkQkqQqA0KSVGVASJKqDAhJUtWyARERN0bEExFxX1fbhoi4MyIeKT/Xl/aIiA9GxFxEfC0iXjzM4iVJw7OSM4i/B85f1LYT2JOZZwJ7yjjAq4Azy2sH8KHBlClJatuyAZGZXwD+c1HzRcDuMrwbuLir/R/KR3XvBtZFxMZBFStJak+/9yAmMvNgGX4cmCjDm4Bvd833WGmTJI2Y6HwZb5mZIjYDt2fm2WX8qcxc1zX9ycxcHxG3A9dk5hdL+x7gXZm5t7LOHXQuQzExMbFtZmZm2ToWFhYYHx9fyftac0a1dusevP3zh3tOmzgBDj3dGd666aSWKmpuLW/vpYx63dPT0/syc3JY/fT7LKZDEbExMw+WS0hPlPZ54PSu+U4rbT8hM3cBuwAmJydzampq2U5nZ2dZyXxr0ajWbt2Dd/nOO3pOu3LrEa7b3zksD1w21VJFza3l7b0U615av5eYbgO2l+HtwK1d7X9QPs10DnC461KUJGmELHsGEREfBaaAUyLiMeDdwDXALRFxBfBN4HVl9k8DFwBzwP8AbxhCzZKkFiwbEJl5aY9J51XmTeDNTYuSJK0+v0ktSaoyICRJVQaEJKnKgJAkVRkQkqQqA0KSVGVASJKqDAhJUpUBIUmqMiAkSVUGhCSpyoCQJFUZEJKkKgNCklRlQEiSqgwISVKVASFJqjIgJElVBoQkqcqAkCRVGRCSpCoDQpJUZUBIkqoMCElSlQEhSaoyICRJVQaEJKnKgJAkVRkQkqQqA0KSVGVASJKqDAhJUlWjgIiIt0fE/RFxX0R8NCKeGxFbIuKeiJiLiJsj4vhBFStJak/fARERm4A/BiYz82zgOOAS4FrgA5n5AuBJ4IpBFCpJalfTS0xjwAkRMQY8DzgIvAL4eJm+G7i4YR+SpFXQd0Bk5jzw58C36ATDYWAf8FRmHimzPQZsalqkJKl9kZn9LRixHvgE8PvAU8DH6Jw5vKdcXiIiTgc+Uy5BLV5+B7ADYGJiYtvMzMyyfS4sLDA+Pt5XvattVGu37sHbP3+457SJE+DQ053hrZtOaqmi5tby9l7KqNc9PT29LzMnh9XPWINlXwl8IzO/AxARnwTOBdZFxFg5izgNmK8tnJm7gF0Ak5OTOTU1tWyHs7OzrGS+tWhUa7fuwbt85x09p1259QjX7e8clgcum2qpoubW8vZeinUvrck9iG8B50TE8yIigPOAB4C7gNeWebYDtzYrUZK0Gprcg7iHziWlLwP7y7p2Ae8C3hERc8DJwA0DqFOS1LIml5jIzHcD717U/CjwkibrlSStPr9JLUmqMiAkSVUGhCSpyoCQJFUZEJKkKgNCklRlQEiSqgwISVKVASFJqjIgJElVBoQkqcqAkCRVGRCSpCoDQpJUZUBIkqoMCElSlQEhSaoyICRJVQaEJKnKgJAkVRkQkqQqA0KSVGVASJKqDAhJUpUBIUmqMiAkSVUGhCSpyoCQJFUZEJKkKgNCklRlQEiSqgwISVKVASFJqmoUEBGxLiI+HhEPRcSDEfHSiNgQEXdGxCPl5/pBFStJak/TM4jrgX/OzF8Bfg14ENgJ7MnMM4E9ZVySNGL6DoiIOAl4OXADQGb+b2Y+BVwE7C6z7QYublqkJKl9Tc4gtgDfAf4uIr4SER+JiBOBicw8WOZ5HJhoWqQkqX2Rmf0tGDEJ3A2cm5n3RMT1wH8Bb83MdV3zPZmZP3EfIiJ2ADsAJiYmts3MzCzb58LCAuPj433Vu9pGtXbrHrz984d7Tps4AQ493Rneuumklipqbi1v76WMet3T09P7MnNyWP00CYjnA3dn5uYy/jI69xteAExl5sGI2AjMZuYLl1rX5ORk7t27d9k+Z2dnmZqa6qve1TaqtVv34G3eeUfPaVduPcJ1+8cAOHDNhW2V1Nha3t5LGfW6I2KoAdH3JabMfBz4dkQc/eV/HvAAcBuwvbRtB25tVKEkaVWMNVz+rcBNEXE88CjwBjqhc0tEXAF8E3hdwz4kSaugUUBk5r1A7fTmvCbrlbT0pahuo3QpSqPFb1JLkqoMCElSlQEhSaoyICRJVQaEJKmq6cdcJRUr/dSRNCo8g5AkVRkQkqQqA0KSVGVASJKqDAhJUpUBIUmqMiAkSVUGhCSpyoCQJFUZEJKkKgNCklRlQEiSqgwISVKVASFJqjIgJElVBoQkqcqAkCRVGRCSpCoDQpJUZUBIkqoMCElSlQEhSaoyICRJVQaEJKnKgJAkVRkQkqSqxgEREcdFxFci4vYyviUi7omIuYi4OSKOb16mJKltgziDeBvwYNf4tcAHMvMFwJPAFQPoQ5LUskYBERGnARcCHynjAbwC+HiZZTdwcZM+JEmro+kZxF8CfwL8sIyfDDyVmUfK+GPApoZ9SJJWQWRmfwtGvBq4IDPfFBFTwDuBy4G7y+UlIuJ04DOZeXZl+R3ADoCJiYltMzMzy/a5sLDA+Ph4X/WutlGt3bpXbv/84cbrmDgBDj39zJbZuumkxv025X7SrqN1T09P78vMyWH1M9Zg2XOB34mIC4DnAj8PXA+si4ixchZxGjBfWzgzdwG7ACYnJ3NqamrZDmdnZ1nJfGvRqNZu3St3+c47Gq/jyq1HuG7/MzssD1w21bjfptxP2tVW3X1fYsrMqzLztMzcDFwC/GtmXgbcBby2zLYduLVxlZKk1g3jexDvAt4REXN07kncMIQ+JElD1uQS049k5iwwW4YfBV4yiPVKklaP36SWJFUZEJKkKgNCklRlQEiSqgwISVKVASFJqjIgJElVBoQkqcqAkCRVGRCSpCoDQpJUZUBIkqoMCElSlQEhSaoyICRJVQaEJKnKgJAkVRkQkqQqA0KSVGVASJKqDAhJUpUBIUmqMiAkSVUGhCSpamy1C5DUzOadd6xovgPXXDjkSvRs4xmEJKnKgJAkVRkQkqQqA0KSVGVASJKqDAhJUpUBIUmqMiAkSVV9B0REnB4Rd0XEAxFxf0S8rbRviIg7I+KR8nP94MqVJLWlyRnEEeDKzDwLOAd4c0ScBewE9mTmmcCeMi5JGjF9B0RmHszML5fh/wYeBDYBFwG7y2y7gYubFilJal9kZvOVRGwGvgCcDXwrM9eV9gCePDq+aJkdwA6AiYmJbTMzM8v2s7CwwPj4eON6V8Oo1m7dK7d//nDjdUycAIeeHkAxFVs3nTScFeN+0rajdU9PT+/LzMlh9dM4ICJiHPg88GeZ+cmIeKo7ECLiycxc8j7E5ORk7t27d9m+ZmdnmZqaalTvahnV2q175Vb60LylXLn1CNftH84zNIf5sD73k3YdrTsihhoQjT7FFBE/C3wCuCkzP1maD0XExjJ9I/BEsxIlSauhyaeYArgBeDAz/6Jr0m3A9jK8Hbi1//IkSaulybnsucDrgf0RcW9p+1PgGuCWiLgC+CbwumYlSpJWQ98BkZlfBKLH5PP6Xa8kaW3wm9SSpCoDQpJUZUBIkqqG84Fr6VliEN9tkEaVZxCSpCoDQpJUZUBIkqoMCElSlQEhSaryU0zST4mVfiJrmE991WjxDEKSVGVASJKqDAhJUpUBIUmqMiAkSVUGhCSpyoCQJFUZEJKkKgNCklRlQEiSqgwISVKVASFJqjIgJElVPs1VP5X8v6al5XkGIUmqMiAkSVUGhCSpyoCQJFV5k1rSMfyvSXWUZxCSpCrPICT1pftM48qtR7h8iTMPzzZGk2cQkqSqoZxBRMT5wPXAccBHMvOaYfQjLXb0r9rl/qLV2uT9j7Vl4GcQEXEc8NfAq4CzgEsj4qxB9yNJGq5hnEG8BJjLzEcBImIGuAh4YAh9DeUvjmfLXzHPlvcBPhpj1K31fz9/j9QN4x7EJuDbXeOPlTZJ0giJzBzsCiNeC5yfmX9Yxl8P/HpmvmXRfDuAHWX0hcDDK1j9KcB3B1hum0a1dutul3W3a9Tr/qXMPHVYnQzjEtM8cHrX+Gml7RiZuQvY9UxWHBF7M3OyWXmrY1Rrt+52WXe7rHtpw7jE9O/AmRGxJSKOBy4BbhtCP5KkIRr4GURmHomItwCfpfMx1xsz8/5B9yNJGq6hfA8iMz8NfHoIq35Gl6TWmFGt3brbZd3tsu4lDPwmtSTp2cFHbUiSqloPiIh4f0Q8FBFfi4hPRcS6rmlXRcRcRDwcEb/V1X5+aZuLiJ1d7Vsi4p7SfnO5KU5EPKeMz5Xpm5frY4W1/15E3B8RP4yIya72zRHxdETcW14f7pq2LSL2lz4/GBFR2jdExJ0R8Uj5ub60R5lvrmyjF3eta3uZ/5GI2N607qW2x1rZ5l3reE9EzHdt4wvafA/D1qvWtkXEgbK/3hsRe0vbwPbVXsdDn7XeGBFPRMR9XW1Dr7VXHw3rXpv7d2a2+gJ+Exgrw9cC15bhs4CvAs8BtgBfp3OT+7gyfAZwfJnnrLLMLcAlZfjDwB+V4TcBHy7DlwA3L9XHM6j9V+l8Z2MWmOxq3wzc12OZLwHnAAF8BnhVaX8fsLMM7+zaDheU+aIsd09p3wA8Wn6uL8PrG9a95rd5V63vAd5ZaR/6e2jhmOhZ6yocnweAUxa1DWxf7XU89Fnry4EX03XstVFrrz4a1r0m9+/Wd8BFb/41wE1l+Crgqq5pnwVeWl6f7Wq/qryCzhdFjobNj+Y7umwZHivzRa8++qh7lhUEBLAReKhr/FLgb8rww8DGrvkeLsN/A1zatczDZfqPlq3N12fdo7TNex1AQ38PLRwH1VqH3W+PWg7wkwExkH11qeOhQb3HHHtt1Nqrj4Z1r8n9e7XvQbyRTjJD70d09Go/GXgqM48saj9mXWX64TL/MB8DsiUivhIRn4+Il3XV8ViP/iYy82AZfhyYWFz7omWGUfuobfO3lMsDN3ad1rfxHoZtLT2eJoF/iYh90XnaAQxuX13qeBiUNmrt1UdTa27/Htbjvj8HPL8y6erMvLXMczVwBLhpGDX0ayW1VxwEfjEzvxcR24B/iogXrbTPzMyIaPRxsj7rXlOWeg/Ah4D30vkF9l7gOjp/YGiwfiMz5yPiF4A7I+Kh7omD2Ffb0katA+xjTe7fw/oexCuXmh4RlwOvBs7Lcr7D0o/oqLV/D1gXEWMlDbvnP7quxyJiDDipzL/sY0CWq70mM38A/KAM74uIrwO/XNZ9Wo/+DkXExsw8GBEbgScW1b54mXlgalH7bJO6l+iLHu1D2ebP9D1ExN8Ct7f4HoZtxdto2DJzvvx8IiI+RefpzIPaV5c6HgaljVp79dG3zDx0dHhN7d9Nrv/1ec3wfDqP/j51UfuLOPZmzKN0bsSMleEt/PhmzIvKMh/j2JsxbyrDb+bYmzG3LNVHH+9hlmOv5Z96dD10bhrNAxvK+OIbXReU9vdz7I2u95XhCzn2ZtqXSvsG4Bt0bqStL8MbGtY9Stt8Y9fw24GZtt5DC8dEz1pbPjZPBH6ua/jf6ByvA9tXex0PDWrezLHX8odea68+Gta9JvfvVnfAUtgcnetg95bXh7umXU3nzvzDdH26gc4nEP6jTLu6q/2M8o84VzbKc0r7c8v4XJl+xnJ9rLD219C5pvcD4BA/vvnzu8D95f18GfjtrmUmgftKn3/Fj7+ceDKwB3gE+FzXThl0/sOlrwP7OfYX+hvLe5oD3tC07lHY5l3r+MeyPb5G59leG9t8Dy0cF9VaWz42z6Dzi+arZX++etD7aq/joc96P0rn8u7/lf37ijZq7dVHw7rX5P7tN6klSVWr/SkmSdIaZUBIkqoMCElSlQEhSaoyICRJVQaEJKnKgJAkVRkQkqSq/wcrd1BuAxWfqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(grid.predict(X_val) - y_val).hist(bins=30).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-2.82405984, -2.5268341 , -2.35847189, -2.23845937, -2.14401259,\n",
       "         -2.06553252, -1.99803001, -1.9385663 , -1.88525859, -1.83682524,\n",
       "         -1.79235285, -1.75116654, -1.712753  , -1.6767123 , -1.64272657,\n",
       "         -1.6105388 , -1.57993808, -1.55074915, -1.52282467, -1.49603959,\n",
       "         -1.47028677, -1.44547373, -1.42152004, -1.39835531, -1.37591755,\n",
       "         -1.35415189, -1.33300949, -1.31244672, -1.29242438, -1.27290718,\n",
       "         -1.25386317, -1.23526335, -1.21708133, -1.199293  , -1.18187626,\n",
       "         -1.16481085, -1.14807809, -1.13166074, -1.11554287, -1.09970971,\n",
       "         -1.08414754, -1.0688436 , -1.05378598, -1.03896357, -1.02436598,\n",
       "         -1.00998348, -0.99580691, -0.98182771, -0.96803779, -0.95442953,\n",
       "         -0.94099577, -0.92772971, -0.91462495, -0.90167541, -0.88887533,\n",
       "         -0.87621926, -0.86370201, -0.85131863, -0.83906446, -0.826935  ,\n",
       "         -0.814926  , -0.8030334 , -0.7912533 , -0.77958199, -0.76801592,\n",
       "         -0.7565517 , -0.74518605, -0.73391587, -0.72273814, -0.71164999,\n",
       "         -0.70064865, -0.68973147, -0.67889588, -0.66813942, -0.65745972,\n",
       "         -0.64685448, -0.6363215 , -0.62585865, -0.61546387, -0.60513517,\n",
       "         -0.59487063, -0.58466839, -0.57452664, -0.56444364, -0.55441771,\n",
       "         -0.5444472 , -0.53453053, -0.52466614, -0.51485255, -0.50508829,\n",
       "         -0.49537195, -0.48570215, -0.47607756, -0.46649687, -0.45695882,\n",
       "         -0.44746215, -0.43800567, -0.42858819, -0.41920858, -0.4098657 ,\n",
       "         -0.40055846, -0.3912858 , -0.38204665, -0.37284001, -0.36366486,\n",
       "         -0.35452022, -0.34540513, -0.33631866, -0.32725986, -0.31822785,\n",
       "         -0.30922172, -0.3002406 , -0.29128364, -0.28234998, -0.2734388 ,\n",
       "         -0.26454928, -0.25568062, -0.24683203, -0.23800272, -0.22919192,\n",
       "         -0.22039888, -0.21162285, -0.20286309, -0.19411887, -0.18538946,\n",
       "         -0.17667416, -0.16797226, -0.15928306, -0.15060587, -0.14194001,\n",
       "         -0.13328479, -0.12463954, -0.11600361, -0.10737631, -0.098757  ,\n",
       "         -0.09014502, -0.08153972, -0.07294045, -0.06434657, -0.05575745,\n",
       "         -0.04717243, -0.0385909 , -0.0300122 , -0.02143571, -0.01286079,\n",
       "         -0.00428683,  0.00428683,  0.01286079,  0.02143571,  0.0300122 ,\n",
       "          0.0385909 ,  0.04717243,  0.05575745,  0.06434657,  0.07294045,\n",
       "          0.08153972,  0.09014502,  0.098757  ,  0.10737631,  0.11600361,\n",
       "          0.12463954,  0.13328479,  0.14194001,  0.15060587,  0.15928306,\n",
       "          0.16797226,  0.17667416,  0.18538946,  0.19411887,  0.20286309,\n",
       "          0.21162285,  0.22039888,  0.22919192,  0.23800272,  0.24683203,\n",
       "          0.25568062,  0.26454928,  0.2734388 ,  0.28234998,  0.29128364,\n",
       "          0.3002406 ,  0.30922172,  0.31822785,  0.32725986,  0.33631866,\n",
       "          0.34540513,  0.35452022,  0.36366486,  0.37284001,  0.38204665,\n",
       "          0.3912858 ,  0.40055846,  0.4098657 ,  0.41920858,  0.42858819,\n",
       "          0.43800567,  0.44746215,  0.45695882,  0.46649687,  0.47607756,\n",
       "          0.48570215,  0.49537195,  0.50508829,  0.51485255,  0.52466614,\n",
       "          0.53453053,  0.5444472 ,  0.55441771,  0.56444364,  0.57452664,\n",
       "          0.58466839,  0.59487063,  0.60513517,  0.61546387,  0.62585865,\n",
       "          0.6363215 ,  0.64685448,  0.65745972,  0.66813942,  0.67889588,\n",
       "          0.68973147,  0.70064865,  0.71164999,  0.72273814,  0.73391587,\n",
       "          0.74518605,  0.7565517 ,  0.76801592,  0.77958199,  0.7912533 ,\n",
       "          0.8030334 ,  0.814926  ,  0.826935  ,  0.83906446,  0.85131863,\n",
       "          0.86370201,  0.87621926,  0.88887533,  0.90167541,  0.91462495,\n",
       "          0.92772971,  0.94099577,  0.95442953,  0.96803779,  0.98182771,\n",
       "          0.99580691,  1.00998348,  1.02436598,  1.03896357,  1.05378598,\n",
       "          1.0688436 ,  1.08414754,  1.09970971,  1.11554287,  1.13166074,\n",
       "          1.14807809,  1.16481085,  1.18187626,  1.199293  ,  1.21708133,\n",
       "          1.23526335,  1.25386317,  1.27290718,  1.29242438,  1.31244672,\n",
       "          1.33300949,  1.35415189,  1.37591755,  1.39835531,  1.42152004,\n",
       "          1.44547373,  1.47028677,  1.49603959,  1.52282467,  1.55074915,\n",
       "          1.57993808,  1.6105388 ,  1.64272657,  1.6767123 ,  1.712753  ,\n",
       "          1.75116654,  1.79235285,  1.83682524,  1.88525859,  1.9385663 ,\n",
       "          1.99803001,  2.06553252,  2.14401259,  2.23845937,  2.35847189,\n",
       "          2.5268341 ,  2.82405984]),\n",
       "  array([-1.94680877e+05, -1.63894607e+05, -1.11871499e+05, -5.69668105e+04,\n",
       "         -4.92545333e+04, -4.61350466e+04, -4.02831592e+04, -3.43961965e+04,\n",
       "         -3.30805478e+04, -3.23657316e+04, -3.05323301e+04, -2.99710418e+04,\n",
       "         -2.68903192e+04, -2.63215535e+04, -2.61253619e+04, -2.59282884e+04,\n",
       "         -2.55970582e+04, -2.53727106e+04, -2.44778145e+04, -2.42313889e+04,\n",
       "         -2.38789410e+04, -2.27698682e+04, -2.11373844e+04, -2.06069633e+04,\n",
       "         -2.02404131e+04, -1.93397535e+04, -1.92320857e+04, -1.90123673e+04,\n",
       "         -1.87324519e+04, -1.81607456e+04, -1.77973310e+04, -1.76051666e+04,\n",
       "         -1.73956536e+04, -1.71084234e+04, -1.70333161e+04, -1.70225359e+04,\n",
       "         -1.66885653e+04, -1.63451981e+04, -1.62051213e+04, -1.61979320e+04,\n",
       "         -1.60520469e+04, -1.59755671e+04, -1.56206955e+04, -1.54571825e+04,\n",
       "         -1.52323329e+04, -1.52064455e+04, -1.47930719e+04, -1.45521726e+04,\n",
       "         -1.44244945e+04, -1.38281798e+04, -1.36671211e+04, -1.32521887e+04,\n",
       "         -1.31737293e+04, -1.30874925e+04, -1.30131476e+04, -1.28400713e+04,\n",
       "         -1.28357293e+04, -1.26475008e+04, -1.26244808e+04, -1.22071674e+04,\n",
       "         -1.21291080e+04, -1.18490970e+04, -1.12911864e+04, -1.09388954e+04,\n",
       "         -1.09329194e+04, -1.09169722e+04, -1.08469186e+04, -1.06280337e+04,\n",
       "         -1.00971957e+04, -9.97025634e+03, -9.70900203e+03, -9.70851893e+03,\n",
       "         -9.60709776e+03, -9.47701637e+03, -9.34512073e+03, -9.04004519e+03,\n",
       "         -8.53511283e+03, -8.50518377e+03, -8.43134015e+03, -8.05789562e+03,\n",
       "         -8.02002357e+03, -8.01470544e+03, -7.95679416e+03, -7.59994475e+03,\n",
       "         -7.42413897e+03, -7.29753935e+03, -7.17402422e+03, -7.17056426e+03,\n",
       "         -7.15804502e+03, -7.13145821e+03, -6.98832034e+03, -6.85026594e+03,\n",
       "         -6.64704897e+03, -6.53794407e+03, -6.47557715e+03, -6.42845989e+03,\n",
       "         -6.42391351e+03, -6.35896157e+03, -6.33927438e+03, -6.30109087e+03,\n",
       "         -6.11689901e+03, -6.03865696e+03, -5.84843229e+03, -5.76995617e+03,\n",
       "         -5.76871157e+03, -5.75075460e+03, -5.08243236e+03, -4.93322910e+03,\n",
       "         -4.90420716e+03, -4.84808242e+03, -4.74374362e+03, -4.72928979e+03,\n",
       "         -4.67269597e+03, -4.62299157e+03, -4.56648827e+03, -4.47196957e+03,\n",
       "         -4.26550516e+03, -4.26243548e+03, -4.19653435e+03, -4.13471532e+03,\n",
       "         -3.80634705e+03, -3.80164311e+03, -3.77866166e+03, -3.70033635e+03,\n",
       "         -3.64403972e+03, -3.55717069e+03, -3.44568732e+03, -3.44300752e+03,\n",
       "         -3.41259980e+03, -3.41169631e+03, -3.39514718e+03, -3.35131311e+03,\n",
       "         -3.06239770e+03, -3.05259232e+03, -2.91411256e+03, -2.89289969e+03,\n",
       "         -2.34129543e+03, -2.01743577e+03, -1.92805610e+03, -1.85335272e+03,\n",
       "         -1.80277201e+03, -1.77599536e+03, -1.74100600e+03, -1.01085130e+03,\n",
       "         -9.65336087e+02, -7.41010048e+02, -4.99559069e+02, -3.81779048e+02,\n",
       "         -2.41342631e+02, -1.89566591e+02, -1.06510233e+02, -3.16259229e+00,\n",
       "          7.79496580e+00,  7.19540532e+01,  1.94829804e+02,  2.13127802e+02,\n",
       "          3.01242756e+02,  3.87791450e+02,  4.37753749e+02,  4.47035188e+02,\n",
       "          4.69422275e+02,  5.49233692e+02,  7.11262506e+02,  1.00496308e+03,\n",
       "          1.23189544e+03,  1.25627136e+03,  1.46757003e+03,  1.73530062e+03,\n",
       "          1.77611195e+03,  2.03668577e+03,  2.21472329e+03,  2.26877156e+03,\n",
       "          2.34704577e+03,  2.47169319e+03,  2.52981459e+03,  2.67048103e+03,\n",
       "          2.80065456e+03,  2.85403288e+03,  2.93368566e+03,  2.99026580e+03,\n",
       "          3.03058997e+03,  3.08236444e+03,  3.21363506e+03,  3.34848860e+03,\n",
       "          3.65592140e+03,  3.66705031e+03,  3.72460589e+03,  3.84764880e+03,\n",
       "          4.71538421e+03,  4.77578937e+03,  4.86792438e+03,  5.22432270e+03,\n",
       "          5.66540293e+03,  5.77372915e+03,  5.79681814e+03,  5.88261831e+03,\n",
       "          6.37126993e+03,  6.39235220e+03,  6.53410388e+03,  6.63125999e+03,\n",
       "          6.71195472e+03,  6.80662193e+03,  6.89026750e+03,  6.94532191e+03,\n",
       "          6.95494521e+03,  6.99562928e+03,  7.08895270e+03,  7.10647958e+03,\n",
       "          7.13794512e+03,  7.62087679e+03,  7.93873667e+03,  7.94134805e+03,\n",
       "          8.05133612e+03,  8.32116696e+03,  8.38635128e+03,  8.70373498e+03,\n",
       "          9.26811247e+03,  9.44205146e+03,  9.48177627e+03,  9.51996757e+03,\n",
       "          9.77234946e+03,  9.92941964e+03,  1.03473039e+04,  1.04066479e+04,\n",
       "          1.05690067e+04,  1.06589046e+04,  1.09766025e+04,  1.11397258e+04,\n",
       "          1.14279156e+04,  1.14926981e+04,  1.15667207e+04,  1.21519425e+04,\n",
       "          1.22543119e+04,  1.23638104e+04,  1.26684394e+04,  1.33155321e+04,\n",
       "          1.33378862e+04,  1.34211900e+04,  1.36920185e+04,  1.41221010e+04,\n",
       "          1.41286195e+04,  1.42379187e+04,  1.46286808e+04,  1.47277512e+04,\n",
       "          1.49151984e+04,  1.69843360e+04,  1.70168769e+04,  1.80006089e+04,\n",
       "          1.80912233e+04,  1.83558507e+04,  1.85131439e+04,  1.89470259e+04,\n",
       "          1.92031635e+04,  1.92077111e+04,  1.92695541e+04,  1.98910095e+04,\n",
       "          2.00132917e+04,  2.03446455e+04,  2.03534453e+04,  2.05020983e+04,\n",
       "          2.06907551e+04,  2.13520413e+04,  2.22991139e+04,  2.23635804e+04,\n",
       "          2.27785065e+04,  2.36962872e+04,  2.46373442e+04,  2.63862186e+04,\n",
       "          2.67738951e+04,  2.82521476e+04,  2.85706668e+04,  2.98315867e+04,\n",
       "          3.01154152e+04,  3.04117520e+04,  3.15958770e+04,  3.33064882e+04,\n",
       "          3.48088905e+04,  3.48546192e+04,  3.55028459e+04,  3.60838055e+04,\n",
       "          3.64093318e+04,  3.86920014e+04,  3.92193443e+04,  4.47266273e+04,\n",
       "          4.91153777e+04,  5.30176334e+04,  5.59430749e+04,  6.68283137e+04,\n",
       "          6.98561158e+04,  7.42809471e+04,  1.05140784e+05,  1.35171606e+05])),\n",
       " (22750.599647064144, 88.58428073035384, 0.8660025991839272))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import probplot\n",
    "probplot(grid.predict(X_val) - y_val, plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals do not look normal. Pretty extreme values at either end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only look at gradient boosting models without scaling. Use model based feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 192007.1411559\ttotal: 8.53ms\tremaining: 8.53s\n",
      "1:\tlearn: 186952.8881425\ttotal: 15.3ms\tremaining: 7.63s\n",
      "2:\tlearn: 182069.6918677\ttotal: 22.2ms\tremaining: 7.37s\n",
      "3:\tlearn: 177307.0776562\ttotal: 28.8ms\tremaining: 7.18s\n",
      "4:\tlearn: 172818.1095609\ttotal: 34.7ms\tremaining: 6.91s\n",
      "5:\tlearn: 168238.1486220\ttotal: 40.9ms\tremaining: 6.77s\n",
      "6:\tlearn: 163975.8815801\ttotal: 46.4ms\tremaining: 6.58s\n",
      "7:\tlearn: 159711.8837850\ttotal: 52.2ms\tremaining: 6.48s\n",
      "8:\tlearn: 155786.4531074\ttotal: 57.5ms\tremaining: 6.33s\n",
      "9:\tlearn: 151940.1473838\ttotal: 64.6ms\tremaining: 6.39s\n",
      "10:\tlearn: 148139.2334652\ttotal: 70.4ms\tremaining: 6.33s\n",
      "11:\tlearn: 144550.8577087\ttotal: 75.8ms\tremaining: 6.24s\n",
      "12:\tlearn: 140890.2723707\ttotal: 80.8ms\tremaining: 6.13s\n",
      "13:\tlearn: 137306.5139227\ttotal: 83ms\tremaining: 5.85s\n",
      "14:\tlearn: 133930.7867794\ttotal: 88.1ms\tremaining: 5.79s\n",
      "15:\tlearn: 130587.6217052\ttotal: 93.3ms\tremaining: 5.74s\n",
      "16:\tlearn: 127521.8539414\ttotal: 98.5ms\tremaining: 5.7s\n",
      "17:\tlearn: 124490.1328098\ttotal: 104ms\tremaining: 5.66s\n",
      "18:\tlearn: 121425.3583249\ttotal: 107ms\tremaining: 5.54s\n",
      "19:\tlearn: 118469.2702064\ttotal: 113ms\tremaining: 5.52s\n",
      "20:\tlearn: 115662.6817836\ttotal: 115ms\tremaining: 5.38s\n",
      "21:\tlearn: 112783.6574492\ttotal: 121ms\tremaining: 5.38s\n",
      "22:\tlearn: 110005.1297336\ttotal: 123ms\tremaining: 5.24s\n",
      "23:\tlearn: 107416.0248493\ttotal: 129ms\tremaining: 5.25s\n",
      "24:\tlearn: 104941.9886476\ttotal: 134ms\tremaining: 5.24s\n",
      "25:\tlearn: 102407.0686683\ttotal: 139ms\tremaining: 5.22s\n",
      "26:\tlearn: 100087.9286863\ttotal: 141ms\tremaining: 5.09s\n",
      "27:\tlearn: 97778.4455639\ttotal: 147ms\tremaining: 5.09s\n",
      "28:\tlearn: 95497.2491085\ttotal: 152ms\tremaining: 5.08s\n",
      "29:\tlearn: 93329.1399659\ttotal: 158ms\tremaining: 5.11s\n",
      "30:\tlearn: 91184.5509510\ttotal: 164ms\tremaining: 5.13s\n",
      "31:\tlearn: 89203.1041414\ttotal: 170ms\tremaining: 5.16s\n",
      "32:\tlearn: 87254.7036349\ttotal: 173ms\tremaining: 5.06s\n",
      "33:\tlearn: 85276.4305356\ttotal: 178ms\tremaining: 5.05s\n",
      "34:\tlearn: 83441.9374587\ttotal: 184ms\tremaining: 5.07s\n",
      "35:\tlearn: 81608.5828870\ttotal: 189ms\tremaining: 5.06s\n",
      "36:\tlearn: 80023.1493650\ttotal: 194ms\tremaining: 5.06s\n",
      "37:\tlearn: 78433.7242112\ttotal: 200ms\tremaining: 5.05s\n",
      "38:\tlearn: 76771.6220691\ttotal: 205ms\tremaining: 5.06s\n",
      "39:\tlearn: 75115.2040129\ttotal: 211ms\tremaining: 5.07s\n",
      "40:\tlearn: 73571.4834936\ttotal: 217ms\tremaining: 5.08s\n",
      "41:\tlearn: 72081.5582246\ttotal: 223ms\tremaining: 5.09s\n",
      "42:\tlearn: 70507.9438540\ttotal: 229ms\tremaining: 5.1s\n",
      "43:\tlearn: 69116.0245276\ttotal: 235ms\tremaining: 5.12s\n",
      "44:\tlearn: 67728.5476219\ttotal: 243ms\tremaining: 5.16s\n",
      "45:\tlearn: 66365.0756412\ttotal: 252ms\tremaining: 5.22s\n",
      "46:\tlearn: 65137.7771730\ttotal: 263ms\tremaining: 5.33s\n",
      "47:\tlearn: 63894.7934726\ttotal: 269ms\tremaining: 5.34s\n",
      "48:\tlearn: 62722.8922837\ttotal: 275ms\tremaining: 5.33s\n",
      "49:\tlearn: 61591.8992652\ttotal: 278ms\tremaining: 5.28s\n",
      "50:\tlearn: 60476.9381646\ttotal: 284ms\tremaining: 5.28s\n",
      "51:\tlearn: 59326.1236294\ttotal: 289ms\tremaining: 5.27s\n",
      "52:\tlearn: 58259.6198547\ttotal: 294ms\tremaining: 5.26s\n",
      "53:\tlearn: 57277.0860005\ttotal: 299ms\tremaining: 5.25s\n",
      "54:\tlearn: 56273.1366181\ttotal: 305ms\tremaining: 5.24s\n",
      "55:\tlearn: 55282.0633143\ttotal: 310ms\tremaining: 5.22s\n",
      "56:\tlearn: 54309.7372263\ttotal: 316ms\tremaining: 5.22s\n",
      "57:\tlearn: 53367.3493531\ttotal: 321ms\tremaining: 5.22s\n",
      "58:\tlearn: 52420.5585849\ttotal: 326ms\tremaining: 5.21s\n",
      "59:\tlearn: 51528.2229606\ttotal: 332ms\tremaining: 5.2s\n",
      "60:\tlearn: 50691.0372108\ttotal: 337ms\tremaining: 5.19s\n",
      "61:\tlearn: 49866.7105771\ttotal: 342ms\tremaining: 5.18s\n",
      "62:\tlearn: 49133.9698279\ttotal: 348ms\tremaining: 5.17s\n",
      "63:\tlearn: 48416.5503496\ttotal: 354ms\tremaining: 5.18s\n",
      "64:\tlearn: 47623.3127707\ttotal: 360ms\tremaining: 5.18s\n",
      "65:\tlearn: 46919.7391667\ttotal: 366ms\tremaining: 5.18s\n",
      "66:\tlearn: 46286.6784124\ttotal: 371ms\tremaining: 5.17s\n",
      "67:\tlearn: 45614.0859109\ttotal: 376ms\tremaining: 5.16s\n",
      "68:\tlearn: 44877.1073680\ttotal: 382ms\tremaining: 5.15s\n",
      "69:\tlearn: 44263.6757207\ttotal: 387ms\tremaining: 5.14s\n",
      "70:\tlearn: 43641.2066223\ttotal: 392ms\tremaining: 5.13s\n",
      "71:\tlearn: 43022.6750634\ttotal: 398ms\tremaining: 5.12s\n",
      "72:\tlearn: 42509.2432316\ttotal: 404ms\tremaining: 5.12s\n",
      "73:\tlearn: 41922.6337614\ttotal: 409ms\tremaining: 5.12s\n",
      "74:\tlearn: 41349.2964269\ttotal: 415ms\tremaining: 5.12s\n",
      "75:\tlearn: 40799.0198667\ttotal: 421ms\tremaining: 5.11s\n",
      "76:\tlearn: 40316.2393426\ttotal: 426ms\tremaining: 5.11s\n",
      "77:\tlearn: 39764.2300698\ttotal: 433ms\tremaining: 5.12s\n",
      "78:\tlearn: 39299.8348233\ttotal: 440ms\tremaining: 5.13s\n",
      "79:\tlearn: 38846.7539309\ttotal: 448ms\tremaining: 5.15s\n",
      "80:\tlearn: 38333.0552707\ttotal: 454ms\tremaining: 5.15s\n",
      "81:\tlearn: 37900.0372128\ttotal: 460ms\tremaining: 5.15s\n",
      "82:\tlearn: 37484.6867583\ttotal: 466ms\tremaining: 5.15s\n",
      "83:\tlearn: 37143.0037075\ttotal: 471ms\tremaining: 5.14s\n",
      "84:\tlearn: 36737.7499841\ttotal: 478ms\tremaining: 5.14s\n",
      "85:\tlearn: 36367.3935610\ttotal: 483ms\tremaining: 5.13s\n",
      "86:\tlearn: 35988.6858930\ttotal: 488ms\tremaining: 5.12s\n",
      "87:\tlearn: 35668.4165645\ttotal: 493ms\tremaining: 5.11s\n",
      "88:\tlearn: 35365.7716308\ttotal: 499ms\tremaining: 5.1s\n",
      "89:\tlearn: 34965.5727308\ttotal: 504ms\tremaining: 5.09s\n",
      "90:\tlearn: 34579.4421596\ttotal: 509ms\tremaining: 5.08s\n",
      "91:\tlearn: 34196.1494262\ttotal: 514ms\tremaining: 5.08s\n",
      "92:\tlearn: 33849.9149281\ttotal: 520ms\tremaining: 5.07s\n",
      "93:\tlearn: 33549.1067451\ttotal: 525ms\tremaining: 5.06s\n",
      "94:\tlearn: 33253.8517056\ttotal: 530ms\tremaining: 5.05s\n",
      "95:\tlearn: 32940.6408317\ttotal: 535ms\tremaining: 5.04s\n",
      "96:\tlearn: 32617.5588373\ttotal: 540ms\tremaining: 5.03s\n",
      "97:\tlearn: 32391.2928089\ttotal: 547ms\tremaining: 5.03s\n",
      "98:\tlearn: 32144.1668290\ttotal: 556ms\tremaining: 5.05s\n",
      "99:\tlearn: 31876.8529805\ttotal: 561ms\tremaining: 5.05s\n",
      "100:\tlearn: 31631.6538685\ttotal: 566ms\tremaining: 5.04s\n",
      "101:\tlearn: 31366.4018348\ttotal: 572ms\tremaining: 5.04s\n",
      "102:\tlearn: 31145.4585903\ttotal: 578ms\tremaining: 5.03s\n",
      "103:\tlearn: 30881.4293662\ttotal: 583ms\tremaining: 5.02s\n",
      "104:\tlearn: 30621.3991486\ttotal: 589ms\tremaining: 5.02s\n",
      "105:\tlearn: 30371.9366573\ttotal: 594ms\tremaining: 5.01s\n",
      "106:\tlearn: 30177.1107648\ttotal: 600ms\tremaining: 5s\n",
      "107:\tlearn: 30034.7834863\ttotal: 605ms\tremaining: 5s\n",
      "108:\tlearn: 29841.4786044\ttotal: 611ms\tremaining: 4.99s\n",
      "109:\tlearn: 29677.1480639\ttotal: 616ms\tremaining: 4.99s\n",
      "110:\tlearn: 29522.3082840\ttotal: 622ms\tremaining: 4.98s\n",
      "111:\tlearn: 29315.7624735\ttotal: 629ms\tremaining: 4.99s\n",
      "112:\tlearn: 29168.9476452\ttotal: 637ms\tremaining: 5s\n",
      "113:\tlearn: 29024.8404514\ttotal: 643ms\tremaining: 4.99s\n",
      "114:\tlearn: 28834.3281964\ttotal: 654ms\tremaining: 5.04s\n",
      "115:\tlearn: 28667.3846076\ttotal: 664ms\tremaining: 5.06s\n",
      "116:\tlearn: 28462.8261453\ttotal: 670ms\tremaining: 5.06s\n",
      "117:\tlearn: 28296.7895926\ttotal: 676ms\tremaining: 5.05s\n",
      "118:\tlearn: 28145.6253499\ttotal: 681ms\tremaining: 5.04s\n",
      "119:\tlearn: 27970.6646343\ttotal: 687ms\tremaining: 5.04s\n",
      "120:\tlearn: 27825.5382394\ttotal: 693ms\tremaining: 5.03s\n",
      "121:\tlearn: 27673.7672039\ttotal: 698ms\tremaining: 5.02s\n",
      "122:\tlearn: 27544.8345702\ttotal: 703ms\tremaining: 5.01s\n",
      "123:\tlearn: 27423.6567189\ttotal: 708ms\tremaining: 5s\n",
      "124:\tlearn: 27266.6367280\ttotal: 713ms\tremaining: 4.99s\n",
      "125:\tlearn: 27193.3846646\ttotal: 719ms\tremaining: 4.98s\n",
      "126:\tlearn: 27077.8050180\ttotal: 724ms\tremaining: 4.97s\n",
      "127:\tlearn: 26977.1667487\ttotal: 729ms\tremaining: 4.96s\n",
      "128:\tlearn: 26875.3203573\ttotal: 734ms\tremaining: 4.96s\n",
      "129:\tlearn: 26749.4664648\ttotal: 739ms\tremaining: 4.95s\n",
      "130:\tlearn: 26659.2063787\ttotal: 746ms\tremaining: 4.95s\n",
      "131:\tlearn: 26524.8436758\ttotal: 751ms\tremaining: 4.94s\n",
      "132:\tlearn: 26425.4065818\ttotal: 756ms\tremaining: 4.93s\n",
      "133:\tlearn: 26305.0561345\ttotal: 762ms\tremaining: 4.92s\n",
      "134:\tlearn: 26210.4029303\ttotal: 768ms\tremaining: 4.92s\n",
      "135:\tlearn: 26102.0697887\ttotal: 773ms\tremaining: 4.91s\n",
      "136:\tlearn: 26001.5131689\ttotal: 778ms\tremaining: 4.9s\n",
      "137:\tlearn: 25888.0420134\ttotal: 783ms\tremaining: 4.89s\n",
      "138:\tlearn: 25771.3361613\ttotal: 788ms\tremaining: 4.88s\n",
      "139:\tlearn: 25653.2512347\ttotal: 794ms\tremaining: 4.88s\n",
      "140:\tlearn: 25557.6146110\ttotal: 800ms\tremaining: 4.87s\n",
      "141:\tlearn: 25463.8248794\ttotal: 805ms\tremaining: 4.87s\n",
      "142:\tlearn: 25359.7292607\ttotal: 811ms\tremaining: 4.86s\n",
      "143:\tlearn: 25280.8823107\ttotal: 819ms\tremaining: 4.87s\n",
      "144:\tlearn: 25189.5218994\ttotal: 825ms\tremaining: 4.86s\n",
      "145:\tlearn: 25119.2176311\ttotal: 833ms\tremaining: 4.87s\n",
      "146:\tlearn: 25045.3465613\ttotal: 839ms\tremaining: 4.87s\n",
      "147:\tlearn: 24985.8649263\ttotal: 845ms\tremaining: 4.87s\n",
      "148:\tlearn: 24911.3859678\ttotal: 850ms\tremaining: 4.86s\n",
      "149:\tlearn: 24860.7601938\ttotal: 856ms\tremaining: 4.85s\n",
      "150:\tlearn: 24806.4088820\ttotal: 862ms\tremaining: 4.84s\n",
      "151:\tlearn: 24720.1062110\ttotal: 867ms\tremaining: 4.83s\n",
      "152:\tlearn: 24621.2599016\ttotal: 872ms\tremaining: 4.83s\n",
      "153:\tlearn: 24533.4641835\ttotal: 877ms\tremaining: 4.82s\n",
      "154:\tlearn: 24489.2053572\ttotal: 882ms\tremaining: 4.81s\n",
      "155:\tlearn: 24413.8155222\ttotal: 887ms\tremaining: 4.8s\n",
      "156:\tlearn: 24335.6753277\ttotal: 892ms\tremaining: 4.79s\n",
      "157:\tlearn: 24264.1278750\ttotal: 897ms\tremaining: 4.78s\n",
      "158:\tlearn: 24217.1660919\ttotal: 899ms\tremaining: 4.76s\n",
      "159:\tlearn: 24122.5709680\ttotal: 904ms\tremaining: 4.75s\n",
      "160:\tlearn: 24080.3405690\ttotal: 910ms\tremaining: 4.74s\n",
      "161:\tlearn: 24022.3905685\ttotal: 915ms\tremaining: 4.73s\n",
      "162:\tlearn: 23978.8489720\ttotal: 920ms\tremaining: 4.72s\n",
      "163:\tlearn: 23889.0702988\ttotal: 925ms\tremaining: 4.71s\n",
      "164:\tlearn: 23825.8587970\ttotal: 930ms\tremaining: 4.71s\n",
      "165:\tlearn: 23783.8161797\ttotal: 936ms\tremaining: 4.7s\n",
      "166:\tlearn: 23751.7992109\ttotal: 941ms\tremaining: 4.7s\n",
      "167:\tlearn: 23709.3614635\ttotal: 947ms\tremaining: 4.69s\n",
      "168:\tlearn: 23643.7672439\ttotal: 952ms\tremaining: 4.68s\n",
      "169:\tlearn: 23607.1820588\ttotal: 954ms\tremaining: 4.66s\n",
      "170:\tlearn: 23557.1715005\ttotal: 959ms\tremaining: 4.65s\n",
      "171:\tlearn: 23513.9208036\ttotal: 964ms\tremaining: 4.64s\n",
      "172:\tlearn: 23457.5422668\ttotal: 970ms\tremaining: 4.63s\n",
      "173:\tlearn: 23400.7501460\ttotal: 975ms\tremaining: 4.63s\n",
      "174:\tlearn: 23355.1498437\ttotal: 980ms\tremaining: 4.62s\n",
      "175:\tlearn: 23274.3087255\ttotal: 985ms\tremaining: 4.61s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176:\tlearn: 23197.1728075\ttotal: 991ms\tremaining: 4.61s\n",
      "177:\tlearn: 23129.9026081\ttotal: 996ms\tremaining: 4.6s\n",
      "178:\tlearn: 23084.5651334\ttotal: 999ms\tremaining: 4.58s\n",
      "179:\tlearn: 23024.7080523\ttotal: 1s\tremaining: 4.57s\n",
      "180:\tlearn: 22975.9549912\ttotal: 1.01s\tremaining: 4.57s\n",
      "181:\tlearn: 22928.4496105\ttotal: 1.02s\tremaining: 4.57s\n",
      "182:\tlearn: 22876.6318528\ttotal: 1.03s\tremaining: 4.58s\n",
      "183:\tlearn: 22811.9039198\ttotal: 1.03s\tremaining: 4.58s\n",
      "184:\tlearn: 22746.3763112\ttotal: 1.04s\tremaining: 4.58s\n",
      "185:\tlearn: 22697.0822653\ttotal: 1.04s\tremaining: 4.57s\n",
      "186:\tlearn: 22670.5358620\ttotal: 1.05s\tremaining: 4.56s\n",
      "187:\tlearn: 22624.8178029\ttotal: 1.05s\tremaining: 4.56s\n",
      "188:\tlearn: 22604.9986903\ttotal: 1.06s\tremaining: 4.55s\n",
      "189:\tlearn: 22584.8161030\ttotal: 1.06s\tremaining: 4.53s\n",
      "190:\tlearn: 22544.6168043\ttotal: 1.07s\tremaining: 4.52s\n",
      "191:\tlearn: 22484.8211365\ttotal: 1.07s\tremaining: 4.52s\n",
      "192:\tlearn: 22424.9881629\ttotal: 1.08s\tremaining: 4.51s\n",
      "193:\tlearn: 22406.8678746\ttotal: 1.08s\tremaining: 4.5s\n",
      "194:\tlearn: 22338.7619529\ttotal: 1.09s\tremaining: 4.49s\n",
      "195:\tlearn: 22307.1184148\ttotal: 1.09s\tremaining: 4.49s\n",
      "196:\tlearn: 22271.0742710\ttotal: 1.1s\tremaining: 4.48s\n",
      "197:\tlearn: 22211.9163890\ttotal: 1.1s\tremaining: 4.47s\n",
      "198:\tlearn: 22173.9803857\ttotal: 1.11s\tremaining: 4.46s\n",
      "199:\tlearn: 22143.3110481\ttotal: 1.11s\tremaining: 4.45s\n",
      "200:\tlearn: 22088.3416750\ttotal: 1.12s\tremaining: 4.45s\n",
      "201:\tlearn: 22043.1783261\ttotal: 1.12s\tremaining: 4.44s\n",
      "202:\tlearn: 22017.4611859\ttotal: 1.13s\tremaining: 4.44s\n",
      "203:\tlearn: 21980.4760050\ttotal: 1.14s\tremaining: 4.43s\n",
      "204:\tlearn: 21944.2040217\ttotal: 1.14s\tremaining: 4.42s\n",
      "205:\tlearn: 21922.4261568\ttotal: 1.15s\tremaining: 4.42s\n",
      "206:\tlearn: 21891.7569617\ttotal: 1.15s\tremaining: 4.4s\n",
      "207:\tlearn: 21856.7725397\ttotal: 1.15s\tremaining: 4.4s\n",
      "208:\tlearn: 21827.7729332\ttotal: 1.16s\tremaining: 4.39s\n",
      "209:\tlearn: 21794.0245420\ttotal: 1.16s\tremaining: 4.38s\n",
      "210:\tlearn: 21769.1287336\ttotal: 1.17s\tremaining: 4.37s\n",
      "211:\tlearn: 21730.3502177\ttotal: 1.18s\tremaining: 4.37s\n",
      "212:\tlearn: 21716.5913873\ttotal: 1.18s\tremaining: 4.36s\n",
      "213:\tlearn: 21696.2728982\ttotal: 1.19s\tremaining: 4.36s\n",
      "214:\tlearn: 21680.4318063\ttotal: 1.19s\tremaining: 4.36s\n",
      "215:\tlearn: 21642.8562637\ttotal: 1.2s\tremaining: 4.35s\n",
      "216:\tlearn: 21626.7305611\ttotal: 1.21s\tremaining: 4.35s\n",
      "217:\tlearn: 21590.4944773\ttotal: 1.21s\tremaining: 4.35s\n",
      "218:\tlearn: 21572.9384532\ttotal: 1.22s\tremaining: 4.34s\n",
      "219:\tlearn: 21540.7291390\ttotal: 1.22s\tremaining: 4.33s\n",
      "220:\tlearn: 21529.1199777\ttotal: 1.23s\tremaining: 4.33s\n",
      "221:\tlearn: 21503.4895375\ttotal: 1.23s\tremaining: 4.32s\n",
      "222:\tlearn: 21458.1953235\ttotal: 1.24s\tremaining: 4.32s\n",
      "223:\tlearn: 21412.2413467\ttotal: 1.24s\tremaining: 4.31s\n",
      "224:\tlearn: 21396.4188953\ttotal: 1.25s\tremaining: 4.3s\n",
      "225:\tlearn: 21368.3078132\ttotal: 1.25s\tremaining: 4.3s\n",
      "226:\tlearn: 21359.2450789\ttotal: 1.26s\tremaining: 4.29s\n",
      "227:\tlearn: 21312.9716424\ttotal: 1.26s\tremaining: 4.28s\n",
      "228:\tlearn: 21294.7343278\ttotal: 1.27s\tremaining: 4.28s\n",
      "229:\tlearn: 21267.2782610\ttotal: 1.27s\tremaining: 4.27s\n",
      "230:\tlearn: 21247.0778572\ttotal: 1.28s\tremaining: 4.26s\n",
      "231:\tlearn: 21224.0785698\ttotal: 1.28s\tremaining: 4.25s\n",
      "232:\tlearn: 21200.3933204\ttotal: 1.29s\tremaining: 4.25s\n",
      "233:\tlearn: 21162.5291588\ttotal: 1.29s\tremaining: 4.24s\n",
      "234:\tlearn: 21150.7044548\ttotal: 1.3s\tremaining: 4.23s\n",
      "235:\tlearn: 21122.3641423\ttotal: 1.3s\tremaining: 4.23s\n",
      "236:\tlearn: 21100.7485418\ttotal: 1.31s\tremaining: 4.22s\n",
      "237:\tlearn: 21079.8533693\ttotal: 1.31s\tremaining: 4.21s\n",
      "238:\tlearn: 21069.8405970\ttotal: 1.32s\tremaining: 4.22s\n",
      "239:\tlearn: 21057.7748591\ttotal: 1.33s\tremaining: 4.21s\n",
      "240:\tlearn: 21015.6259458\ttotal: 1.33s\tremaining: 4.2s\n",
      "241:\tlearn: 21002.8218372\ttotal: 1.34s\tremaining: 4.2s\n",
      "242:\tlearn: 20979.3089777\ttotal: 1.34s\tremaining: 4.19s\n",
      "243:\tlearn: 20969.1105618\ttotal: 1.35s\tremaining: 4.18s\n",
      "244:\tlearn: 20958.4476701\ttotal: 1.36s\tremaining: 4.18s\n",
      "245:\tlearn: 20945.8243613\ttotal: 1.36s\tremaining: 4.17s\n",
      "246:\tlearn: 20896.5442311\ttotal: 1.37s\tremaining: 4.16s\n",
      "247:\tlearn: 20870.7171147\ttotal: 1.37s\tremaining: 4.16s\n",
      "248:\tlearn: 20866.5397108\ttotal: 1.37s\tremaining: 4.14s\n",
      "249:\tlearn: 20844.4804144\ttotal: 1.38s\tremaining: 4.13s\n",
      "250:\tlearn: 20833.4461209\ttotal: 1.38s\tremaining: 4.13s\n",
      "251:\tlearn: 20809.7334846\ttotal: 1.39s\tremaining: 4.12s\n",
      "252:\tlearn: 20774.6112759\ttotal: 1.39s\tremaining: 4.12s\n",
      "253:\tlearn: 20765.4135247\ttotal: 1.4s\tremaining: 4.11s\n",
      "254:\tlearn: 20754.5561085\ttotal: 1.41s\tremaining: 4.11s\n",
      "255:\tlearn: 20747.1162487\ttotal: 1.41s\tremaining: 4.1s\n",
      "256:\tlearn: 20715.6526626\ttotal: 1.41s\tremaining: 4.09s\n",
      "257:\tlearn: 20711.5453904\ttotal: 1.42s\tremaining: 4.09s\n",
      "258:\tlearn: 20671.1396118\ttotal: 1.43s\tremaining: 4.08s\n",
      "259:\tlearn: 20638.6522700\ttotal: 1.43s\tremaining: 4.08s\n",
      "260:\tlearn: 20632.4020126\ttotal: 1.44s\tremaining: 4.07s\n",
      "261:\tlearn: 20605.4229423\ttotal: 1.44s\tremaining: 4.06s\n",
      "262:\tlearn: 20574.7569599\ttotal: 1.45s\tremaining: 4.05s\n",
      "263:\tlearn: 20534.9600276\ttotal: 1.45s\tremaining: 4.05s\n",
      "264:\tlearn: 20503.3011382\ttotal: 1.46s\tremaining: 4.04s\n",
      "265:\tlearn: 20463.2578157\ttotal: 1.46s\tremaining: 4.04s\n",
      "266:\tlearn: 20459.3298106\ttotal: 1.47s\tremaining: 4.03s\n",
      "267:\tlearn: 20439.0195516\ttotal: 1.47s\tremaining: 4.02s\n",
      "268:\tlearn: 20411.8875757\ttotal: 1.48s\tremaining: 4.01s\n",
      "269:\tlearn: 20403.5364584\ttotal: 1.48s\tremaining: 4.01s\n",
      "270:\tlearn: 20345.0978937\ttotal: 1.49s\tremaining: 4s\n",
      "271:\tlearn: 20323.9345731\ttotal: 1.49s\tremaining: 3.99s\n",
      "272:\tlearn: 20316.1656383\ttotal: 1.5s\tremaining: 3.99s\n",
      "273:\tlearn: 20313.2005395\ttotal: 1.5s\tremaining: 3.98s\n",
      "274:\tlearn: 20299.9770865\ttotal: 1.51s\tremaining: 3.97s\n",
      "275:\tlearn: 20265.1755237\ttotal: 1.51s\tremaining: 3.97s\n",
      "276:\tlearn: 20254.9269766\ttotal: 1.52s\tremaining: 3.97s\n",
      "277:\tlearn: 20221.3033373\ttotal: 1.53s\tremaining: 3.96s\n",
      "278:\tlearn: 20209.2484661\ttotal: 1.53s\tremaining: 3.96s\n",
      "279:\tlearn: 20195.4764741\ttotal: 1.53s\tremaining: 3.95s\n",
      "280:\tlearn: 20176.9061628\ttotal: 1.54s\tremaining: 3.94s\n",
      "281:\tlearn: 20173.0257076\ttotal: 1.54s\tremaining: 3.93s\n",
      "282:\tlearn: 20154.9134916\ttotal: 1.55s\tremaining: 3.93s\n",
      "283:\tlearn: 20131.4829332\ttotal: 1.55s\tremaining: 3.92s\n",
      "284:\tlearn: 20129.5303846\ttotal: 1.56s\tremaining: 3.91s\n",
      "285:\tlearn: 20101.6394222\ttotal: 1.56s\tremaining: 3.9s\n",
      "286:\tlearn: 20093.8648237\ttotal: 1.57s\tremaining: 3.9s\n",
      "287:\tlearn: 20069.5606990\ttotal: 1.57s\tremaining: 3.89s\n",
      "288:\tlearn: 20064.7474897\ttotal: 1.58s\tremaining: 3.88s\n",
      "289:\tlearn: 20033.8205663\ttotal: 1.58s\tremaining: 3.88s\n",
      "290:\tlearn: 20029.0277517\ttotal: 1.59s\tremaining: 3.88s\n",
      "291:\tlearn: 20023.7148471\ttotal: 1.6s\tremaining: 3.87s\n",
      "292:\tlearn: 20017.8144537\ttotal: 1.6s\tremaining: 3.87s\n",
      "293:\tlearn: 20010.9209593\ttotal: 1.61s\tremaining: 3.86s\n",
      "294:\tlearn: 19995.0206875\ttotal: 1.61s\tremaining: 3.86s\n",
      "295:\tlearn: 19979.8870772\ttotal: 1.62s\tremaining: 3.85s\n",
      "296:\tlearn: 19957.1064252\ttotal: 1.63s\tremaining: 3.85s\n",
      "297:\tlearn: 19937.4829187\ttotal: 1.63s\tremaining: 3.84s\n",
      "298:\tlearn: 19923.5184105\ttotal: 1.64s\tremaining: 3.83s\n",
      "299:\tlearn: 19918.2455620\ttotal: 1.64s\tremaining: 3.82s\n",
      "300:\tlearn: 19916.0845547\ttotal: 1.64s\tremaining: 3.82s\n",
      "301:\tlearn: 19889.4521498\ttotal: 1.65s\tremaining: 3.81s\n",
      "302:\tlearn: 19852.3039692\ttotal: 1.65s\tremaining: 3.8s\n",
      "303:\tlearn: 19846.0856318\ttotal: 1.66s\tremaining: 3.8s\n",
      "304:\tlearn: 19824.6192692\ttotal: 1.66s\tremaining: 3.79s\n",
      "305:\tlearn: 19806.6691992\ttotal: 1.67s\tremaining: 3.78s\n",
      "306:\tlearn: 19790.5550353\ttotal: 1.67s\tremaining: 3.78s\n",
      "307:\tlearn: 19761.2997831\ttotal: 1.68s\tremaining: 3.77s\n",
      "308:\tlearn: 19749.2833932\ttotal: 1.68s\tremaining: 3.76s\n",
      "309:\tlearn: 19720.3390058\ttotal: 1.69s\tremaining: 3.76s\n",
      "310:\tlearn: 19707.2259414\ttotal: 1.69s\tremaining: 3.75s\n",
      "311:\tlearn: 19701.6901277\ttotal: 1.7s\tremaining: 3.75s\n",
      "312:\tlearn: 19695.7430130\ttotal: 1.7s\tremaining: 3.74s\n",
      "313:\tlearn: 19681.5700191\ttotal: 1.71s\tremaining: 3.73s\n",
      "314:\tlearn: 19676.5098343\ttotal: 1.72s\tremaining: 3.73s\n",
      "315:\tlearn: 19673.9414279\ttotal: 1.72s\tremaining: 3.73s\n",
      "316:\tlearn: 19660.0646052\ttotal: 1.73s\tremaining: 3.72s\n",
      "317:\tlearn: 19644.6126759\ttotal: 1.73s\tremaining: 3.71s\n",
      "318:\tlearn: 19629.1578054\ttotal: 1.74s\tremaining: 3.71s\n",
      "319:\tlearn: 19597.9559124\ttotal: 1.74s\tremaining: 3.7s\n",
      "320:\tlearn: 19588.5858507\ttotal: 1.74s\tremaining: 3.69s\n",
      "321:\tlearn: 19578.2255106\ttotal: 1.75s\tremaining: 3.68s\n",
      "322:\tlearn: 19571.7327809\ttotal: 1.75s\tremaining: 3.67s\n",
      "323:\tlearn: 19551.2408742\ttotal: 1.76s\tremaining: 3.67s\n",
      "324:\tlearn: 19534.5008684\ttotal: 1.76s\tremaining: 3.66s\n",
      "325:\tlearn: 19530.6164840\ttotal: 1.77s\tremaining: 3.66s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326:\tlearn: 19519.8365510\ttotal: 1.77s\tremaining: 3.65s\n",
      "327:\tlearn: 19517.2771686\ttotal: 1.78s\tremaining: 3.65s\n",
      "328:\tlearn: 19506.6317293\ttotal: 1.78s\tremaining: 3.64s\n",
      "329:\tlearn: 19505.9168678\ttotal: 1.79s\tremaining: 3.63s\n",
      "330:\tlearn: 19496.2215293\ttotal: 1.79s\tremaining: 3.63s\n",
      "331:\tlearn: 19479.6138926\ttotal: 1.8s\tremaining: 3.62s\n",
      "332:\tlearn: 19475.8542099\ttotal: 1.81s\tremaining: 3.62s\n",
      "333:\tlearn: 19457.9292288\ttotal: 1.81s\tremaining: 3.61s\n",
      "334:\tlearn: 19456.0067929\ttotal: 1.82s\tremaining: 3.61s\n",
      "335:\tlearn: 19454.2971408\ttotal: 1.82s\tremaining: 3.6s\n",
      "336:\tlearn: 19433.8421060\ttotal: 1.83s\tremaining: 3.6s\n",
      "337:\tlearn: 19405.0009899\ttotal: 1.83s\tremaining: 3.59s\n",
      "338:\tlearn: 19395.4418886\ttotal: 1.84s\tremaining: 3.58s\n",
      "339:\tlearn: 19392.6999648\ttotal: 1.84s\tremaining: 3.58s\n",
      "340:\tlearn: 19379.8338195\ttotal: 1.85s\tremaining: 3.57s\n",
      "341:\tlearn: 19370.3716540\ttotal: 1.85s\tremaining: 3.56s\n",
      "342:\tlearn: 19359.7544427\ttotal: 1.86s\tremaining: 3.56s\n",
      "343:\tlearn: 19358.3636952\ttotal: 1.86s\tremaining: 3.55s\n",
      "344:\tlearn: 19310.9162807\ttotal: 1.87s\tremaining: 3.54s\n",
      "345:\tlearn: 19298.6276242\ttotal: 1.87s\tremaining: 3.54s\n",
      "346:\tlearn: 19294.3204863\ttotal: 1.88s\tremaining: 3.53s\n",
      "347:\tlearn: 19286.4640189\ttotal: 1.88s\tremaining: 3.52s\n",
      "348:\tlearn: 19284.8116557\ttotal: 1.89s\tremaining: 3.52s\n",
      "349:\tlearn: 19280.8457878\ttotal: 1.89s\tremaining: 3.51s\n",
      "350:\tlearn: 19262.9172834\ttotal: 1.9s\tremaining: 3.51s\n",
      "351:\tlearn: 19251.3914209\ttotal: 1.9s\tremaining: 3.5s\n",
      "352:\tlearn: 19249.2617279\ttotal: 1.91s\tremaining: 3.5s\n",
      "353:\tlearn: 19223.7148325\ttotal: 1.91s\tremaining: 3.49s\n",
      "354:\tlearn: 19222.8277663\ttotal: 1.92s\tremaining: 3.48s\n",
      "355:\tlearn: 19208.3625420\ttotal: 1.92s\tremaining: 3.48s\n",
      "356:\tlearn: 19198.3572766\ttotal: 1.93s\tremaining: 3.47s\n",
      "357:\tlearn: 19178.9680725\ttotal: 1.93s\tremaining: 3.47s\n",
      "358:\tlearn: 19172.2101795\ttotal: 1.94s\tremaining: 3.46s\n",
      "359:\tlearn: 19144.2833282\ttotal: 1.94s\tremaining: 3.46s\n",
      "360:\tlearn: 19131.8822154\ttotal: 1.95s\tremaining: 3.45s\n",
      "361:\tlearn: 19087.2832796\ttotal: 1.95s\tremaining: 3.44s\n",
      "362:\tlearn: 19080.4314363\ttotal: 1.96s\tremaining: 3.44s\n",
      "363:\tlearn: 19079.8812960\ttotal: 1.96s\tremaining: 3.42s\n",
      "364:\tlearn: 19078.6278685\ttotal: 1.97s\tremaining: 3.42s\n",
      "365:\tlearn: 19073.3650464\ttotal: 1.97s\tremaining: 3.42s\n",
      "366:\tlearn: 19054.7520689\ttotal: 1.98s\tremaining: 3.41s\n",
      "367:\tlearn: 19032.2420311\ttotal: 1.98s\tremaining: 3.4s\n",
      "368:\tlearn: 19021.6023943\ttotal: 1.99s\tremaining: 3.4s\n",
      "369:\tlearn: 19016.6401064\ttotal: 2s\tremaining: 3.4s\n",
      "370:\tlearn: 18990.8135541\ttotal: 2s\tremaining: 3.4s\n",
      "371:\tlearn: 18977.8973241\ttotal: 2.01s\tremaining: 3.39s\n",
      "372:\tlearn: 18967.3282918\ttotal: 2.01s\tremaining: 3.38s\n",
      "373:\tlearn: 18965.5153511\ttotal: 2.02s\tremaining: 3.38s\n",
      "374:\tlearn: 18960.7258211\ttotal: 2.02s\tremaining: 3.37s\n",
      "375:\tlearn: 18954.4865999\ttotal: 2.03s\tremaining: 3.37s\n",
      "376:\tlearn: 18949.5683521\ttotal: 2.03s\tremaining: 3.36s\n",
      "377:\tlearn: 18947.9539902\ttotal: 2.04s\tremaining: 3.35s\n",
      "378:\tlearn: 18933.9116343\ttotal: 2.04s\tremaining: 3.35s\n",
      "379:\tlearn: 18929.6736266\ttotal: 2.05s\tremaining: 3.34s\n",
      "380:\tlearn: 18924.6812585\ttotal: 2.05s\tremaining: 3.34s\n",
      "381:\tlearn: 18923.1901953\ttotal: 2.06s\tremaining: 3.33s\n",
      "382:\tlearn: 18873.8792358\ttotal: 2.06s\tremaining: 3.32s\n",
      "383:\tlearn: 18863.9532832\ttotal: 2.07s\tremaining: 3.32s\n",
      "384:\tlearn: 18860.9723912\ttotal: 2.07s\tremaining: 3.31s\n",
      "385:\tlearn: 18856.8485088\ttotal: 2.08s\tremaining: 3.31s\n",
      "386:\tlearn: 18848.6739268\ttotal: 2.08s\tremaining: 3.3s\n",
      "387:\tlearn: 18846.1027832\ttotal: 2.09s\tremaining: 3.29s\n",
      "388:\tlearn: 18845.3210326\ttotal: 2.1s\tremaining: 3.29s\n",
      "389:\tlearn: 18844.4153691\ttotal: 2.1s\tremaining: 3.29s\n",
      "390:\tlearn: 18822.3296058\ttotal: 2.11s\tremaining: 3.28s\n",
      "391:\tlearn: 18816.1985452\ttotal: 2.11s\tremaining: 3.28s\n",
      "392:\tlearn: 18805.5957536\ttotal: 2.12s\tremaining: 3.27s\n",
      "393:\tlearn: 18804.0644210\ttotal: 2.12s\tremaining: 3.26s\n",
      "394:\tlearn: 18795.5794779\ttotal: 2.13s\tremaining: 3.26s\n",
      "395:\tlearn: 18759.2977071\ttotal: 2.13s\tremaining: 3.25s\n",
      "396:\tlearn: 18758.4425623\ttotal: 2.14s\tremaining: 3.25s\n",
      "397:\tlearn: 18751.8323302\ttotal: 2.14s\tremaining: 3.24s\n",
      "398:\tlearn: 18731.1153871\ttotal: 2.15s\tremaining: 3.23s\n",
      "399:\tlearn: 18726.5874361\ttotal: 2.15s\tremaining: 3.23s\n",
      "400:\tlearn: 18718.5000144\ttotal: 2.16s\tremaining: 3.22s\n",
      "401:\tlearn: 18716.3378020\ttotal: 2.16s\tremaining: 3.22s\n",
      "402:\tlearn: 18692.8631831\ttotal: 2.17s\tremaining: 3.21s\n",
      "403:\tlearn: 18691.0511100\ttotal: 2.17s\tremaining: 3.21s\n",
      "404:\tlearn: 18689.4136673\ttotal: 2.18s\tremaining: 3.2s\n",
      "405:\tlearn: 18687.9220900\ttotal: 2.19s\tremaining: 3.2s\n",
      "406:\tlearn: 18665.2657650\ttotal: 2.19s\tremaining: 3.2s\n",
      "407:\tlearn: 18657.6358230\ttotal: 2.2s\tremaining: 3.19s\n",
      "408:\tlearn: 18656.3912927\ttotal: 2.2s\tremaining: 3.19s\n",
      "409:\tlearn: 18655.6559808\ttotal: 2.21s\tremaining: 3.18s\n",
      "410:\tlearn: 18654.1356226\ttotal: 2.21s\tremaining: 3.17s\n",
      "411:\tlearn: 18651.9987995\ttotal: 2.22s\tremaining: 3.17s\n",
      "412:\tlearn: 18651.3823249\ttotal: 2.22s\tremaining: 3.16s\n",
      "413:\tlearn: 18615.9623612\ttotal: 2.23s\tremaining: 3.15s\n",
      "414:\tlearn: 18615.2401541\ttotal: 2.23s\tremaining: 3.15s\n",
      "415:\tlearn: 18609.0293419\ttotal: 2.24s\tremaining: 3.14s\n",
      "416:\tlearn: 18607.5785551\ttotal: 2.24s\tremaining: 3.14s\n",
      "417:\tlearn: 18604.5051832\ttotal: 2.25s\tremaining: 3.13s\n",
      "418:\tlearn: 18591.5762593\ttotal: 2.25s\tremaining: 3.13s\n",
      "419:\tlearn: 18588.6863872\ttotal: 2.26s\tremaining: 3.12s\n",
      "420:\tlearn: 18586.0287349\ttotal: 2.26s\tremaining: 3.11s\n",
      "421:\tlearn: 18578.5226179\ttotal: 2.27s\tremaining: 3.11s\n",
      "422:\tlearn: 18559.8767198\ttotal: 2.27s\tremaining: 3.1s\n",
      "423:\tlearn: 18542.1473647\ttotal: 2.28s\tremaining: 3.1s\n",
      "424:\tlearn: 18537.8478351\ttotal: 2.29s\tremaining: 3.09s\n",
      "425:\tlearn: 18534.7871929\ttotal: 2.29s\tremaining: 3.09s\n",
      "426:\tlearn: 18530.3305421\ttotal: 2.3s\tremaining: 3.08s\n",
      "427:\tlearn: 18516.4804140\ttotal: 2.3s\tremaining: 3.08s\n",
      "428:\tlearn: 18514.3411854\ttotal: 2.31s\tremaining: 3.07s\n",
      "429:\tlearn: 18462.9824512\ttotal: 2.31s\tremaining: 3.07s\n",
      "430:\tlearn: 18454.5890101\ttotal: 2.32s\tremaining: 3.06s\n",
      "431:\tlearn: 18447.8958633\ttotal: 2.32s\tremaining: 3.05s\n",
      "432:\tlearn: 18436.3345309\ttotal: 2.33s\tremaining: 3.05s\n",
      "433:\tlearn: 18428.8198358\ttotal: 2.33s\tremaining: 3.04s\n",
      "434:\tlearn: 18420.4160517\ttotal: 2.34s\tremaining: 3.04s\n",
      "435:\tlearn: 18405.6645566\ttotal: 2.34s\tremaining: 3.03s\n",
      "436:\tlearn: 18404.6329690\ttotal: 2.35s\tremaining: 3.02s\n",
      "437:\tlearn: 18389.7986549\ttotal: 2.35s\tremaining: 3.02s\n",
      "438:\tlearn: 18388.6584641\ttotal: 2.36s\tremaining: 3.02s\n",
      "439:\tlearn: 18378.1956000\ttotal: 2.37s\tremaining: 3.01s\n",
      "440:\tlearn: 18377.9030536\ttotal: 2.37s\tremaining: 3s\n",
      "441:\tlearn: 18370.5452557\ttotal: 2.38s\tremaining: 3s\n",
      "442:\tlearn: 18362.9719187\ttotal: 2.38s\tremaining: 3s\n",
      "443:\tlearn: 18325.2549343\ttotal: 2.39s\tremaining: 2.99s\n",
      "444:\tlearn: 18321.6372477\ttotal: 2.39s\tremaining: 2.98s\n",
      "445:\tlearn: 18319.3733179\ttotal: 2.4s\tremaining: 2.98s\n",
      "446:\tlearn: 18312.8707721\ttotal: 2.4s\tremaining: 2.97s\n",
      "447:\tlearn: 18311.5919657\ttotal: 2.41s\tremaining: 2.97s\n",
      "448:\tlearn: 18299.7427111\ttotal: 2.41s\tremaining: 2.96s\n",
      "449:\tlearn: 18298.8601908\ttotal: 2.42s\tremaining: 2.96s\n",
      "450:\tlearn: 18295.4376859\ttotal: 2.42s\tremaining: 2.95s\n",
      "451:\tlearn: 18290.4263592\ttotal: 2.43s\tremaining: 2.94s\n",
      "452:\tlearn: 18289.4115117\ttotal: 2.43s\tremaining: 2.94s\n",
      "453:\tlearn: 18266.9814881\ttotal: 2.44s\tremaining: 2.93s\n",
      "454:\tlearn: 18247.3756091\ttotal: 2.44s\tremaining: 2.93s\n",
      "455:\tlearn: 18226.6351501\ttotal: 2.45s\tremaining: 2.92s\n",
      "456:\tlearn: 18205.7052472\ttotal: 2.45s\tremaining: 2.91s\n",
      "457:\tlearn: 18205.0075935\ttotal: 2.46s\tremaining: 2.91s\n",
      "458:\tlearn: 18202.7580080\ttotal: 2.46s\tremaining: 2.9s\n",
      "459:\tlearn: 18195.7993614\ttotal: 2.47s\tremaining: 2.9s\n",
      "460:\tlearn: 18192.2389042\ttotal: 2.48s\tremaining: 2.9s\n",
      "461:\tlearn: 18191.4675057\ttotal: 2.48s\tremaining: 2.89s\n",
      "462:\tlearn: 18150.9182980\ttotal: 2.49s\tremaining: 2.88s\n",
      "463:\tlearn: 18148.9063553\ttotal: 2.49s\tremaining: 2.88s\n",
      "464:\tlearn: 18147.2115666\ttotal: 2.5s\tremaining: 2.87s\n",
      "465:\tlearn: 18146.1674282\ttotal: 2.5s\tremaining: 2.87s\n",
      "466:\tlearn: 18145.5573288\ttotal: 2.5s\tremaining: 2.86s\n",
      "467:\tlearn: 18130.8670428\ttotal: 2.51s\tremaining: 2.85s\n",
      "468:\tlearn: 18117.0279736\ttotal: 2.52s\tremaining: 2.85s\n",
      "469:\tlearn: 18098.8664306\ttotal: 2.52s\tremaining: 2.84s\n",
      "470:\tlearn: 18087.6373067\ttotal: 2.52s\tremaining: 2.84s\n",
      "471:\tlearn: 18082.3864231\ttotal: 2.53s\tremaining: 2.83s\n",
      "472:\tlearn: 18079.4564113\ttotal: 2.54s\tremaining: 2.82s\n",
      "473:\tlearn: 18069.6726052\ttotal: 2.54s\tremaining: 2.82s\n",
      "474:\tlearn: 18069.1046644\ttotal: 2.55s\tremaining: 2.82s\n",
      "475:\tlearn: 18055.8297793\ttotal: 2.56s\tremaining: 2.81s\n",
      "476:\tlearn: 18048.0981770\ttotal: 2.56s\tremaining: 2.81s\n",
      "477:\tlearn: 18046.4014461\ttotal: 2.57s\tremaining: 2.81s\n",
      "478:\tlearn: 18043.8145589\ttotal: 2.57s\tremaining: 2.8s\n",
      "479:\tlearn: 18042.8263508\ttotal: 2.58s\tremaining: 2.79s\n",
      "480:\tlearn: 18041.9876493\ttotal: 2.58s\tremaining: 2.79s\n",
      "481:\tlearn: 18020.8005173\ttotal: 2.59s\tremaining: 2.78s\n",
      "482:\tlearn: 18014.5590508\ttotal: 2.59s\tremaining: 2.78s\n",
      "483:\tlearn: 18013.4827060\ttotal: 2.6s\tremaining: 2.77s\n",
      "484:\tlearn: 18009.3979219\ttotal: 2.6s\tremaining: 2.76s\n",
      "485:\tlearn: 18008.3869526\ttotal: 2.61s\tremaining: 2.76s\n",
      "486:\tlearn: 18006.3093809\ttotal: 2.61s\tremaining: 2.75s\n",
      "487:\tlearn: 17995.5028258\ttotal: 2.62s\tremaining: 2.75s\n",
      "488:\tlearn: 17990.5494244\ttotal: 2.62s\tremaining: 2.74s\n",
      "489:\tlearn: 17987.2484120\ttotal: 2.63s\tremaining: 2.73s\n",
      "490:\tlearn: 17986.3601465\ttotal: 2.63s\tremaining: 2.73s\n",
      "491:\tlearn: 17983.5139441\ttotal: 2.64s\tremaining: 2.72s\n",
      "492:\tlearn: 17970.3310017\ttotal: 2.64s\tremaining: 2.72s\n",
      "493:\tlearn: 17953.2824809\ttotal: 2.65s\tremaining: 2.71s\n",
      "494:\tlearn: 17951.1657344\ttotal: 2.65s\tremaining: 2.71s\n",
      "495:\tlearn: 17943.2447745\ttotal: 2.66s\tremaining: 2.7s\n",
      "496:\tlearn: 17931.3192492\ttotal: 2.66s\tremaining: 2.7s\n",
      "497:\tlearn: 17925.0792438\ttotal: 2.67s\tremaining: 2.69s\n",
      "498:\tlearn: 17920.0676998\ttotal: 2.67s\tremaining: 2.69s\n",
      "499:\tlearn: 17916.8581837\ttotal: 2.68s\tremaining: 2.68s\n",
      "500:\tlearn: 17898.5167680\ttotal: 2.68s\tremaining: 2.67s\n",
      "501:\tlearn: 17894.9269450\ttotal: 2.69s\tremaining: 2.67s\n",
      "502:\tlearn: 17883.8539722\ttotal: 2.69s\tremaining: 2.66s\n",
      "503:\tlearn: 17883.6240741\ttotal: 2.7s\tremaining: 2.66s\n",
      "504:\tlearn: 17877.2535260\ttotal: 2.7s\tremaining: 2.65s\n",
      "505:\tlearn: 17874.9896059\ttotal: 2.71s\tremaining: 2.65s\n",
      "506:\tlearn: 17872.6309678\ttotal: 2.71s\tremaining: 2.64s\n",
      "507:\tlearn: 17869.3648166\ttotal: 2.72s\tremaining: 2.63s\n",
      "508:\tlearn: 17849.1471057\ttotal: 2.72s\tremaining: 2.63s\n",
      "509:\tlearn: 17847.2793873\ttotal: 2.73s\tremaining: 2.62s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510:\tlearn: 17804.4898927\ttotal: 2.73s\tremaining: 2.62s\n",
      "511:\tlearn: 17801.6730251\ttotal: 2.74s\tremaining: 2.61s\n",
      "512:\tlearn: 17801.4615427\ttotal: 2.74s\tremaining: 2.6s\n",
      "513:\tlearn: 17795.2088929\ttotal: 2.75s\tremaining: 2.6s\n",
      "514:\tlearn: 17793.3944530\ttotal: 2.76s\tremaining: 2.6s\n",
      "515:\tlearn: 17792.1221739\ttotal: 2.76s\tremaining: 2.59s\n",
      "516:\tlearn: 17791.1419709\ttotal: 2.77s\tremaining: 2.58s\n",
      "517:\tlearn: 17790.6731898\ttotal: 2.77s\tremaining: 2.58s\n",
      "518:\tlearn: 17783.1442852\ttotal: 2.78s\tremaining: 2.57s\n",
      "519:\tlearn: 17763.7299432\ttotal: 2.78s\tremaining: 2.57s\n",
      "520:\tlearn: 17759.6429001\ttotal: 2.79s\tremaining: 2.56s\n",
      "521:\tlearn: 17723.0831583\ttotal: 2.79s\tremaining: 2.56s\n",
      "522:\tlearn: 17720.5285996\ttotal: 2.8s\tremaining: 2.55s\n",
      "523:\tlearn: 17715.9559707\ttotal: 2.8s\tremaining: 2.54s\n",
      "524:\tlearn: 17710.9428024\ttotal: 2.81s\tremaining: 2.54s\n",
      "525:\tlearn: 17710.2097512\ttotal: 2.81s\tremaining: 2.53s\n",
      "526:\tlearn: 17704.9971434\ttotal: 2.82s\tremaining: 2.53s\n",
      "527:\tlearn: 17700.6974840\ttotal: 2.82s\tremaining: 2.52s\n",
      "528:\tlearn: 17686.9052069\ttotal: 2.83s\tremaining: 2.52s\n",
      "529:\tlearn: 17684.9231426\ttotal: 2.83s\tremaining: 2.51s\n",
      "530:\tlearn: 17674.3137950\ttotal: 2.84s\tremaining: 2.5s\n",
      "531:\tlearn: 17674.0569204\ttotal: 2.84s\tremaining: 2.5s\n",
      "532:\tlearn: 17672.9355399\ttotal: 2.85s\tremaining: 2.49s\n",
      "533:\tlearn: 17661.5823843\ttotal: 2.85s\tremaining: 2.49s\n",
      "534:\tlearn: 17659.6069049\ttotal: 2.86s\tremaining: 2.48s\n",
      "535:\tlearn: 17658.5683304\ttotal: 2.86s\tremaining: 2.48s\n",
      "536:\tlearn: 17648.2090376\ttotal: 2.87s\tremaining: 2.47s\n",
      "537:\tlearn: 17646.2377254\ttotal: 2.88s\tremaining: 2.47s\n",
      "538:\tlearn: 17643.3251691\ttotal: 2.88s\tremaining: 2.47s\n",
      "539:\tlearn: 17637.7125638\ttotal: 2.89s\tremaining: 2.46s\n",
      "540:\tlearn: 17632.9907810\ttotal: 2.9s\tremaining: 2.46s\n",
      "541:\tlearn: 17628.7710223\ttotal: 2.9s\tremaining: 2.45s\n",
      "542:\tlearn: 17627.6011028\ttotal: 2.91s\tremaining: 2.45s\n",
      "543:\tlearn: 17621.1816962\ttotal: 2.91s\tremaining: 2.44s\n",
      "544:\tlearn: 17618.4825391\ttotal: 2.92s\tremaining: 2.44s\n",
      "545:\tlearn: 17613.9263272\ttotal: 2.92s\tremaining: 2.43s\n",
      "546:\tlearn: 17609.9432045\ttotal: 2.93s\tremaining: 2.43s\n",
      "547:\tlearn: 17607.8298716\ttotal: 2.94s\tremaining: 2.42s\n",
      "548:\tlearn: 17607.0240930\ttotal: 2.94s\tremaining: 2.42s\n",
      "549:\tlearn: 17600.6941377\ttotal: 2.95s\tremaining: 2.41s\n",
      "550:\tlearn: 17595.6748079\ttotal: 2.95s\tremaining: 2.41s\n",
      "551:\tlearn: 17589.1187452\ttotal: 2.96s\tremaining: 2.4s\n",
      "552:\tlearn: 17582.0985364\ttotal: 2.96s\tremaining: 2.4s\n",
      "553:\tlearn: 17572.7947528\ttotal: 2.97s\tremaining: 2.39s\n",
      "554:\tlearn: 17565.3916936\ttotal: 2.98s\tremaining: 2.39s\n",
      "555:\tlearn: 17525.1406681\ttotal: 2.98s\tremaining: 2.38s\n",
      "556:\tlearn: 17523.6507042\ttotal: 2.98s\tremaining: 2.37s\n",
      "557:\tlearn: 17515.7719899\ttotal: 2.99s\tremaining: 2.37s\n",
      "558:\tlearn: 17515.4982876\ttotal: 3s\tremaining: 2.36s\n",
      "559:\tlearn: 17503.3706845\ttotal: 3s\tremaining: 2.36s\n",
      "560:\tlearn: 17493.7852138\ttotal: 3s\tremaining: 2.35s\n",
      "561:\tlearn: 17492.9652797\ttotal: 3.01s\tremaining: 2.35s\n",
      "562:\tlearn: 17482.6759392\ttotal: 3.02s\tremaining: 2.34s\n",
      "563:\tlearn: 17480.4701948\ttotal: 3.02s\tremaining: 2.33s\n",
      "564:\tlearn: 17478.6148007\ttotal: 3.02s\tremaining: 2.33s\n",
      "565:\tlearn: 17475.3352064\ttotal: 3.03s\tremaining: 2.32s\n",
      "566:\tlearn: 17462.4540673\ttotal: 3.04s\tremaining: 2.32s\n",
      "567:\tlearn: 17459.0443064\ttotal: 3.04s\tremaining: 2.31s\n",
      "568:\tlearn: 17457.3056081\ttotal: 3.04s\tremaining: 2.31s\n",
      "569:\tlearn: 17454.3986990\ttotal: 3.05s\tremaining: 2.3s\n",
      "570:\tlearn: 17449.8458856\ttotal: 3.05s\tremaining: 2.29s\n",
      "571:\tlearn: 17449.0755436\ttotal: 3.06s\tremaining: 2.29s\n",
      "572:\tlearn: 17446.8598489\ttotal: 3.06s\tremaining: 2.28s\n",
      "573:\tlearn: 17445.3188205\ttotal: 3.07s\tremaining: 2.28s\n",
      "574:\tlearn: 17435.4893774\ttotal: 3.07s\tremaining: 2.27s\n",
      "575:\tlearn: 17405.3740437\ttotal: 3.08s\tremaining: 2.27s\n",
      "576:\tlearn: 17404.7211390\ttotal: 3.08s\tremaining: 2.26s\n",
      "577:\tlearn: 17404.0784097\ttotal: 3.08s\tremaining: 2.25s\n",
      "578:\tlearn: 17403.7275854\ttotal: 3.09s\tremaining: 2.25s\n",
      "579:\tlearn: 17403.1493233\ttotal: 3.09s\tremaining: 2.24s\n",
      "580:\tlearn: 17403.0323882\ttotal: 3.1s\tremaining: 2.23s\n",
      "581:\tlearn: 17394.8022710\ttotal: 3.1s\tremaining: 2.23s\n",
      "582:\tlearn: 17393.4481407\ttotal: 3.11s\tremaining: 2.22s\n",
      "583:\tlearn: 17391.9275907\ttotal: 3.11s\tremaining: 2.22s\n",
      "584:\tlearn: 17388.3620825\ttotal: 3.12s\tremaining: 2.21s\n",
      "585:\tlearn: 17387.9293275\ttotal: 3.12s\tremaining: 2.21s\n",
      "586:\tlearn: 17384.0939872\ttotal: 3.13s\tremaining: 2.2s\n",
      "587:\tlearn: 17378.7415817\ttotal: 3.14s\tremaining: 2.2s\n",
      "588:\tlearn: 17376.7674402\ttotal: 3.14s\tremaining: 2.19s\n",
      "589:\tlearn: 17371.1476496\ttotal: 3.15s\tremaining: 2.19s\n",
      "590:\tlearn: 17341.4296236\ttotal: 3.15s\tremaining: 2.18s\n",
      "591:\tlearn: 17331.8591487\ttotal: 3.16s\tremaining: 2.18s\n",
      "592:\tlearn: 17330.9592537\ttotal: 3.16s\tremaining: 2.17s\n",
      "593:\tlearn: 17327.7253106\ttotal: 3.17s\tremaining: 2.17s\n",
      "594:\tlearn: 17298.4187513\ttotal: 3.17s\tremaining: 2.16s\n",
      "595:\tlearn: 17285.1800035\ttotal: 3.18s\tremaining: 2.15s\n",
      "596:\tlearn: 17253.0028739\ttotal: 3.18s\tremaining: 2.15s\n",
      "597:\tlearn: 17240.1292719\ttotal: 3.19s\tremaining: 2.14s\n",
      "598:\tlearn: 17232.9293751\ttotal: 3.19s\tremaining: 2.14s\n",
      "599:\tlearn: 17232.3203115\ttotal: 3.2s\tremaining: 2.13s\n",
      "600:\tlearn: 17229.1209863\ttotal: 3.2s\tremaining: 2.13s\n",
      "601:\tlearn: 17228.4883142\ttotal: 3.21s\tremaining: 2.12s\n",
      "602:\tlearn: 17227.6048327\ttotal: 3.21s\tremaining: 2.11s\n",
      "603:\tlearn: 17222.0985481\ttotal: 3.22s\tremaining: 2.11s\n",
      "604:\tlearn: 17220.2365028\ttotal: 3.22s\tremaining: 2.1s\n",
      "605:\tlearn: 17206.9593440\ttotal: 3.23s\tremaining: 2.1s\n",
      "606:\tlearn: 17206.0296527\ttotal: 3.23s\tremaining: 2.09s\n",
      "607:\tlearn: 17201.3550206\ttotal: 3.24s\tremaining: 2.09s\n",
      "608:\tlearn: 17194.5920508\ttotal: 3.24s\tremaining: 2.08s\n",
      "609:\tlearn: 17192.4601755\ttotal: 3.25s\tremaining: 2.08s\n",
      "610:\tlearn: 17188.7085240\ttotal: 3.25s\tremaining: 2.07s\n",
      "611:\tlearn: 17188.6741573\ttotal: 3.26s\tremaining: 2.06s\n",
      "612:\tlearn: 17168.4648112\ttotal: 3.26s\tremaining: 2.06s\n",
      "613:\tlearn: 17154.2487463\ttotal: 3.27s\tremaining: 2.05s\n",
      "614:\tlearn: 17151.6670569\ttotal: 3.27s\tremaining: 2.05s\n",
      "615:\tlearn: 17146.3054878\ttotal: 3.27s\tremaining: 2.04s\n",
      "616:\tlearn: 17145.4273399\ttotal: 3.28s\tremaining: 2.04s\n",
      "617:\tlearn: 17144.8442214\ttotal: 3.29s\tremaining: 2.03s\n",
      "618:\tlearn: 17135.1095407\ttotal: 3.29s\tremaining: 2.02s\n",
      "619:\tlearn: 17133.0932922\ttotal: 3.29s\tremaining: 2.02s\n",
      "620:\tlearn: 17130.5302137\ttotal: 3.3s\tremaining: 2.01s\n",
      "621:\tlearn: 17129.0909336\ttotal: 3.3s\tremaining: 2.01s\n",
      "622:\tlearn: 17125.8329901\ttotal: 3.31s\tremaining: 2s\n",
      "623:\tlearn: 17124.4706520\ttotal: 3.31s\tremaining: 2s\n",
      "624:\tlearn: 17120.8838769\ttotal: 3.32s\tremaining: 1.99s\n",
      "625:\tlearn: 17119.8854816\ttotal: 3.33s\tremaining: 1.99s\n",
      "626:\tlearn: 17107.5802409\ttotal: 3.33s\tremaining: 1.98s\n",
      "627:\tlearn: 17106.3871957\ttotal: 3.34s\tremaining: 1.98s\n",
      "628:\tlearn: 17092.5576077\ttotal: 3.35s\tremaining: 1.97s\n",
      "629:\tlearn: 17081.3236423\ttotal: 3.35s\tremaining: 1.97s\n",
      "630:\tlearn: 17080.3448424\ttotal: 3.36s\tremaining: 1.96s\n",
      "631:\tlearn: 17077.1149321\ttotal: 3.36s\tremaining: 1.96s\n",
      "632:\tlearn: 17076.8894626\ttotal: 3.37s\tremaining: 1.95s\n",
      "633:\tlearn: 17075.6441539\ttotal: 3.37s\tremaining: 1.95s\n",
      "634:\tlearn: 17074.8913880\ttotal: 3.38s\tremaining: 1.94s\n",
      "635:\tlearn: 17071.3647564\ttotal: 3.38s\tremaining: 1.94s\n",
      "636:\tlearn: 17058.1804506\ttotal: 3.39s\tremaining: 1.93s\n",
      "637:\tlearn: 17057.9338316\ttotal: 3.39s\tremaining: 1.92s\n",
      "638:\tlearn: 17057.1089615\ttotal: 3.4s\tremaining: 1.92s\n",
      "639:\tlearn: 17056.3911073\ttotal: 3.4s\tremaining: 1.91s\n",
      "640:\tlearn: 17054.0637396\ttotal: 3.4s\tremaining: 1.91s\n",
      "641:\tlearn: 17052.5824664\ttotal: 3.41s\tremaining: 1.9s\n",
      "642:\tlearn: 17050.3214124\ttotal: 3.42s\tremaining: 1.9s\n",
      "643:\tlearn: 17021.3154535\ttotal: 3.43s\tremaining: 1.89s\n",
      "644:\tlearn: 17013.4186041\ttotal: 3.43s\tremaining: 1.89s\n",
      "645:\tlearn: 17011.3098304\ttotal: 3.44s\tremaining: 1.88s\n",
      "646:\tlearn: 17010.8834121\ttotal: 3.44s\tremaining: 1.88s\n",
      "647:\tlearn: 17010.3449642\ttotal: 3.45s\tremaining: 1.87s\n",
      "648:\tlearn: 17010.1541263\ttotal: 3.45s\tremaining: 1.87s\n",
      "649:\tlearn: 17009.5805231\ttotal: 3.46s\tremaining: 1.86s\n",
      "650:\tlearn: 17009.3972456\ttotal: 3.46s\tremaining: 1.86s\n",
      "651:\tlearn: 16991.2434636\ttotal: 3.47s\tremaining: 1.85s\n",
      "652:\tlearn: 16989.8053334\ttotal: 3.47s\tremaining: 1.84s\n",
      "653:\tlearn: 16987.2800458\ttotal: 3.48s\tremaining: 1.84s\n",
      "654:\tlearn: 16986.6760650\ttotal: 3.48s\tremaining: 1.83s\n",
      "655:\tlearn: 16986.1453155\ttotal: 3.49s\tremaining: 1.83s\n",
      "656:\tlearn: 16985.1083192\ttotal: 3.49s\tremaining: 1.82s\n",
      "657:\tlearn: 16959.3815387\ttotal: 3.5s\tremaining: 1.82s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658:\tlearn: 16958.6384563\ttotal: 3.5s\tremaining: 1.81s\n",
      "659:\tlearn: 16955.8400309\ttotal: 3.51s\tremaining: 1.81s\n",
      "660:\tlearn: 16955.6772814\ttotal: 3.52s\tremaining: 1.8s\n",
      "661:\tlearn: 16951.9962189\ttotal: 3.52s\tremaining: 1.8s\n",
      "662:\tlearn: 16950.6811535\ttotal: 3.53s\tremaining: 1.79s\n",
      "663:\tlearn: 16944.5238150\ttotal: 3.54s\tremaining: 1.79s\n",
      "664:\tlearn: 16943.9408566\ttotal: 3.54s\tremaining: 1.78s\n",
      "665:\tlearn: 16938.7720679\ttotal: 3.55s\tremaining: 1.78s\n",
      "666:\tlearn: 16932.7275170\ttotal: 3.55s\tremaining: 1.77s\n",
      "667:\tlearn: 16932.3104762\ttotal: 3.56s\tremaining: 1.77s\n",
      "668:\tlearn: 16931.3577506\ttotal: 3.56s\tremaining: 1.76s\n",
      "669:\tlearn: 16931.1829009\ttotal: 3.57s\tremaining: 1.76s\n",
      "670:\tlearn: 16921.8712997\ttotal: 3.57s\tremaining: 1.75s\n",
      "671:\tlearn: 16913.6748456\ttotal: 3.58s\tremaining: 1.75s\n",
      "672:\tlearn: 16906.8053963\ttotal: 3.58s\tremaining: 1.74s\n",
      "673:\tlearn: 16901.4455518\ttotal: 3.59s\tremaining: 1.73s\n",
      "674:\tlearn: 16900.6473980\ttotal: 3.59s\tremaining: 1.73s\n",
      "675:\tlearn: 16899.7705779\ttotal: 3.6s\tremaining: 1.72s\n",
      "676:\tlearn: 16895.6801339\ttotal: 3.6s\tremaining: 1.72s\n",
      "677:\tlearn: 16894.9658984\ttotal: 3.61s\tremaining: 1.71s\n",
      "678:\tlearn: 16894.3177471\ttotal: 3.61s\tremaining: 1.71s\n",
      "679:\tlearn: 16890.3451058\ttotal: 3.62s\tremaining: 1.7s\n",
      "680:\tlearn: 16889.9787413\ttotal: 3.62s\tremaining: 1.7s\n",
      "681:\tlearn: 16889.4381676\ttotal: 3.63s\tremaining: 1.69s\n",
      "682:\tlearn: 16883.3343092\ttotal: 3.63s\tremaining: 1.69s\n",
      "683:\tlearn: 16883.2059328\ttotal: 3.64s\tremaining: 1.68s\n",
      "684:\tlearn: 16882.2293059\ttotal: 3.64s\tremaining: 1.67s\n",
      "685:\tlearn: 16881.7384689\ttotal: 3.65s\tremaining: 1.67s\n",
      "686:\tlearn: 16879.9896446\ttotal: 3.65s\tremaining: 1.66s\n",
      "687:\tlearn: 16866.8254873\ttotal: 3.65s\tremaining: 1.66s\n",
      "688:\tlearn: 16864.6428196\ttotal: 3.66s\tremaining: 1.65s\n",
      "689:\tlearn: 16863.6549098\ttotal: 3.67s\tremaining: 1.65s\n",
      "690:\tlearn: 16862.1439178\ttotal: 3.67s\tremaining: 1.64s\n",
      "691:\tlearn: 16834.4020999\ttotal: 3.67s\tremaining: 1.64s\n",
      "692:\tlearn: 16833.0383012\ttotal: 3.68s\tremaining: 1.63s\n",
      "693:\tlearn: 16832.8153198\ttotal: 3.69s\tremaining: 1.62s\n",
      "694:\tlearn: 16832.6703718\ttotal: 3.69s\tremaining: 1.62s\n",
      "695:\tlearn: 16832.2031339\ttotal: 3.7s\tremaining: 1.61s\n",
      "696:\tlearn: 16831.8870016\ttotal: 3.7s\tremaining: 1.61s\n",
      "697:\tlearn: 16830.4503057\ttotal: 3.71s\tremaining: 1.6s\n",
      "698:\tlearn: 16828.0061446\ttotal: 3.72s\tremaining: 1.6s\n",
      "699:\tlearn: 16827.1827165\ttotal: 3.72s\tremaining: 1.59s\n",
      "700:\tlearn: 16824.8785078\ttotal: 3.73s\tremaining: 1.59s\n",
      "701:\tlearn: 16824.1000869\ttotal: 3.73s\tremaining: 1.58s\n",
      "702:\tlearn: 16823.9851489\ttotal: 3.74s\tremaining: 1.58s\n",
      "703:\tlearn: 16823.4075369\ttotal: 3.74s\tremaining: 1.57s\n",
      "704:\tlearn: 16823.1142102\ttotal: 3.75s\tremaining: 1.57s\n",
      "705:\tlearn: 16819.8776823\ttotal: 3.75s\tremaining: 1.56s\n",
      "706:\tlearn: 16817.7316682\ttotal: 3.76s\tremaining: 1.56s\n",
      "707:\tlearn: 16816.2347632\ttotal: 3.76s\tremaining: 1.55s\n",
      "708:\tlearn: 16816.0991463\ttotal: 3.77s\tremaining: 1.54s\n",
      "709:\tlearn: 16815.8727056\ttotal: 3.77s\tremaining: 1.54s\n",
      "710:\tlearn: 16810.5322776\ttotal: 3.78s\tremaining: 1.53s\n",
      "711:\tlearn: 16808.9330863\ttotal: 3.78s\tremaining: 1.53s\n",
      "712:\tlearn: 16807.9986312\ttotal: 3.79s\tremaining: 1.52s\n",
      "713:\tlearn: 16807.7282632\ttotal: 3.79s\tremaining: 1.52s\n",
      "714:\tlearn: 16805.4550819\ttotal: 3.8s\tremaining: 1.51s\n",
      "715:\tlearn: 16804.5103839\ttotal: 3.8s\tremaining: 1.51s\n",
      "716:\tlearn: 16785.6744835\ttotal: 3.81s\tremaining: 1.5s\n",
      "717:\tlearn: 16785.1902662\ttotal: 3.81s\tremaining: 1.5s\n",
      "718:\tlearn: 16770.2785237\ttotal: 3.82s\tremaining: 1.49s\n",
      "719:\tlearn: 16768.7778920\ttotal: 3.82s\tremaining: 1.49s\n",
      "720:\tlearn: 16767.4095355\ttotal: 3.83s\tremaining: 1.48s\n",
      "721:\tlearn: 16760.3501787\ttotal: 3.83s\tremaining: 1.48s\n",
      "722:\tlearn: 16760.0335588\ttotal: 3.84s\tremaining: 1.47s\n",
      "723:\tlearn: 16752.9260761\ttotal: 3.84s\tremaining: 1.46s\n",
      "724:\tlearn: 16751.7164075\ttotal: 3.85s\tremaining: 1.46s\n",
      "725:\tlearn: 16743.1731583\ttotal: 3.85s\tremaining: 1.45s\n",
      "726:\tlearn: 16742.3968228\ttotal: 3.86s\tremaining: 1.45s\n",
      "727:\tlearn: 16739.9949078\ttotal: 3.86s\tremaining: 1.44s\n",
      "728:\tlearn: 16739.5710127\ttotal: 3.87s\tremaining: 1.44s\n",
      "729:\tlearn: 16739.2102782\ttotal: 3.87s\tremaining: 1.43s\n",
      "730:\tlearn: 16738.2522365\ttotal: 3.88s\tremaining: 1.43s\n",
      "731:\tlearn: 16733.7195524\ttotal: 3.88s\tremaining: 1.42s\n",
      "732:\tlearn: 16733.5044474\ttotal: 3.89s\tremaining: 1.42s\n",
      "733:\tlearn: 16733.3079224\ttotal: 3.9s\tremaining: 1.41s\n",
      "734:\tlearn: 16732.7304366\ttotal: 3.91s\tremaining: 1.41s\n",
      "735:\tlearn: 16731.8808297\ttotal: 3.91s\tremaining: 1.4s\n",
      "736:\tlearn: 16731.5683019\ttotal: 3.92s\tremaining: 1.4s\n",
      "737:\tlearn: 16730.7794733\ttotal: 3.92s\tremaining: 1.39s\n",
      "738:\tlearn: 16730.6039993\ttotal: 3.93s\tremaining: 1.39s\n",
      "739:\tlearn: 16729.1196110\ttotal: 3.93s\tremaining: 1.38s\n",
      "740:\tlearn: 16728.4813448\ttotal: 3.94s\tremaining: 1.38s\n",
      "741:\tlearn: 16727.8071972\ttotal: 3.94s\tremaining: 1.37s\n",
      "742:\tlearn: 16726.1464690\ttotal: 3.95s\tremaining: 1.36s\n",
      "743:\tlearn: 16718.0540573\ttotal: 3.95s\tremaining: 1.36s\n",
      "744:\tlearn: 16717.8992332\ttotal: 3.95s\tremaining: 1.35s\n",
      "745:\tlearn: 16716.5139105\ttotal: 3.96s\tremaining: 1.35s\n",
      "746:\tlearn: 16716.3565948\ttotal: 3.96s\tremaining: 1.34s\n",
      "747:\tlearn: 16701.6257799\ttotal: 3.97s\tremaining: 1.34s\n",
      "748:\tlearn: 16700.4856856\ttotal: 3.97s\tremaining: 1.33s\n",
      "749:\tlearn: 16700.4364591\ttotal: 3.98s\tremaining: 1.32s\n",
      "750:\tlearn: 16696.6166607\ttotal: 3.98s\tremaining: 1.32s\n",
      "751:\tlearn: 16694.9026551\ttotal: 3.99s\tremaining: 1.31s\n",
      "752:\tlearn: 16694.8285702\ttotal: 3.99s\tremaining: 1.31s\n",
      "753:\tlearn: 16690.3680690\ttotal: 4s\tremaining: 1.3s\n",
      "754:\tlearn: 16690.2355151\ttotal: 4s\tremaining: 1.3s\n",
      "755:\tlearn: 16657.9324882\ttotal: 4.01s\tremaining: 1.29s\n",
      "756:\tlearn: 16657.5817056\ttotal: 4.01s\tremaining: 1.29s\n",
      "757:\tlearn: 16656.0641413\ttotal: 4.02s\tremaining: 1.28s\n",
      "758:\tlearn: 16655.4659061\ttotal: 4.02s\tremaining: 1.28s\n",
      "759:\tlearn: 16655.1998137\ttotal: 4.03s\tremaining: 1.27s\n",
      "760:\tlearn: 16654.9276331\ttotal: 4.03s\tremaining: 1.27s\n",
      "761:\tlearn: 16654.5138481\ttotal: 4.04s\tremaining: 1.26s\n",
      "762:\tlearn: 16652.6511027\ttotal: 4.04s\tremaining: 1.25s\n",
      "763:\tlearn: 16650.7301489\ttotal: 4.05s\tremaining: 1.25s\n",
      "764:\tlearn: 16650.4107260\ttotal: 4.05s\tremaining: 1.24s\n",
      "765:\tlearn: 16649.6489685\ttotal: 4.06s\tremaining: 1.24s\n",
      "766:\tlearn: 16649.4735070\ttotal: 4.06s\tremaining: 1.23s\n",
      "767:\tlearn: 16646.9011458\ttotal: 4.07s\tremaining: 1.23s\n",
      "768:\tlearn: 16646.4163462\ttotal: 4.08s\tremaining: 1.22s\n",
      "769:\tlearn: 16645.9291336\ttotal: 4.08s\tremaining: 1.22s\n",
      "770:\tlearn: 16638.4846683\ttotal: 4.09s\tremaining: 1.21s\n",
      "771:\tlearn: 16638.1534317\ttotal: 4.09s\tremaining: 1.21s\n",
      "772:\tlearn: 16637.9770841\ttotal: 4.1s\tremaining: 1.2s\n",
      "773:\tlearn: 16636.9357212\ttotal: 4.11s\tremaining: 1.2s\n",
      "774:\tlearn: 16636.7266657\ttotal: 4.11s\tremaining: 1.19s\n",
      "775:\tlearn: 16636.2749285\ttotal: 4.12s\tremaining: 1.19s\n",
      "776:\tlearn: 16635.9355730\ttotal: 4.12s\tremaining: 1.18s\n",
      "777:\tlearn: 16624.9712126\ttotal: 4.13s\tremaining: 1.18s\n",
      "778:\tlearn: 16617.8824813\ttotal: 4.13s\tremaining: 1.17s\n",
      "779:\tlearn: 16612.1500438\ttotal: 4.13s\tremaining: 1.17s\n",
      "780:\tlearn: 16611.0196983\ttotal: 4.14s\tremaining: 1.16s\n",
      "781:\tlearn: 16610.5743949\ttotal: 4.14s\tremaining: 1.16s\n",
      "782:\tlearn: 16606.2051650\ttotal: 4.15s\tremaining: 1.15s\n",
      "783:\tlearn: 16581.4599683\ttotal: 4.16s\tremaining: 1.15s\n",
      "784:\tlearn: 16580.8087980\ttotal: 4.16s\tremaining: 1.14s\n",
      "785:\tlearn: 16580.2531107\ttotal: 4.17s\tremaining: 1.13s\n",
      "786:\tlearn: 16580.0138378\ttotal: 4.17s\tremaining: 1.13s\n",
      "787:\tlearn: 16579.4501953\ttotal: 4.18s\tremaining: 1.12s\n",
      "788:\tlearn: 16577.7369966\ttotal: 4.18s\tremaining: 1.12s\n",
      "789:\tlearn: 16571.9239812\ttotal: 4.19s\tremaining: 1.11s\n",
      "790:\tlearn: 16567.2700236\ttotal: 4.19s\tremaining: 1.11s\n",
      "791:\tlearn: 16567.1731590\ttotal: 4.19s\tremaining: 1.1s\n",
      "792:\tlearn: 16566.6882714\ttotal: 4.2s\tremaining: 1.1s\n",
      "793:\tlearn: 16565.8739045\ttotal: 4.2s\tremaining: 1.09s\n",
      "794:\tlearn: 16565.6516645\ttotal: 4.21s\tremaining: 1.08s\n",
      "795:\tlearn: 16563.7892690\ttotal: 4.21s\tremaining: 1.08s\n",
      "796:\tlearn: 16563.2235546\ttotal: 4.22s\tremaining: 1.07s\n",
      "797:\tlearn: 16563.0348231\ttotal: 4.22s\tremaining: 1.07s\n",
      "798:\tlearn: 16562.7575695\ttotal: 4.23s\tremaining: 1.06s\n",
      "799:\tlearn: 16560.3148874\ttotal: 4.23s\tremaining: 1.06s\n",
      "800:\tlearn: 16557.2080912\ttotal: 4.24s\tremaining: 1.05s\n",
      "801:\tlearn: 16556.7537396\ttotal: 4.24s\tremaining: 1.05s\n",
      "802:\tlearn: 16556.3305564\ttotal: 4.25s\tremaining: 1.04s\n",
      "803:\tlearn: 16544.2352616\ttotal: 4.25s\tremaining: 1.04s\n",
      "804:\tlearn: 16544.0400372\ttotal: 4.26s\tremaining: 1.03s\n",
      "805:\tlearn: 16543.7327137\ttotal: 4.26s\tremaining: 1.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806:\tlearn: 16543.4628713\ttotal: 4.27s\tremaining: 1.02s\n",
      "807:\tlearn: 16534.4597353\ttotal: 4.28s\tremaining: 1.01s\n",
      "808:\tlearn: 16534.0216485\ttotal: 4.28s\tremaining: 1.01s\n",
      "809:\tlearn: 16533.9336718\ttotal: 4.28s\tremaining: 1s\n",
      "810:\tlearn: 16533.5783442\ttotal: 4.29s\tremaining: 1000ms\n",
      "811:\tlearn: 16531.9966992\ttotal: 4.29s\tremaining: 994ms\n",
      "812:\tlearn: 16531.5965264\ttotal: 4.3s\tremaining: 989ms\n",
      "813:\tlearn: 16531.4965564\ttotal: 4.3s\tremaining: 984ms\n",
      "814:\tlearn: 16512.0351515\ttotal: 4.31s\tremaining: 978ms\n",
      "815:\tlearn: 16511.7900022\ttotal: 4.32s\tremaining: 973ms\n",
      "816:\tlearn: 16511.2411693\ttotal: 4.32s\tremaining: 968ms\n",
      "817:\tlearn: 16510.8413866\ttotal: 4.32s\tremaining: 962ms\n",
      "818:\tlearn: 16510.5128657\ttotal: 4.33s\tremaining: 957ms\n",
      "819:\tlearn: 16509.7321805\ttotal: 4.33s\tremaining: 951ms\n",
      "820:\tlearn: 16508.9831851\ttotal: 4.34s\tremaining: 946ms\n",
      "821:\tlearn: 16508.9066636\ttotal: 4.34s\tremaining: 941ms\n",
      "822:\tlearn: 16508.8313884\ttotal: 4.35s\tremaining: 935ms\n",
      "823:\tlearn: 16507.9047618\ttotal: 4.35s\tremaining: 930ms\n",
      "824:\tlearn: 16507.6377088\ttotal: 4.36s\tremaining: 925ms\n",
      "825:\tlearn: 16502.5730806\ttotal: 4.36s\tremaining: 919ms\n",
      "826:\tlearn: 16502.3286481\ttotal: 4.37s\tremaining: 914ms\n",
      "827:\tlearn: 16497.9364261\ttotal: 4.37s\tremaining: 909ms\n",
      "828:\tlearn: 16492.6439264\ttotal: 4.38s\tremaining: 903ms\n",
      "829:\tlearn: 16474.3182469\ttotal: 4.38s\tremaining: 898ms\n",
      "830:\tlearn: 16472.2350072\ttotal: 4.39s\tremaining: 893ms\n",
      "831:\tlearn: 16471.0323865\ttotal: 4.39s\tremaining: 887ms\n",
      "832:\tlearn: 16470.9624051\ttotal: 4.4s\tremaining: 881ms\n",
      "833:\tlearn: 16470.7885539\ttotal: 4.4s\tremaining: 876ms\n",
      "834:\tlearn: 16470.4187323\ttotal: 4.41s\tremaining: 871ms\n",
      "835:\tlearn: 16470.2227037\ttotal: 4.41s\tremaining: 865ms\n",
      "836:\tlearn: 16469.8343894\ttotal: 4.41s\tremaining: 859ms\n",
      "837:\tlearn: 16469.7647622\ttotal: 4.42s\tremaining: 853ms\n",
      "838:\tlearn: 16469.3028854\ttotal: 4.42s\tremaining: 848ms\n",
      "839:\tlearn: 16468.8485131\ttotal: 4.42s\tremaining: 843ms\n",
      "840:\tlearn: 16468.6803079\ttotal: 4.43s\tremaining: 838ms\n",
      "841:\tlearn: 16468.2250598\ttotal: 4.43s\tremaining: 832ms\n",
      "842:\tlearn: 16467.2767989\ttotal: 4.44s\tremaining: 827ms\n",
      "843:\tlearn: 16465.9341435\ttotal: 4.45s\tremaining: 822ms\n",
      "844:\tlearn: 16465.5571985\ttotal: 4.45s\tremaining: 816ms\n",
      "845:\tlearn: 16465.4403646\ttotal: 4.45s\tremaining: 811ms\n",
      "846:\tlearn: 16465.1609582\ttotal: 4.46s\tremaining: 806ms\n",
      "847:\tlearn: 16465.0416622\ttotal: 4.46s\tremaining: 800ms\n",
      "848:\tlearn: 16464.5518831\ttotal: 4.47s\tremaining: 795ms\n",
      "849:\tlearn: 16455.5596907\ttotal: 4.48s\tremaining: 790ms\n",
      "850:\tlearn: 16455.2399944\ttotal: 4.48s\tremaining: 785ms\n",
      "851:\tlearn: 16455.1287240\ttotal: 4.48s\tremaining: 779ms\n",
      "852:\tlearn: 16454.9458280\ttotal: 4.49s\tremaining: 774ms\n",
      "853:\tlearn: 16454.8424254\ttotal: 4.49s\tremaining: 768ms\n",
      "854:\tlearn: 16454.7136033\ttotal: 4.5s\tremaining: 763ms\n",
      "855:\tlearn: 16448.1004458\ttotal: 4.5s\tremaining: 758ms\n",
      "856:\tlearn: 16448.0207620\ttotal: 4.51s\tremaining: 752ms\n",
      "857:\tlearn: 16447.5540215\ttotal: 4.51s\tremaining: 747ms\n",
      "858:\tlearn: 16447.3244265\ttotal: 4.52s\tremaining: 742ms\n",
      "859:\tlearn: 16447.2634469\ttotal: 4.52s\tremaining: 736ms\n",
      "860:\tlearn: 16447.1181159\ttotal: 4.53s\tremaining: 731ms\n",
      "861:\tlearn: 16426.9935847\ttotal: 4.53s\tremaining: 725ms\n",
      "862:\tlearn: 16426.9246071\ttotal: 4.54s\tremaining: 721ms\n",
      "863:\tlearn: 16423.5729189\ttotal: 4.54s\tremaining: 715ms\n",
      "864:\tlearn: 16423.2419610\ttotal: 4.55s\tremaining: 710ms\n",
      "865:\tlearn: 16422.7169532\ttotal: 4.55s\tremaining: 705ms\n",
      "866:\tlearn: 16422.2913439\ttotal: 4.56s\tremaining: 700ms\n",
      "867:\tlearn: 16421.6548475\ttotal: 4.56s\tremaining: 694ms\n",
      "868:\tlearn: 16418.1032531\ttotal: 4.57s\tremaining: 689ms\n",
      "869:\tlearn: 16416.9788213\ttotal: 4.57s\tremaining: 684ms\n",
      "870:\tlearn: 16416.9251938\ttotal: 4.58s\tremaining: 678ms\n",
      "871:\tlearn: 16412.0514495\ttotal: 4.58s\tremaining: 672ms\n",
      "872:\tlearn: 16411.6244096\ttotal: 4.59s\tremaining: 667ms\n",
      "873:\tlearn: 16411.5186069\ttotal: 4.59s\tremaining: 662ms\n",
      "874:\tlearn: 16402.9744127\ttotal: 4.59s\tremaining: 657ms\n",
      "875:\tlearn: 16402.7459747\ttotal: 4.6s\tremaining: 651ms\n",
      "876:\tlearn: 16402.3781379\ttotal: 4.61s\tremaining: 646ms\n",
      "877:\tlearn: 16401.7377036\ttotal: 4.61s\tremaining: 641ms\n",
      "878:\tlearn: 16401.3348554\ttotal: 4.61s\tremaining: 635ms\n",
      "879:\tlearn: 16399.5137349\ttotal: 4.62s\tremaining: 630ms\n",
      "880:\tlearn: 16393.2316449\ttotal: 4.62s\tremaining: 624ms\n",
      "881:\tlearn: 16392.9104432\ttotal: 4.63s\tremaining: 619ms\n",
      "882:\tlearn: 16386.9400870\ttotal: 4.63s\tremaining: 614ms\n",
      "883:\tlearn: 16386.5294326\ttotal: 4.64s\tremaining: 609ms\n",
      "884:\tlearn: 16386.0271288\ttotal: 4.65s\tremaining: 604ms\n",
      "885:\tlearn: 16380.5607506\ttotal: 4.65s\tremaining: 599ms\n",
      "886:\tlearn: 16370.6869661\ttotal: 4.66s\tremaining: 594ms\n",
      "887:\tlearn: 16370.4213936\ttotal: 4.66s\tremaining: 588ms\n",
      "888:\tlearn: 16370.0867726\ttotal: 4.67s\tremaining: 583ms\n",
      "889:\tlearn: 16368.7242239\ttotal: 4.68s\tremaining: 578ms\n",
      "890:\tlearn: 16368.1342262\ttotal: 4.68s\tremaining: 573ms\n",
      "891:\tlearn: 16368.1285438\ttotal: 4.68s\tremaining: 567ms\n",
      "892:\tlearn: 16366.7828226\ttotal: 4.69s\tremaining: 562ms\n",
      "893:\tlearn: 16366.2413817\ttotal: 4.69s\tremaining: 556ms\n",
      "894:\tlearn: 16363.7105264\ttotal: 4.7s\tremaining: 551ms\n",
      "895:\tlearn: 16363.6022302\ttotal: 4.7s\tremaining: 546ms\n",
      "896:\tlearn: 16363.2825237\ttotal: 4.71s\tremaining: 541ms\n",
      "897:\tlearn: 16359.8691253\ttotal: 4.71s\tremaining: 535ms\n",
      "898:\tlearn: 16359.7281225\ttotal: 4.72s\tremaining: 530ms\n",
      "899:\tlearn: 16359.6897902\ttotal: 4.72s\tremaining: 524ms\n",
      "900:\tlearn: 16359.3374873\ttotal: 4.72s\tremaining: 519ms\n",
      "901:\tlearn: 16359.2989963\ttotal: 4.73s\tremaining: 514ms\n",
      "902:\tlearn: 16358.9017686\ttotal: 4.73s\tremaining: 508ms\n",
      "903:\tlearn: 16358.7970293\ttotal: 4.74s\tremaining: 503ms\n",
      "904:\tlearn: 16358.6650088\ttotal: 4.74s\tremaining: 498ms\n",
      "905:\tlearn: 16353.0840342\ttotal: 4.75s\tremaining: 492ms\n",
      "906:\tlearn: 16353.0381020\ttotal: 4.75s\tremaining: 487ms\n",
      "907:\tlearn: 16352.8983733\ttotal: 4.75s\tremaining: 482ms\n",
      "908:\tlearn: 16348.9128837\ttotal: 4.76s\tremaining: 477ms\n",
      "909:\tlearn: 16348.7380601\ttotal: 4.76s\tremaining: 471ms\n",
      "910:\tlearn: 16348.7039420\ttotal: 4.77s\tremaining: 466ms\n",
      "911:\tlearn: 16348.6704916\ttotal: 4.77s\tremaining: 460ms\n",
      "912:\tlearn: 16347.7268836\ttotal: 4.77s\tremaining: 455ms\n",
      "913:\tlearn: 16347.5978720\ttotal: 4.78s\tremaining: 450ms\n",
      "914:\tlearn: 16347.5242945\ttotal: 4.78s\tremaining: 444ms\n",
      "915:\tlearn: 16346.9625796\ttotal: 4.79s\tremaining: 439ms\n",
      "916:\tlearn: 16346.9299540\ttotal: 4.79s\tremaining: 434ms\n",
      "917:\tlearn: 16346.1235862\ttotal: 4.79s\tremaining: 428ms\n",
      "918:\tlearn: 16342.9947003\ttotal: 4.8s\tremaining: 423ms\n",
      "919:\tlearn: 16342.1731407\ttotal: 4.8s\tremaining: 418ms\n",
      "920:\tlearn: 16341.7920604\ttotal: 4.81s\tremaining: 412ms\n",
      "921:\tlearn: 16340.2277336\ttotal: 4.81s\tremaining: 407ms\n",
      "922:\tlearn: 16340.2220796\ttotal: 4.82s\tremaining: 402ms\n",
      "923:\tlearn: 16335.0029877\ttotal: 4.82s\tremaining: 397ms\n",
      "924:\tlearn: 16334.5868622\ttotal: 4.83s\tremaining: 391ms\n",
      "925:\tlearn: 16333.0801690\ttotal: 4.83s\tremaining: 386ms\n",
      "926:\tlearn: 16331.8570713\ttotal: 4.84s\tremaining: 381ms\n",
      "927:\tlearn: 16324.2948229\ttotal: 4.84s\tremaining: 376ms\n",
      "928:\tlearn: 16323.8803939\ttotal: 4.85s\tremaining: 371ms\n",
      "929:\tlearn: 16323.7573325\ttotal: 4.86s\tremaining: 366ms\n",
      "930:\tlearn: 16323.6257098\ttotal: 4.86s\tremaining: 360ms\n",
      "931:\tlearn: 16320.1193271\ttotal: 4.87s\tremaining: 355ms\n",
      "932:\tlearn: 16319.8096688\ttotal: 4.87s\tremaining: 350ms\n",
      "933:\tlearn: 16316.9783981\ttotal: 4.88s\tremaining: 345ms\n",
      "934:\tlearn: 16316.8537811\ttotal: 4.88s\tremaining: 339ms\n",
      "935:\tlearn: 16312.9369465\ttotal: 4.89s\tremaining: 334ms\n",
      "936:\tlearn: 16312.7008203\ttotal: 4.89s\tremaining: 329ms\n",
      "937:\tlearn: 16312.6498072\ttotal: 4.9s\tremaining: 324ms\n",
      "938:\tlearn: 16312.6097926\ttotal: 4.9s\tremaining: 318ms\n",
      "939:\tlearn: 16308.1168031\ttotal: 4.91s\tremaining: 313ms\n",
      "940:\tlearn: 16306.0832069\ttotal: 4.91s\tremaining: 308ms\n",
      "941:\tlearn: 16303.1294950\ttotal: 4.92s\tremaining: 303ms\n",
      "942:\tlearn: 16303.1228790\ttotal: 4.92s\tremaining: 297ms\n",
      "943:\tlearn: 16302.9977989\ttotal: 4.92s\tremaining: 292ms\n",
      "944:\tlearn: 16302.7167652\ttotal: 4.93s\tremaining: 287ms\n",
      "945:\tlearn: 16302.2418714\ttotal: 4.93s\tremaining: 282ms\n",
      "946:\tlearn: 16296.5850259\ttotal: 4.94s\tremaining: 276ms\n",
      "947:\tlearn: 16296.5571757\ttotal: 4.94s\tremaining: 271ms\n",
      "948:\tlearn: 16296.5315352\ttotal: 4.94s\tremaining: 266ms\n",
      "949:\tlearn: 16295.3401169\ttotal: 4.95s\tremaining: 260ms\n",
      "950:\tlearn: 16289.8858410\ttotal: 4.95s\tremaining: 255ms\n",
      "951:\tlearn: 16285.7454633\ttotal: 4.96s\tremaining: 250ms\n",
      "952:\tlearn: 16285.2174460\ttotal: 4.96s\tremaining: 245ms\n",
      "953:\tlearn: 16285.0668138\ttotal: 4.97s\tremaining: 240ms\n",
      "954:\tlearn: 16285.0333196\ttotal: 4.97s\tremaining: 234ms\n",
      "955:\tlearn: 16284.9293771\ttotal: 4.98s\tremaining: 229ms\n",
      "956:\tlearn: 16284.3115244\ttotal: 4.98s\tremaining: 224ms\n",
      "957:\tlearn: 16284.2091558\ttotal: 4.99s\tremaining: 219ms\n",
      "958:\tlearn: 16258.8153143\ttotal: 4.99s\tremaining: 213ms\n",
      "959:\tlearn: 16238.3706465\ttotal: 5s\tremaining: 208ms\n",
      "960:\tlearn: 16226.1683353\ttotal: 5s\tremaining: 203ms\n",
      "961:\tlearn: 16225.9847743\ttotal: 5.01s\tremaining: 198ms\n",
      "962:\tlearn: 16225.1384472\ttotal: 5.01s\tremaining: 193ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963:\tlearn: 16224.8267721\ttotal: 5.02s\tremaining: 187ms\n",
      "964:\tlearn: 16224.7735412\ttotal: 5.02s\tremaining: 182ms\n",
      "965:\tlearn: 16221.1965896\ttotal: 5.03s\tremaining: 177ms\n",
      "966:\tlearn: 16221.0457983\ttotal: 5.04s\tremaining: 172ms\n",
      "967:\tlearn: 16220.8911292\ttotal: 5.04s\tremaining: 167ms\n",
      "968:\tlearn: 16220.7161035\ttotal: 5.04s\tremaining: 161ms\n",
      "969:\tlearn: 16215.3449235\ttotal: 5.05s\tremaining: 156ms\n",
      "970:\tlearn: 16215.2563400\ttotal: 5.06s\tremaining: 151ms\n",
      "971:\tlearn: 16215.2343195\ttotal: 5.06s\tremaining: 146ms\n",
      "972:\tlearn: 16215.2225220\ttotal: 5.06s\tremaining: 140ms\n",
      "973:\tlearn: 16208.9326121\ttotal: 5.07s\tremaining: 135ms\n",
      "974:\tlearn: 16208.8154791\ttotal: 5.07s\tremaining: 130ms\n",
      "975:\tlearn: 16208.1702275\ttotal: 5.08s\tremaining: 125ms\n",
      "976:\tlearn: 16206.6411731\ttotal: 5.08s\tremaining: 120ms\n",
      "977:\tlearn: 16206.0472755\ttotal: 5.09s\tremaining: 114ms\n",
      "978:\tlearn: 16204.6989848\ttotal: 5.09s\tremaining: 109ms\n",
      "979:\tlearn: 16204.3493438\ttotal: 5.1s\tremaining: 104ms\n",
      "980:\tlearn: 16204.0392675\ttotal: 5.1s\tremaining: 98.9ms\n",
      "981:\tlearn: 16195.0467503\ttotal: 5.11s\tremaining: 93.7ms\n",
      "982:\tlearn: 16194.9057240\ttotal: 5.11s\tremaining: 88.4ms\n",
      "983:\tlearn: 16194.8501479\ttotal: 5.12s\tremaining: 83.2ms\n",
      "984:\tlearn: 16189.5913676\ttotal: 5.12s\tremaining: 78ms\n",
      "985:\tlearn: 16182.8040248\ttotal: 5.13s\tremaining: 72.8ms\n",
      "986:\tlearn: 16182.6814528\ttotal: 5.13s\tremaining: 67.6ms\n",
      "987:\tlearn: 16182.6628982\ttotal: 5.13s\tremaining: 62.4ms\n",
      "988:\tlearn: 16180.2590701\ttotal: 5.14s\tremaining: 57.2ms\n",
      "989:\tlearn: 16179.5616468\ttotal: 5.14s\tremaining: 52ms\n",
      "990:\tlearn: 16179.3495704\ttotal: 5.15s\tremaining: 46.8ms\n",
      "991:\tlearn: 16177.1744683\ttotal: 5.15s\tremaining: 41.6ms\n",
      "992:\tlearn: 16177.0155848\ttotal: 5.16s\tremaining: 36.4ms\n",
      "993:\tlearn: 16176.9636383\ttotal: 5.16s\tremaining: 31.2ms\n",
      "994:\tlearn: 16176.1709491\ttotal: 5.17s\tremaining: 26ms\n",
      "995:\tlearn: 16175.9914396\ttotal: 5.17s\tremaining: 20.8ms\n",
      "996:\tlearn: 16175.8987371\ttotal: 5.18s\tremaining: 15.6ms\n",
      "997:\tlearn: 16175.6029210\ttotal: 5.19s\tremaining: 10.4ms\n",
      "998:\tlearn: 16175.5684532\ttotal: 5.19s\tremaining: 5.2ms\n",
      "999:\tlearn: 16174.5689998\ttotal: 5.19s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbose=0)), ('feature_selection', SelectFromModel(estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "         ...one, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'feature_selection': [SelectFromModel(estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       " ..., <catboost.core.CatBoostRegressor object at 0x7fd1816b9588>], 'regressor__max_depth': [3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy=\"median\")),\n",
    "    ('feature_selection', SelectFromModel(RandomForestRegressor(n_estimators=100))),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "param_grid = { 'feature_selection': [SelectFromModel(RandomForestRegressor(n_estimators=100), threshold=0.0001),\n",
    "                                     None],\n",
    "               'regressor': [GradientBoostingRegressor(max_features=0.3),\n",
    "                             XGBRegressor(),\n",
    "                             CatBoostRegressor()],\n",
    "               'regressor__max_depth': [3, 4, 5, 6],\n",
    "              }\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_log_error', return_train_score=False, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor</th>\n",
       "      <th>param_regressor__max_depth</th>\n",
       "      <th>param_feature_selection</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.129451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.130433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.131280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.132134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.132136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.132418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.132459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.132638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.132722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>0.132856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>0.132904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>0.133276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>14</td>\n",
       "      <td>0.133680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.133757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.134534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.134847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.134912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.135196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.135230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>21</td>\n",
       "      <td>0.135398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>22</td>\n",
       "      <td>0.135922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.136325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.137148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      param_regressor  \\\n",
       "11  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "1   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "14  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "23  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "10  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "13  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "22  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "12  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "15  GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "2   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "20  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "17  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "16  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "21  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "0   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "6   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "3   GradientBoostingRegressor(alpha=0.9, criterion...   \n",
       "5   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "9   <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "4   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "19  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "18  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "7   XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "8   <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "\n",
       "   param_regressor__max_depth  \\\n",
       "11                          6   \n",
       "1                           4   \n",
       "14                          5   \n",
       "23                          6   \n",
       "10                          5   \n",
       "13                          4   \n",
       "22                          5   \n",
       "12                          3   \n",
       "15                          6   \n",
       "2                           5   \n",
       "20                          3   \n",
       "17                          4   \n",
       "16                          3   \n",
       "21                          4   \n",
       "0                           3   \n",
       "6                           5   \n",
       "3                           6   \n",
       "5                           4   \n",
       "9                           4   \n",
       "4                           3   \n",
       "19                          6   \n",
       "18                          5   \n",
       "7                           6   \n",
       "8                           3   \n",
       "\n",
       "                              param_feature_selection  rank_test_score  \\\n",
       "11  SelectFromModel(estimator=RandomForestRegresso...                1   \n",
       "1   SelectFromModel(estimator=RandomForestRegresso...                2   \n",
       "14                                               None                3   \n",
       "23                                               None                4   \n",
       "10  SelectFromModel(estimator=RandomForestRegresso...                5   \n",
       "13                                               None                6   \n",
       "22                                               None                7   \n",
       "12                                               None                8   \n",
       "15                                               None                9   \n",
       "2   SelectFromModel(estimator=RandomForestRegresso...               10   \n",
       "20                                               None               11   \n",
       "17                                               None               12   \n",
       "16                                               None               13   \n",
       "21                                               None               14   \n",
       "0   SelectFromModel(estimator=RandomForestRegresso...               15   \n",
       "6   SelectFromModel(estimator=RandomForestRegresso...               16   \n",
       "3   SelectFromModel(estimator=RandomForestRegresso...               17   \n",
       "5   SelectFromModel(estimator=RandomForestRegresso...               18   \n",
       "9   SelectFromModel(estimator=RandomForestRegresso...               19   \n",
       "4   SelectFromModel(estimator=RandomForestRegresso...               20   \n",
       "19                                               None               21   \n",
       "18                                               None               22   \n",
       "7   SelectFromModel(estimator=RandomForestRegresso...               23   \n",
       "8   SelectFromModel(estimator=RandomForestRegresso...               24   \n",
       "\n",
       "       rmsle  \n",
       "11  0.129403  \n",
       "1   0.129451  \n",
       "14  0.130433  \n",
       "23  0.131280  \n",
       "10  0.132134  \n",
       "13  0.132136  \n",
       "22  0.132418  \n",
       "12  0.132459  \n",
       "15  0.132638  \n",
       "2   0.132722  \n",
       "20  0.132856  \n",
       "17  0.132904  \n",
       "16  0.133276  \n",
       "21  0.133680  \n",
       "0   0.133757  \n",
       "6   0.134534  \n",
       "3   0.134847  \n",
       "5   0.134912  \n",
       "9   0.135196  \n",
       "4   0.135230  \n",
       "19  0.135398  \n",
       "18  0.135922  \n",
       "7   0.136325  \n",
       "8   0.137148  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(grid.cv_results_)\n",
    "res['rmsle'] = np.sqrt(-res.mean_test_score)\n",
    "res.loc[:, ['param_regressor', 'param_regressor__max_depth', 'param_feature_selection',\n",
    "            'rank_test_score', 'rmsle']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1322916619216565"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cat boost seems to do well but might do even better if I hadn't one hot encoded the data.\n",
    "* Feature selection seemed to help a little with a low threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
